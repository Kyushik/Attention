{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hard Attention MNIST\n",
    "\n",
    "This is jupyter notebook for `Hard Attention` from paper [Show, Attend and Tell](https://arxiv.org/abs/1502.03044). \n",
    "<br>This Algorithm will be tested by `Modified MNIST dataset` Which is made by [Jongwon Park](https://github.com/jwpark116). <br>This modified MNIST dataset is good for verifying attention algorithm.\n",
    "<br>You can download modified MNIST data from this link\n",
    "<br>[Training dataset](https://www.dropbox.com/s/e7jxyulxx2anqyq/MNIST_data_train_re.mat?dl=0)  /  [Testing dataset](https://www.dropbox.com/s/fcw4754bavva9my/MNIST_data_test_re.mat?dl=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (55000, 112, 112)\n",
      "Train label shape: (55000, 10)\n",
      "Test data shape: (9900, 112, 112)\n",
      "Test label shape: (9900, 10)\n",
      "Validation data shape: (100, 112, 112)\n",
      "Validation label shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "\n",
    "mat_data_train = scipy.io.loadmat('MNIST_data_train_re.mat')\n",
    "mat_data_test = scipy.io.loadmat('MNIST_data_test_re.mat')\n",
    "\n",
    "train_x = mat_data_train['X_train']\n",
    "train_y = mat_data_train['Y_train']\n",
    "\n",
    "test_x = mat_data_test['X_test'][:9900, :]\n",
    "test_y = mat_data_test['Y_test'][:9900, :]\n",
    "\n",
    "validation_x = mat_data_test['X_test'][9900:, :]\n",
    "validation_y = mat_data_test['Y_test'][9900:, :]\n",
    "\n",
    "del mat_data_train\n",
    "del mat_data_test\n",
    "\n",
    "print(\"Train data shape: \" + str(train_x.shape))\n",
    "print(\"Train label shape: \" + str(train_y.shape))\n",
    "print(\"Test data shape: \" + str(test_x.shape))\n",
    "print(\"Test label shape: \" + str(test_y.shape))\n",
    "print(\"Validation data shape: \" + str(validation_x.shape))\n",
    "print(\"Validation label shape: \" + str(validation_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal Length: 7\n",
      "Vertical Length: 7\n",
      "Window Length: 49\n"
     ]
    }
   ],
   "source": [
    "# Parameters \n",
    "img_size = train_x.shape[1]\n",
    "img_flat_size = img_size * img_size\n",
    "\n",
    "# If you want to train the model -> True, otherwise -> False\n",
    "Is_train = True\n",
    "\n",
    "# If you want to load saved model -> True, otherwise -> False \n",
    "Load_model = False\n",
    "\n",
    "# Name of the save file\n",
    "save_name = 'hard1'\n",
    "\n",
    "# Numbers of sampling to test the code \n",
    "num_test_sample = 10\n",
    "\n",
    "# labels: 0 - 9\n",
    "num_label = 10\n",
    "\n",
    "# Parameters for training\n",
    "num_epoch = 10\n",
    "\n",
    "learning_rate = 5e-4\n",
    "epsilon = 1e-8\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Parameter for LSTM\n",
    "lstm_size = 256\n",
    "step_size = 4\n",
    "flatten_size = img_size\n",
    "\n",
    "gpu_fraction = 0.3\n",
    "\n",
    "# parameter for attention\n",
    "img_fraction_size = 28\n",
    "stride = 14\n",
    "\n",
    "len_horizontal = int((img_size - img_fraction_size) / stride + 1)\n",
    "len_vertical   = int((img_size - img_fraction_size) / stride + 1)\n",
    "len_stack = len_horizontal * len_vertical\n",
    "\n",
    "print(\"Horizontal Length: \" + str(len_horizontal))\n",
    "print(\"Vertical Length: \" +str(len_vertical))\n",
    "print(\"Window Length: \" +str(len_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Sample Image (Modified MNIST for Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAFjCAYAAAAU10ErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xddd14e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Plotting example image\n",
    "img = train_x[0, :, :]\n",
    "# img_resize = img.reshape((img_size, img_size))\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()\n",
    "print('Label: ' + str(train_y[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Sample Image Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAFjCAYAAAD7OehQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIAhhBsAAEP+H+4yL5eqBS4yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe961a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(len_vertical, len_horizontal)\n",
    "\n",
    "img_fraction = np.zeros([img_fraction_size, img_fraction_size, len_stack])\n",
    "index_fraction = 0\n",
    "for i in range(len_vertical):\n",
    "    start_v = stride * i\n",
    "    for j in range(len_horizontal):\n",
    "        start_h = stride * j\n",
    "                \n",
    "        img_fraction[:,:,index_fraction] = img[start_v : start_v + img_fraction_size, \n",
    "                                               start_h : start_h + img_fraction_size]\n",
    "        \n",
    "        ax[i, j].imshow(img_fraction[:,:,index_fraction], cmap = 'gray')\n",
    "        ax[i, j].axis('off')\n",
    "        \n",
    "        index_fraction += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize weights and bias \n",
    "def conv2d(x,w, stride):\n",
    "\treturn tf.nn.conv2d(x,w,strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Get Variables\n",
    "def weight_variable(name, shape):\n",
    "    return tf.get_variable(name,shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    return tf.get_variable(name,shape=shape, initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM and Attention function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# LSTM function\n",
    "def LSTM_cell(C_prev, h_prev, x_lstm, Wf, Wi, Wc, Wo, bf, bi, bc, bo):\n",
    "    # C_prev: Cell state from lstm of previous time step (shape: [batch_size, lstm_size])\n",
    "    # h_prev: output from lstm of previous time step (shape: [batch_size, lstm_size])\n",
    "    # x_lstm: input of lstm (shape: [batch_size, data_flatten_size])\n",
    "\n",
    "    input_concat = tf.concat([x_lstm, h_prev], 1)\n",
    "    f = tf.sigmoid(tf.matmul(input_concat, Wf) + bf)\n",
    "    i = tf.sigmoid(tf.matmul(input_concat, Wi) + bi)\n",
    "    c = tf.tanh(tf.matmul(input_concat, Wc) + bc)\n",
    "    o = tf.sigmoid(tf.matmul(input_concat, Wo) + bo)\n",
    "    \n",
    "    C_t = tf.multiply(f, C_prev) + tf.multiply(i, c) \n",
    "    h_t = tf.multiply(o, tf.tanh(C_t))\n",
    "    \n",
    "    return C_t, h_t # Cell state, Output\n",
    "\n",
    "# Soft Attention function\n",
    "def hard_attention(h_prev, a, Wa, Wh):\n",
    "    # h_prev: output from lstm of previous time step (shape: [batch_size, lstm_size])\n",
    "    # a: Image windows after CNN. List of convolution window images \n",
    "    # (List len: number of windows, element shape: [batch_size, convolution flatten size])\n",
    "    \n",
    "    m_list = [tf.tanh(tf.matmul(a[i], Wa) + tf.matmul(h_prev, Wh)) for i in range(len(a))]\n",
    "    m_concat = tf.concat([m_list[i] for i in range(len(a))], axis = 1)\n",
    "    alpha = tf.nn.softmax(m_concat)\n",
    "    alpha_argmax = tf.argmax(alpha, axis = 1)\n",
    "    alpha_hard  = tf.one_hot(alpha_argmax, len_stack)\n",
    "    \n",
    "##     For Monte-Carlo Sampling\n",
    "#     alpha_cumsum = tf.cumsum(alpha, axis = 1)\n",
    "#     len_batch = tf.shape(alpha_cumsum)[0]\n",
    "#     rand_prob = tf.random_uniform(shape = [len_batch, 1], minval = 0., maxval = 1.)\n",
    "#     alpha_relu = tf.nn.relu(rand_prob - alpha_cumsum)\n",
    "#     alpha_index = tf.count_nonzero(alpha_relu, 1)\n",
    "#     alpha_hard  = tf.one_hot(alpha_index, len_stack)\n",
    "    \n",
    "    z_list = [tf.multiply(a[i], tf.slice(alpha_hard, (0, i), (-1, 1))) for i in range(len(a))]\n",
    "    z_stack = tf.stack(z_list, axis = 2)\n",
    "    z = tf.reduce_sum(z_stack, axis = 2)\n",
    "\n",
    "    #     return alpha_hard, z, alpha, alpha_cumsum, rand_prob, alpha_relu, alpha_index\n",
    "    \n",
    "    return alpha_hard, z, alpha\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "# Input \n",
    "x_image  = tf.placeholder(tf.float32, shape = [None, img_fraction_size, img_fraction_size, len_stack])\n",
    "y_target = tf.placeholder(tf.float32, shape=[None, num_label])\n",
    "\n",
    "x_unstack = tf.unstack(x_image, axis = 3)\n",
    "\n",
    "# Convolution variables\n",
    "w_conv1 = weight_variable('W_conv1', [3, 3, 1, 32])\n",
    "b_conv1 = bias_variable('b_conv1', [32])\n",
    "w_conv2 = weight_variable('W_conv2', [1, 1, 32, 16])\n",
    "b_conv2 = bias_variable('b_conv2', [16])\n",
    "\n",
    "conv_list = []\n",
    "for i in range(len_stack):\n",
    "    x_conv = tf.reshape(x_unstack[i], (-1, img_fraction_size, img_fraction_size, 1))\n",
    "    conv1 = tf.nn.relu(conv2d(x_conv, w_conv1, 2) + b_conv1)\n",
    "    pool1 = max_pool_2x2(conv1)\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, w_conv2, 1) + b_conv2)\n",
    "    pool2 = max_pool_2x2(conv2)\n",
    "    conv_result_flat = tf.contrib.layers.flatten(pool2)\n",
    "    conv_list.append(conv_result_flat)\n",
    "\n",
    "len_conv = int(conv_list[0].get_shape()[1])\n",
    "\n",
    "#LSTM Variables\n",
    "Wf = weight_variable('Wf', [len_conv + lstm_size, lstm_size])\n",
    "Wi = weight_variable('Wi', [len_conv + lstm_size, lstm_size])\n",
    "Wc = weight_variable('Wc', [len_conv + lstm_size, lstm_size])\n",
    "Wo = weight_variable('Wo', [len_conv + lstm_size, lstm_size])\n",
    "\n",
    "bf = bias_variable('bf', [lstm_size])\n",
    "bi = bias_variable('bi', [lstm_size])\n",
    "bc = bias_variable('bc', [lstm_size])\n",
    "bo = bias_variable('bo', [lstm_size]) \n",
    "\n",
    "# Attention Variables\n",
    "Wa = weight_variable('Wa', [len_conv, 1])\n",
    "Wh = weight_variable('Wh', [lstm_size, 1])\n",
    "\n",
    "rnn_batch_size = tf.shape(x_image)[0]\n",
    "\n",
    "# Initial lstm cell state and output \n",
    "rnn_state = tf.zeros([rnn_batch_size, lstm_size], tf.float32)\n",
    "rnn_out = tf.zeros([rnn_batch_size, lstm_size], tf.float32)\n",
    "\n",
    "#################################### Attention!!! ####################################\n",
    "for i in range(step_size):\n",
    "    alpha_hard, z, alpha = hard_attention(rnn_out, conv_list, Wa, Wh)\n",
    "    rnn_state, rnn_out = LSTM_cell(rnn_state, rnn_out, z, Wf, Wi, Wc, Wo, bf, bi, bc, bo)\n",
    "######################################################################################\n",
    "\n",
    "# Densely connect layer variables \n",
    "w_fc1 = weight_variable('w_fc1', [lstm_size, num_label])\n",
    "b_fc1 = bias_variable('b_fc1', [num_label])\n",
    "\n",
    "output = tf.matmul(rnn_out, w_fc1)+b_fc1\n",
    "\n",
    "# Training \n",
    "Loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y_target, logits = output)\n",
    "Cost = tf.reduce_mean(Loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon = epsilon).minimize(Cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_target,1), tf.argmax(output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "if Load_model == True:\n",
    "    checkpoint = tf.train.get_checkpoint_state(\"saved_networks/\")\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        print(\"Successfully loaded:\", checkpoint.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Could not find old network weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 0/55000 / Cost: 0.702318 / Training Accuracy: 0.132813 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 256/55000 / Cost: 0.652851 / Training Accuracy: 0.0742188 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 512/55000 / Cost: 0.603063 / Training Accuracy: 0.113281 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 768/55000 / Cost: 0.558249 / Training Accuracy: 0.0625 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 1024/55000 / Cost: 0.50767 / Training Accuracy: 0.105469 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 1280/55000 / Cost: 0.463038 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.14\n",
      "Epoch: 1 / Batch: 1536/55000 / Cost: 0.424006 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 1792/55000 / Cost: 0.384546 / Training Accuracy: 0.121094 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 2048/55000 / Cost: 0.359354 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 2304/55000 / Cost: 0.341614 / Training Accuracy: 0.09375 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 2560/55000 / Cost: 0.331928 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 2816/55000 / Cost: 0.334875 / Training Accuracy: 0.0625 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 3072/55000 / Cost: 0.330583 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 3328/55000 / Cost: 0.338705 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 3584/55000 / Cost: 0.345113 / Training Accuracy: 0.078125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 3840/55000 / Cost: 0.344987 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 4096/55000 / Cost: 0.347027 / Training Accuracy: 0.078125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 4352/55000 / Cost: 0.344493 / Training Accuracy: 0.09375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 4608/55000 / Cost: 0.343535 / Training Accuracy: 0.167969 / Validation Accuracy: 0.18\n",
      "Epoch: 1 / Batch: 4864/55000 / Cost: 0.33938 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5120/55000 / Cost: 0.336191 / Training Accuracy: 0.132813 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5376/55000 / Cost: 0.333799 / Training Accuracy: 0.125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5632/55000 / Cost: 0.333179 / Training Accuracy: 0.09375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5888/55000 / Cost: 0.328247 / Training Accuracy: 0.101563 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6144/55000 / Cost: 0.326521 / Training Accuracy: 0.140625 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6400/55000 / Cost: 0.330358 / Training Accuracy: 0.121094 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6656/55000 / Cost: 0.327173 / Training Accuracy: 0.125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6912/55000 / Cost: 0.328925 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7168/55000 / Cost: 0.326045 / Training Accuracy: 0.140625 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7424/55000 / Cost: 0.329882 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7680/55000 / Cost: 0.326372 / Training Accuracy: 0.140625 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7936/55000 / Cost: 0.32586 / Training Accuracy: 0.140625 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 8192/55000 / Cost: 0.326217 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.13\n",
      "Epoch: 1 / Batch: 8448/55000 / Cost: 0.326273 / Training Accuracy: 0.140625 / Validation Accuracy: 0.14\n",
      "Epoch: 1 / Batch: 8704/55000 / Cost: 0.325252 / Training Accuracy: 0.136719 / Validation Accuracy: 0.16\n",
      "Epoch: 1 / Batch: 8960/55000 / Cost: 0.324644 / Training Accuracy: 0.144531 / Validation Accuracy: 0.2\n",
      "Epoch: 1 / Batch: 9216/55000 / Cost: 0.325677 / Training Accuracy: 0.113281 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 9472/55000 / Cost: 0.323812 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 9728/55000 / Cost: 0.325839 / Training Accuracy: 0.0976563 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 9984/55000 / Cost: 0.324209 / Training Accuracy: 0.15625 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 10240/55000 / Cost: 0.324259 / Training Accuracy: 0.136719 / Validation Accuracy: 0.13\n",
      "Epoch: 1 / Batch: 10496/55000 / Cost: 0.324483 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 10752/55000 / Cost: 0.325756 / Training Accuracy: 0.078125 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 11008/55000 / Cost: 0.32601 / Training Accuracy: 0.105469 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 11264/55000 / Cost: 0.325635 / Training Accuracy: 0.113281 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 11520/55000 / Cost: 0.323992 / Training Accuracy: 0.128906 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 11776/55000 / Cost: 0.324739 / Training Accuracy: 0.121094 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 12032/55000 / Cost: 0.323709 / Training Accuracy: 0.113281 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 12288/55000 / Cost: 0.324837 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.08\n",
      "Epoch: 1 / Batch: 12544/55000 / Cost: 0.323807 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 12800/55000 / Cost: 0.322969 / Training Accuracy: 0.117188 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 13056/55000 / Cost: 0.323926 / Training Accuracy: 0.164063 / Validation Accuracy: 0.17\n",
      "Epoch: 1 / Batch: 13312/55000 / Cost: 0.324476 / Training Accuracy: 0.148438 / Validation Accuracy: 0.2\n",
      "Epoch: 1 / Batch: 13568/55000 / Cost: 0.323591 / Training Accuracy: 0.171875 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 13824/55000 / Cost: 0.323572 / Training Accuracy: 0.183594 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 14080/55000 / Cost: 0.322636 / Training Accuracy: 0.183594 / Validation Accuracy: 0.18\n",
      "Epoch: 1 / Batch: 14336/55000 / Cost: 0.323641 / Training Accuracy: 0.164063 / Validation Accuracy: 0.17\n",
      "Epoch: 1 / Batch: 14592/55000 / Cost: 0.323071 / Training Accuracy: 0.15625 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 14848/55000 / Cost: 0.322421 / Training Accuracy: 0.140625 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 15104/55000 / Cost: 0.321924 / Training Accuracy: 0.160156 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 15360/55000 / Cost: 0.32415 / Training Accuracy: 0.132813 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 15616/55000 / Cost: 0.323219 / Training Accuracy: 0.132813 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 15872/55000 / Cost: 0.322797 / Training Accuracy: 0.140625 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 16128/55000 / Cost: 0.322691 / Training Accuracy: 0.175781 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 16384/55000 / Cost: 0.323281 / Training Accuracy: 0.121094 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 16640/55000 / Cost: 0.323587 / Training Accuracy: 0.140625 / Validation Accuracy: 0.17\n",
      "Epoch: 1 / Batch: 16896/55000 / Cost: 0.321207 / Training Accuracy: 0.203125 / Validation Accuracy: 0.18\n",
      "Epoch: 1 / Batch: 17152/55000 / Cost: 0.321736 / Training Accuracy: 0.171875 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 17408/55000 / Cost: 0.322814 / Training Accuracy: 0.164063 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 17664/55000 / Cost: 0.32118 / Training Accuracy: 0.226563 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 17920/55000 / Cost: 0.322904 / Training Accuracy: 0.1875 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 18176/55000 / Cost: 0.322172 / Training Accuracy: 0.1875 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 18432/55000 / Cost: 0.321568 / Training Accuracy: 0.191406 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 18688/55000 / Cost: 0.319992 / Training Accuracy: 0.230469 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 18944/55000 / Cost: 0.322124 / Training Accuracy: 0.152344 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 19200/55000 / Cost: 0.32025 / Training Accuracy: 0.199219 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 19456/55000 / Cost: 0.321199 / Training Accuracy: 0.171875 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 19712/55000 / Cost: 0.316785 / Training Accuracy: 0.246094 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 19968/55000 / Cost: 0.321367 / Training Accuracy: 0.15625 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 20224/55000 / Cost: 0.319303 / Training Accuracy: 0.167969 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 20480/55000 / Cost: 0.32143 / Training Accuracy: 0.195313 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 20736/55000 / Cost: 0.320255 / Training Accuracy: 0.203125 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 20992/55000 / Cost: 0.319128 / Training Accuracy: 0.167969 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 21248/55000 / Cost: 0.319524 / Training Accuracy: 0.21875 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 21504/55000 / Cost: 0.31973 / Training Accuracy: 0.15625 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 21760/55000 / Cost: 0.319129 / Training Accuracy: 0.160156 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 22016/55000 / Cost: 0.319757 / Training Accuracy: 0.136719 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 22272/55000 / Cost: 0.31784 / Training Accuracy: 0.207031 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 22528/55000 / Cost: 0.316385 / Training Accuracy: 0.210938 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 22784/55000 / Cost: 0.319373 / Training Accuracy: 0.210938 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 23040/55000 / Cost: 0.317065 / Training Accuracy: 0.199219 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 23296/55000 / Cost: 0.320675 / Training Accuracy: 0.148438 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 23552/55000 / Cost: 0.318148 / Training Accuracy: 0.242188 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 23808/55000 / Cost: 0.315112 / Training Accuracy: 0.230469 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 24064/55000 / Cost: 0.318616 / Training Accuracy: 0.195313 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 24320/55000 / Cost: 0.316096 / Training Accuracy: 0.1875 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 24576/55000 / Cost: 0.316899 / Training Accuracy: 0.171875 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 24832/55000 / Cost: 0.311924 / Training Accuracy: 0.226563 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 25088/55000 / Cost: 0.31617 / Training Accuracy: 0.199219 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 25344/55000 / Cost: 0.316114 / Training Accuracy: 0.195313 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 25600/55000 / Cost: 0.314828 / Training Accuracy: 0.234375 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 25856/55000 / Cost: 0.313879 / Training Accuracy: 0.226563 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 26112/55000 / Cost: 0.311857 / Training Accuracy: 0.269531 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 26368/55000 / Cost: 0.313832 / Training Accuracy: 0.242188 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 26624/55000 / Cost: 0.310381 / Training Accuracy: 0.261719 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 26880/55000 / Cost: 0.3095 / Training Accuracy: 0.25 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 27136/55000 / Cost: 0.310671 / Training Accuracy: 0.230469 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 27392/55000 / Cost: 0.310333 / Training Accuracy: 0.246094 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 27648/55000 / Cost: 0.313661 / Training Accuracy: 0.1875 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 27904/55000 / Cost: 0.306989 / Training Accuracy: 0.234375 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 28160/55000 / Cost: 0.309251 / Training Accuracy: 0.21875 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 28416/55000 / Cost: 0.310114 / Training Accuracy: 0.199219 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 28672/55000 / Cost: 0.307653 / Training Accuracy: 0.234375 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 28928/55000 / Cost: 0.308869 / Training Accuracy: 0.207031 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 29184/55000 / Cost: 0.309178 / Training Accuracy: 0.21875 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 29440/55000 / Cost: 0.30098 / Training Accuracy: 0.246094 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 29696/55000 / Cost: 0.306774 / Training Accuracy: 0.246094 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 29952/55000 / Cost: 0.303419 / Training Accuracy: 0.273438 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 30208/55000 / Cost: 0.302796 / Training Accuracy: 0.273438 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 30464/55000 / Cost: 0.308467 / Training Accuracy: 0.242188 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 30720/55000 / Cost: 0.305143 / Training Accuracy: 0.25 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 30976/55000 / Cost: 0.30008 / Training Accuracy: 0.296875 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 31232/55000 / Cost: 0.301617 / Training Accuracy: 0.289063 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 31488/55000 / Cost: 0.299954 / Training Accuracy: 0.28125 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 31744/55000 / Cost: 0.306434 / Training Accuracy: 0.269531 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 32000/55000 / Cost: 0.299666 / Training Accuracy: 0.285156 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 32256/55000 / Cost: 0.304211 / Training Accuracy: 0.269531 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 32512/55000 / Cost: 0.303196 / Training Accuracy: 0.269531 / Validation Accuracy: 0.36\n",
      "Epoch: 1 / Batch: 32768/55000 / Cost: 0.294415 / Training Accuracy: 0.3125 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 33024/55000 / Cost: 0.300778 / Training Accuracy: 0.25 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 33280/55000 / Cost: 0.30489 / Training Accuracy: 0.269531 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 33536/55000 / Cost: 0.301748 / Training Accuracy: 0.253906 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 33792/55000 / Cost: 0.303681 / Training Accuracy: 0.265625 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 34048/55000 / Cost: 0.304888 / Training Accuracy: 0.265625 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 34304/55000 / Cost: 0.299197 / Training Accuracy: 0.265625 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 34560/55000 / Cost: 0.299415 / Training Accuracy: 0.28125 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 34816/55000 / Cost: 0.30266 / Training Accuracy: 0.242188 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 35072/55000 / Cost: 0.294424 / Training Accuracy: 0.289063 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 35328/55000 / Cost: 0.299305 / Training Accuracy: 0.300781 / Validation Accuracy: 0.36\n",
      "Epoch: 1 / Batch: 35584/55000 / Cost: 0.293679 / Training Accuracy: 0.296875 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 35840/55000 / Cost: 0.303141 / Training Accuracy: 0.238281 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 36096/55000 / Cost: 0.289246 / Training Accuracy: 0.308594 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 36352/55000 / Cost: 0.298457 / Training Accuracy: 0.257813 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 36608/55000 / Cost: 0.295196 / Training Accuracy: 0.261719 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 36864/55000 / Cost: 0.292101 / Training Accuracy: 0.292969 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 37120/55000 / Cost: 0.294503 / Training Accuracy: 0.28125 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 37376/55000 / Cost: 0.293671 / Training Accuracy: 0.28125 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 37632/55000 / Cost: 0.291851 / Training Accuracy: 0.265625 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 37888/55000 / Cost: 0.298205 / Training Accuracy: 0.230469 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 38144/55000 / Cost: 0.289763 / Training Accuracy: 0.335938 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 38400/55000 / Cost: 0.284429 / Training Accuracy: 0.367188 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 38656/55000 / Cost: 0.292244 / Training Accuracy: 0.296875 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 38912/55000 / Cost: 0.291044 / Training Accuracy: 0.289063 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 39168/55000 / Cost: 0.290513 / Training Accuracy: 0.332031 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 39424/55000 / Cost: 0.284315 / Training Accuracy: 0.332031 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 39680/55000 / Cost: 0.293147 / Training Accuracy: 0.316406 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 39936/55000 / Cost: 0.276659 / Training Accuracy: 0.355469 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 40192/55000 / Cost: 0.295524 / Training Accuracy: 0.285156 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 40448/55000 / Cost: 0.290043 / Training Accuracy: 0.300781 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 40704/55000 / Cost: 0.284955 / Training Accuracy: 0.335938 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 40960/55000 / Cost: 0.277813 / Training Accuracy: 0.355469 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 41216/55000 / Cost: 0.288324 / Training Accuracy: 0.324219 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 41472/55000 / Cost: 0.28336 / Training Accuracy: 0.304688 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 41728/55000 / Cost: 0.285594 / Training Accuracy: 0.320313 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 41984/55000 / Cost: 0.281228 / Training Accuracy: 0.339844 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 42240/55000 / Cost: 0.279941 / Training Accuracy: 0.277344 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 42496/55000 / Cost: 0.282787 / Training Accuracy: 0.335938 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 42752/55000 / Cost: 0.286116 / Training Accuracy: 0.308594 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 43008/55000 / Cost: 0.294012 / Training Accuracy: 0.246094 / Validation Accuracy: 0.36\n",
      "Epoch: 1 / Batch: 43264/55000 / Cost: 0.280406 / Training Accuracy: 0.34375 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 43520/55000 / Cost: 0.278542 / Training Accuracy: 0.351563 / Validation Accuracy: 0.34\n",
      "Epoch: 1 / Batch: 43776/55000 / Cost: 0.283591 / Training Accuracy: 0.339844 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 44032/55000 / Cost: 0.275479 / Training Accuracy: 0.367188 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 44288/55000 / Cost: 0.288166 / Training Accuracy: 0.3125 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 44544/55000 / Cost: 0.280975 / Training Accuracy: 0.320313 / Validation Accuracy: 0.36\n",
      "Epoch: 1 / Batch: 44800/55000 / Cost: 0.289909 / Training Accuracy: 0.308594 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 45056/55000 / Cost: 0.278927 / Training Accuracy: 0.320313 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 45312/55000 / Cost: 0.27946 / Training Accuracy: 0.355469 / Validation Accuracy: 0.4\n",
      "Epoch: 1 / Batch: 45568/55000 / Cost: 0.271893 / Training Accuracy: 0.390625 / Validation Accuracy: 0.4\n",
      "Epoch: 1 / Batch: 45824/55000 / Cost: 0.290387 / Training Accuracy: 0.257813 / Validation Accuracy: 0.42\n",
      "Epoch: 1 / Batch: 46080/55000 / Cost: 0.283833 / Training Accuracy: 0.332031 / Validation Accuracy: 0.42\n",
      "Epoch: 1 / Batch: 46336/55000 / Cost: 0.276439 / Training Accuracy: 0.332031 / Validation Accuracy: 0.41\n",
      "Epoch: 1 / Batch: 46592/55000 / Cost: 0.270415 / Training Accuracy: 0.363281 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 46848/55000 / Cost: 0.275004 / Training Accuracy: 0.339844 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 47104/55000 / Cost: 0.287641 / Training Accuracy: 0.304688 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 47360/55000 / Cost: 0.273334 / Training Accuracy: 0.332031 / Validation Accuracy: 0.39\n",
      "Epoch: 1 / Batch: 47616/55000 / Cost: 0.267911 / Training Accuracy: 0.394531 / Validation Accuracy: 0.41\n",
      "Epoch: 1 / Batch: 47872/55000 / Cost: 0.268966 / Training Accuracy: 0.375 / Validation Accuracy: 0.4\n",
      "Epoch: 1 / Batch: 48128/55000 / Cost: 0.275675 / Training Accuracy: 0.367188 / Validation Accuracy: 0.41\n",
      "Epoch: 1 / Batch: 48384/55000 / Cost: 0.27435 / Training Accuracy: 0.335938 / Validation Accuracy: 0.4\n",
      "Epoch: 1 / Batch: 48640/55000 / Cost: 0.278152 / Training Accuracy: 0.347656 / Validation Accuracy: 0.39\n",
      "Epoch: 1 / Batch: 48896/55000 / Cost: 0.271958 / Training Accuracy: 0.335938 / Validation Accuracy: 0.41\n",
      "Epoch: 1 / Batch: 49152/55000 / Cost: 0.27291 / Training Accuracy: 0.347656 / Validation Accuracy: 0.4\n",
      "Epoch: 1 / Batch: 49408/55000 / Cost: 0.282903 / Training Accuracy: 0.253906 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 49664/55000 / Cost: 0.265791 / Training Accuracy: 0.355469 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 49920/55000 / Cost: 0.270642 / Training Accuracy: 0.320313 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 50176/55000 / Cost: 0.266196 / Training Accuracy: 0.351563 / Validation Accuracy: 0.35\n",
      "Epoch: 1 / Batch: 50432/55000 / Cost: 0.260896 / Training Accuracy: 0.421875 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 50688/55000 / Cost: 0.27376 / Training Accuracy: 0.335938 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 50944/55000 / Cost: 0.258327 / Training Accuracy: 0.417969 / Validation Accuracy: 0.36\n",
      "Epoch: 1 / Batch: 51200/55000 / Cost: 0.272063 / Training Accuracy: 0.386719 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 51456/55000 / Cost: 0.261865 / Training Accuracy: 0.410156 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 51712/55000 / Cost: 0.273832 / Training Accuracy: 0.355469 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 51968/55000 / Cost: 0.279793 / Training Accuracy: 0.335938 / Validation Accuracy: 0.39\n",
      "Epoch: 1 / Batch: 52224/55000 / Cost: 0.273356 / Training Accuracy: 0.351563 / Validation Accuracy: 0.41\n",
      "Epoch: 1 / Batch: 52480/55000 / Cost: 0.256024 / Training Accuracy: 0.417969 / Validation Accuracy: 0.4\n",
      "Epoch: 1 / Batch: 52736/55000 / Cost: 0.274129 / Training Accuracy: 0.367188 / Validation Accuracy: 0.37\n",
      "Epoch: 1 / Batch: 52992/55000 / Cost: 0.261853 / Training Accuracy: 0.425781 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 53248/55000 / Cost: 0.273123 / Training Accuracy: 0.359375 / Validation Accuracy: 0.38\n",
      "Epoch: 1 / Batch: 53504/55000 / Cost: 0.260586 / Training Accuracy: 0.421875 / Validation Accuracy: 0.41\n",
      "Epoch: 1 / Batch: 53760/55000 / Cost: 0.25838 / Training Accuracy: 0.421875 / Validation Accuracy: 0.44\n",
      "Epoch: 1 / Batch: 54016/55000 / Cost: 0.268248 / Training Accuracy: 0.402344 / Validation Accuracy: 0.46\n",
      "Epoch: 1 / Batch: 54272/55000 / Cost: 0.258321 / Training Accuracy: 0.429688 / Validation Accuracy: 0.48\n",
      "Epoch: 1 / Batch: 54528/55000 / Cost: 0.271032 / Training Accuracy: 0.390625 / Validation Accuracy: 0.47\n",
      "Epoch: 1 / Batch: 54784/55000 / Cost: 0.259921 / Training Accuracy: 0.384259 / Validation Accuracy: 0.44\n",
      "Model is saved!!!\n",
      "Epoch: 2 / Batch: 0/55000 / Cost: 0.262207 / Training Accuracy: 0.402344 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 256/55000 / Cost: 0.253005 / Training Accuracy: 0.414063 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 512/55000 / Cost: 0.266502 / Training Accuracy: 0.402344 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 768/55000 / Cost: 0.261627 / Training Accuracy: 0.355469 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 1024/55000 / Cost: 0.25083 / Training Accuracy: 0.4375 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 1280/55000 / Cost: 0.251314 / Training Accuracy: 0.46875 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 1536/55000 / Cost: 0.255376 / Training Accuracy: 0.421875 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 1792/55000 / Cost: 0.242401 / Training Accuracy: 0.472656 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 2048/55000 / Cost: 0.251984 / Training Accuracy: 0.417969 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 2304/55000 / Cost: 0.253246 / Training Accuracy: 0.425781 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 2560/55000 / Cost: 0.260629 / Training Accuracy: 0.382813 / Validation Accuracy: 0.47\n",
      "Epoch: 2 / Batch: 2816/55000 / Cost: 0.259258 / Training Accuracy: 0.417969 / Validation Accuracy: 0.49\n",
      "Epoch: 2 / Batch: 3072/55000 / Cost: 0.259756 / Training Accuracy: 0.40625 / Validation Accuracy: 0.47\n",
      "Epoch: 2 / Batch: 3328/55000 / Cost: 0.232067 / Training Accuracy: 0.515625 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 3584/55000 / Cost: 0.232922 / Training Accuracy: 0.519531 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 3840/55000 / Cost: 0.245561 / Training Accuracy: 0.480469 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 4096/55000 / Cost: 0.252455 / Training Accuracy: 0.433594 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 4352/55000 / Cost: 0.253736 / Training Accuracy: 0.429688 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 4608/55000 / Cost: 0.234935 / Training Accuracy: 0.488281 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 4864/55000 / Cost: 0.245356 / Training Accuracy: 0.402344 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 5120/55000 / Cost: 0.234154 / Training Accuracy: 0.480469 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 5376/55000 / Cost: 0.237264 / Training Accuracy: 0.449219 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 5632/55000 / Cost: 0.241339 / Training Accuracy: 0.464844 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 5888/55000 / Cost: 0.22699 / Training Accuracy: 0.480469 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 6144/55000 / Cost: 0.251885 / Training Accuracy: 0.425781 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 6400/55000 / Cost: 0.240752 / Training Accuracy: 0.476563 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 6656/55000 / Cost: 0.233081 / Training Accuracy: 0.523438 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 6912/55000 / Cost: 0.236041 / Training Accuracy: 0.5 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 7168/55000 / Cost: 0.233082 / Training Accuracy: 0.507813 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 7424/55000 / Cost: 0.236451 / Training Accuracy: 0.488281 / Validation Accuracy: 0.48\n",
      "Epoch: 2 / Batch: 7680/55000 / Cost: 0.231137 / Training Accuracy: 0.539063 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 7936/55000 / Cost: 0.230648 / Training Accuracy: 0.472656 / Validation Accuracy: 0.49\n",
      "Epoch: 2 / Batch: 8192/55000 / Cost: 0.231345 / Training Accuracy: 0.507813 / Validation Accuracy: 0.47\n",
      "Epoch: 2 / Batch: 8448/55000 / Cost: 0.237427 / Training Accuracy: 0.488281 / Validation Accuracy: 0.48\n",
      "Epoch: 2 / Batch: 8704/55000 / Cost: 0.229359 / Training Accuracy: 0.503906 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 8960/55000 / Cost: 0.221866 / Training Accuracy: 0.484375 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 9216/55000 / Cost: 0.225999 / Training Accuracy: 0.566406 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 9472/55000 / Cost: 0.241797 / Training Accuracy: 0.460938 / Validation Accuracy: 0.48\n",
      "Epoch: 2 / Batch: 9728/55000 / Cost: 0.214219 / Training Accuracy: 0.546875 / Validation Accuracy: 0.47\n",
      "Epoch: 2 / Batch: 9984/55000 / Cost: 0.231986 / Training Accuracy: 0.542969 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 10240/55000 / Cost: 0.216012 / Training Accuracy: 0.566406 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 10496/55000 / Cost: 0.207703 / Training Accuracy: 0.574219 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 10752/55000 / Cost: 0.219239 / Training Accuracy: 0.554688 / Validation Accuracy: 0.48\n",
      "Epoch: 2 / Batch: 11008/55000 / Cost: 0.225885 / Training Accuracy: 0.515625 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 11264/55000 / Cost: 0.225966 / Training Accuracy: 0.558594 / Validation Accuracy: 0.51\n",
      "Epoch: 2 / Batch: 11520/55000 / Cost: 0.228936 / Training Accuracy: 0.53125 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 11776/55000 / Cost: 0.221332 / Training Accuracy: 0.546875 / Validation Accuracy: 0.48\n",
      "Epoch: 2 / Batch: 12032/55000 / Cost: 0.215787 / Training Accuracy: 0.566406 / Validation Accuracy: 0.48\n",
      "Epoch: 2 / Batch: 12288/55000 / Cost: 0.208092 / Training Accuracy: 0.609375 / Validation Accuracy: 0.52\n",
      "Epoch: 2 / Batch: 12544/55000 / Cost: 0.226445 / Training Accuracy: 0.523438 / Validation Accuracy: 0.51\n",
      "Epoch: 2 / Batch: 12800/55000 / Cost: 0.219534 / Training Accuracy: 0.53125 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 13056/55000 / Cost: 0.217402 / Training Accuracy: 0.542969 / Validation Accuracy: 0.49\n",
      "Epoch: 2 / Batch: 13312/55000 / Cost: 0.217734 / Training Accuracy: 0.554688 / Validation Accuracy: 0.52\n",
      "Epoch: 2 / Batch: 13568/55000 / Cost: 0.209608 / Training Accuracy: 0.601563 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 13824/55000 / Cost: 0.21376 / Training Accuracy: 0.585938 / Validation Accuracy: 0.53\n",
      "Epoch: 2 / Batch: 14080/55000 / Cost: 0.215739 / Training Accuracy: 0.570313 / Validation Accuracy: 0.56\n",
      "Epoch: 2 / Batch: 14336/55000 / Cost: 0.21419 / Training Accuracy: 0.546875 / Validation Accuracy: 0.58\n",
      "Epoch: 2 / Batch: 14592/55000 / Cost: 0.215033 / Training Accuracy: 0.566406 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 14848/55000 / Cost: 0.202193 / Training Accuracy: 0.613281 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 15104/55000 / Cost: 0.196825 / Training Accuracy: 0.605469 / Validation Accuracy: 0.51\n",
      "Epoch: 2 / Batch: 15360/55000 / Cost: 0.20764 / Training Accuracy: 0.589844 / Validation Accuracy: 0.51\n",
      "Epoch: 2 / Batch: 15616/55000 / Cost: 0.21359 / Training Accuracy: 0.582031 / Validation Accuracy: 0.54\n",
      "Epoch: 2 / Batch: 15872/55000 / Cost: 0.202568 / Training Accuracy: 0.558594 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 16128/55000 / Cost: 0.204853 / Training Accuracy: 0.558594 / Validation Accuracy: 0.58\n",
      "Epoch: 2 / Batch: 16384/55000 / Cost: 0.203536 / Training Accuracy: 0.617188 / Validation Accuracy: 0.59\n",
      "Epoch: 2 / Batch: 16640/55000 / Cost: 0.199479 / Training Accuracy: 0.625 / Validation Accuracy: 0.54\n",
      "Epoch: 2 / Batch: 16896/55000 / Cost: 0.196872 / Training Accuracy: 0.609375 / Validation Accuracy: 0.53\n",
      "Epoch: 2 / Batch: 17152/55000 / Cost: 0.19695 / Training Accuracy: 0.605469 / Validation Accuracy: 0.6\n",
      "Epoch: 2 / Batch: 17408/55000 / Cost: 0.203491 / Training Accuracy: 0.589844 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 17664/55000 / Cost: 0.207124 / Training Accuracy: 0.550781 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 17920/55000 / Cost: 0.202731 / Training Accuracy: 0.546875 / Validation Accuracy: 0.53\n",
      "Epoch: 2 / Batch: 18176/55000 / Cost: 0.190691 / Training Accuracy: 0.667969 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 18432/55000 / Cost: 0.208656 / Training Accuracy: 0.574219 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 18688/55000 / Cost: 0.201651 / Training Accuracy: 0.589844 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 18944/55000 / Cost: 0.19463 / Training Accuracy: 0.589844 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 19200/55000 / Cost: 0.215834 / Training Accuracy: 0.546875 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 19456/55000 / Cost: 0.202453 / Training Accuracy: 0.59375 / Validation Accuracy: 0.58\n",
      "Epoch: 2 / Batch: 19712/55000 / Cost: 0.194477 / Training Accuracy: 0.613281 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 19968/55000 / Cost: 0.192125 / Training Accuracy: 0.625 / Validation Accuracy: 0.58\n",
      "Epoch: 2 / Batch: 20224/55000 / Cost: 0.200922 / Training Accuracy: 0.628906 / Validation Accuracy: 0.54\n",
      "Epoch: 2 / Batch: 20480/55000 / Cost: 0.192802 / Training Accuracy: 0.605469 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 20736/55000 / Cost: 0.203448 / Training Accuracy: 0.605469 / Validation Accuracy: 0.59\n",
      "Epoch: 2 / Batch: 20992/55000 / Cost: 0.194795 / Training Accuracy: 0.625 / Validation Accuracy: 0.59\n",
      "Epoch: 2 / Batch: 21248/55000 / Cost: 0.193154 / Training Accuracy: 0.601563 / Validation Accuracy: 0.58\n",
      "Epoch: 2 / Batch: 21504/55000 / Cost: 0.186573 / Training Accuracy: 0.605469 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 21760/55000 / Cost: 0.177662 / Training Accuracy: 0.675781 / Validation Accuracy: 0.6\n",
      "Epoch: 2 / Batch: 22016/55000 / Cost: 0.196419 / Training Accuracy: 0.589844 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 22272/55000 / Cost: 0.178253 / Training Accuracy: 0.691406 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 22528/55000 / Cost: 0.20102 / Training Accuracy: 0.585938 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 22784/55000 / Cost: 0.192728 / Training Accuracy: 0.625 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 23040/55000 / Cost: 0.176396 / Training Accuracy: 0.667969 / Validation Accuracy: 0.56\n",
      "Epoch: 2 / Batch: 23296/55000 / Cost: 0.187003 / Training Accuracy: 0.640625 / Validation Accuracy: 0.59\n",
      "Epoch: 2 / Batch: 23552/55000 / Cost: 0.189743 / Training Accuracy: 0.617188 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 23808/55000 / Cost: 0.188377 / Training Accuracy: 0.667969 / Validation Accuracy: 0.63\n",
      "Epoch: 2 / Batch: 24064/55000 / Cost: 0.185954 / Training Accuracy: 0.667969 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 24320/55000 / Cost: 0.178573 / Training Accuracy: 0.625 / Validation Accuracy: 0.58\n",
      "Epoch: 2 / Batch: 24576/55000 / Cost: 0.193623 / Training Accuracy: 0.589844 / Validation Accuracy: 0.6\n",
      "Epoch: 2 / Batch: 24832/55000 / Cost: 0.182003 / Training Accuracy: 0.667969 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 25088/55000 / Cost: 0.186893 / Training Accuracy: 0.621094 / Validation Accuracy: 0.63\n",
      "Epoch: 2 / Batch: 25344/55000 / Cost: 0.190601 / Training Accuracy: 0.632813 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 25600/55000 / Cost: 0.167551 / Training Accuracy: 0.679688 / Validation Accuracy: 0.64\n",
      "Epoch: 2 / Batch: 25856/55000 / Cost: 0.183971 / Training Accuracy: 0.605469 / Validation Accuracy: 0.62\n",
      "Epoch: 2 / Batch: 26112/55000 / Cost: 0.175011 / Training Accuracy: 0.65625 / Validation Accuracy: 0.6\n",
      "Epoch: 2 / Batch: 26368/55000 / Cost: 0.192056 / Training Accuracy: 0.605469 / Validation Accuracy: 0.62\n",
      "Epoch: 2 / Batch: 26624/55000 / Cost: 0.188348 / Training Accuracy: 0.636719 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 26880/55000 / Cost: 0.177397 / Training Accuracy: 0.65625 / Validation Accuracy: 0.54\n",
      "Epoch: 2 / Batch: 27136/55000 / Cost: 0.165152 / Training Accuracy: 0.679688 / Validation Accuracy: 0.55\n",
      "Epoch: 2 / Batch: 27392/55000 / Cost: 0.178284 / Training Accuracy: 0.667969 / Validation Accuracy: 0.59\n",
      "Epoch: 2 / Batch: 27648/55000 / Cost: 0.184143 / Training Accuracy: 0.648438 / Validation Accuracy: 0.59\n",
      "Epoch: 2 / Batch: 27904/55000 / Cost: 0.182137 / Training Accuracy: 0.640625 / Validation Accuracy: 0.6\n",
      "Epoch: 2 / Batch: 28160/55000 / Cost: 0.175576 / Training Accuracy: 0.675781 / Validation Accuracy: 0.6\n",
      "Epoch: 2 / Batch: 28416/55000 / Cost: 0.168809 / Training Accuracy: 0.71875 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 28672/55000 / Cost: 0.172438 / Training Accuracy: 0.640625 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 28928/55000 / Cost: 0.172604 / Training Accuracy: 0.667969 / Validation Accuracy: 0.63\n",
      "Epoch: 2 / Batch: 29184/55000 / Cost: 0.17356 / Training Accuracy: 0.6875 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 29440/55000 / Cost: 0.171323 / Training Accuracy: 0.667969 / Validation Accuracy: 0.65\n",
      "Epoch: 2 / Batch: 29696/55000 / Cost: 0.180623 / Training Accuracy: 0.652344 / Validation Accuracy: 0.62\n",
      "Epoch: 2 / Batch: 29952/55000 / Cost: 0.16368 / Training Accuracy: 0.734375 / Validation Accuracy: 0.64\n",
      "Epoch: 2 / Batch: 30208/55000 / Cost: 0.165016 / Training Accuracy: 0.710938 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 30464/55000 / Cost: 0.163226 / Training Accuracy: 0.710938 / Validation Accuracy: 0.61\n",
      "Epoch: 2 / Batch: 30720/55000 / Cost: 0.192454 / Training Accuracy: 0.613281 / Validation Accuracy: 0.57\n",
      "Epoch: 2 / Batch: 30976/55000 / Cost: 0.180533 / Training Accuracy: 0.660156 / Validation Accuracy: 0.59\n",
      "Epoch: 2 / Batch: 31232/55000 / Cost: 0.159525 / Training Accuracy: 0.710938 / Validation Accuracy: 0.65\n",
      "Epoch: 2 / Batch: 31488/55000 / Cost: 0.169702 / Training Accuracy: 0.695313 / Validation Accuracy: 0.64\n",
      "Epoch: 2 / Batch: 31744/55000 / Cost: 0.1609 / Training Accuracy: 0.703125 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 32000/55000 / Cost: 0.185719 / Training Accuracy: 0.65625 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 32256/55000 / Cost: 0.164874 / Training Accuracy: 0.6875 / Validation Accuracy: 0.67\n",
      "Epoch: 2 / Batch: 32512/55000 / Cost: 0.172247 / Training Accuracy: 0.675781 / Validation Accuracy: 0.7\n",
      "Epoch: 2 / Batch: 32768/55000 / Cost: 0.165237 / Training Accuracy: 0.691406 / Validation Accuracy: 0.67\n",
      "Epoch: 2 / Batch: 33024/55000 / Cost: 0.173284 / Training Accuracy: 0.664063 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 33280/55000 / Cost: 0.178295 / Training Accuracy: 0.652344 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 33536/55000 / Cost: 0.16215 / Training Accuracy: 0.726563 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 33792/55000 / Cost: 0.157692 / Training Accuracy: 0.714844 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 34048/55000 / Cost: 0.15765 / Training Accuracy: 0.707031 / Validation Accuracy: 0.64\n",
      "Epoch: 2 / Batch: 34304/55000 / Cost: 0.169468 / Training Accuracy: 0.683594 / Validation Accuracy: 0.65\n",
      "Epoch: 2 / Batch: 34560/55000 / Cost: 0.168711 / Training Accuracy: 0.671875 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 34816/55000 / Cost: 0.184786 / Training Accuracy: 0.609375 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 35072/55000 / Cost: 0.164667 / Training Accuracy: 0.675781 / Validation Accuracy: 0.67\n",
      "Epoch: 2 / Batch: 35328/55000 / Cost: 0.159169 / Training Accuracy: 0.714844 / Validation Accuracy: 0.64\n",
      "Epoch: 2 / Batch: 35584/55000 / Cost: 0.160668 / Training Accuracy: 0.726563 / Validation Accuracy: 0.64\n",
      "Epoch: 2 / Batch: 35840/55000 / Cost: 0.172328 / Training Accuracy: 0.667969 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 36096/55000 / Cost: 0.167264 / Training Accuracy: 0.6875 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 36352/55000 / Cost: 0.168114 / Training Accuracy: 0.636719 / Validation Accuracy: 0.67\n",
      "Epoch: 2 / Batch: 36608/55000 / Cost: 0.162636 / Training Accuracy: 0.679688 / Validation Accuracy: 0.67\n",
      "Epoch: 2 / Batch: 36864/55000 / Cost: 0.154675 / Training Accuracy: 0.691406 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 37120/55000 / Cost: 0.1615 / Training Accuracy: 0.71875 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 37376/55000 / Cost: 0.153606 / Training Accuracy: 0.699219 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 37632/55000 / Cost: 0.162135 / Training Accuracy: 0.707031 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 37888/55000 / Cost: 0.156424 / Training Accuracy: 0.714844 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 38144/55000 / Cost: 0.175924 / Training Accuracy: 0.628906 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 38400/55000 / Cost: 0.159418 / Training Accuracy: 0.730469 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 38656/55000 / Cost: 0.147644 / Training Accuracy: 0.753906 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 38912/55000 / Cost: 0.152785 / Training Accuracy: 0.746094 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 39168/55000 / Cost: 0.157784 / Training Accuracy: 0.6875 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 39424/55000 / Cost: 0.150395 / Training Accuracy: 0.730469 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 39680/55000 / Cost: 0.144498 / Training Accuracy: 0.757813 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 39936/55000 / Cost: 0.14567 / Training Accuracy: 0.742188 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 40192/55000 / Cost: 0.153124 / Training Accuracy: 0.710938 / Validation Accuracy: 0.7\n",
      "Epoch: 2 / Batch: 40448/55000 / Cost: 0.159982 / Training Accuracy: 0.695313 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 40704/55000 / Cost: 0.165455 / Training Accuracy: 0.699219 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 40960/55000 / Cost: 0.170147 / Training Accuracy: 0.667969 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 41216/55000 / Cost: 0.150933 / Training Accuracy: 0.753906 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 41472/55000 / Cost: 0.147759 / Training Accuracy: 0.761719 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 41728/55000 / Cost: 0.157092 / Training Accuracy: 0.730469 / Validation Accuracy: 0.7\n",
      "Epoch: 2 / Batch: 41984/55000 / Cost: 0.150083 / Training Accuracy: 0.738281 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 42240/55000 / Cost: 0.156546 / Training Accuracy: 0.734375 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 42496/55000 / Cost: 0.148916 / Training Accuracy: 0.730469 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 42752/55000 / Cost: 0.163235 / Training Accuracy: 0.683594 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 43008/55000 / Cost: 0.151179 / Training Accuracy: 0.726563 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 43264/55000 / Cost: 0.147327 / Training Accuracy: 0.761719 / Validation Accuracy: 0.7\n",
      "Epoch: 2 / Batch: 43520/55000 / Cost: 0.158453 / Training Accuracy: 0.699219 / Validation Accuracy: 0.7\n",
      "Epoch: 2 / Batch: 43776/55000 / Cost: 0.14087 / Training Accuracy: 0.75 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 44032/55000 / Cost: 0.153717 / Training Accuracy: 0.742188 / Validation Accuracy: 0.69\n",
      "Epoch: 2 / Batch: 44288/55000 / Cost: 0.151233 / Training Accuracy: 0.738281 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 44544/55000 / Cost: 0.158577 / Training Accuracy: 0.71875 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 44800/55000 / Cost: 0.144459 / Training Accuracy: 0.738281 / Validation Accuracy: 0.66\n",
      "Epoch: 2 / Batch: 45056/55000 / Cost: 0.155079 / Training Accuracy: 0.6875 / Validation Accuracy: 0.67\n",
      "Epoch: 2 / Batch: 45312/55000 / Cost: 0.14059 / Training Accuracy: 0.769531 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 45568/55000 / Cost: 0.150122 / Training Accuracy: 0.722656 / Validation Accuracy: 0.68\n",
      "Epoch: 2 / Batch: 45824/55000 / Cost: 0.156997 / Training Accuracy: 0.730469 / Validation Accuracy: 0.7\n",
      "Epoch: 2 / Batch: 46080/55000 / Cost: 0.144179 / Training Accuracy: 0.71875 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 46336/55000 / Cost: 0.146997 / Training Accuracy: 0.71875 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 46592/55000 / Cost: 0.166023 / Training Accuracy: 0.707031 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 46848/55000 / Cost: 0.139919 / Training Accuracy: 0.761719 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 47104/55000 / Cost: 0.15245 / Training Accuracy: 0.722656 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 47360/55000 / Cost: 0.159614 / Training Accuracy: 0.730469 / Validation Accuracy: 0.7\n",
      "Epoch: 2 / Batch: 47616/55000 / Cost: 0.144215 / Training Accuracy: 0.742188 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 47872/55000 / Cost: 0.155307 / Training Accuracy: 0.726563 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 48128/55000 / Cost: 0.144253 / Training Accuracy: 0.753906 / Validation Accuracy: 0.76\n",
      "Epoch: 2 / Batch: 48384/55000 / Cost: 0.146264 / Training Accuracy: 0.746094 / Validation Accuracy: 0.77\n",
      "Epoch: 2 / Batch: 48640/55000 / Cost: 0.151866 / Training Accuracy: 0.738281 / Validation Accuracy: 0.77\n",
      "Epoch: 2 / Batch: 48896/55000 / Cost: 0.14479 / Training Accuracy: 0.738281 / Validation Accuracy: 0.74\n",
      "Epoch: 2 / Batch: 49152/55000 / Cost: 0.144965 / Training Accuracy: 0.75 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 49408/55000 / Cost: 0.137255 / Training Accuracy: 0.769531 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 49664/55000 / Cost: 0.141553 / Training Accuracy: 0.8125 / Validation Accuracy: 0.74\n",
      "Epoch: 2 / Batch: 49920/55000 / Cost: 0.143698 / Training Accuracy: 0.734375 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 50176/55000 / Cost: 0.135003 / Training Accuracy: 0.75 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 50432/55000 / Cost: 0.138482 / Training Accuracy: 0.753906 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 50688/55000 / Cost: 0.142463 / Training Accuracy: 0.730469 / Validation Accuracy: 0.71\n",
      "Epoch: 2 / Batch: 50944/55000 / Cost: 0.141328 / Training Accuracy: 0.757813 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 51200/55000 / Cost: 0.132817 / Training Accuracy: 0.753906 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 51456/55000 / Cost: 0.151617 / Training Accuracy: 0.726563 / Validation Accuracy: 0.74\n",
      "Epoch: 2 / Batch: 51712/55000 / Cost: 0.161342 / Training Accuracy: 0.691406 / Validation Accuracy: 0.75\n",
      "Epoch: 2 / Batch: 51968/55000 / Cost: 0.139265 / Training Accuracy: 0.746094 / Validation Accuracy: 0.75\n",
      "Epoch: 2 / Batch: 52224/55000 / Cost: 0.14381 / Training Accuracy: 0.746094 / Validation Accuracy: 0.74\n",
      "Epoch: 2 / Batch: 52480/55000 / Cost: 0.133972 / Training Accuracy: 0.761719 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 52736/55000 / Cost: 0.136007 / Training Accuracy: 0.773438 / Validation Accuracy: 0.75\n",
      "Epoch: 2 / Batch: 52992/55000 / Cost: 0.138902 / Training Accuracy: 0.753906 / Validation Accuracy: 0.76\n",
      "Epoch: 2 / Batch: 53248/55000 / Cost: 0.14763 / Training Accuracy: 0.742188 / Validation Accuracy: 0.75\n",
      "Epoch: 2 / Batch: 53504/55000 / Cost: 0.135182 / Training Accuracy: 0.742188 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 53760/55000 / Cost: 0.143767 / Training Accuracy: 0.738281 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 54016/55000 / Cost: 0.137014 / Training Accuracy: 0.769531 / Validation Accuracy: 0.73\n",
      "Epoch: 2 / Batch: 54272/55000 / Cost: 0.145569 / Training Accuracy: 0.722656 / Validation Accuracy: 0.72\n",
      "Epoch: 2 / Batch: 54528/55000 / Cost: 0.139186 / Training Accuracy: 0.761719 / Validation Accuracy: 0.74\n",
      "Epoch: 2 / Batch: 54784/55000 / Cost: 0.141573 / Training Accuracy: 0.75463 / Validation Accuracy: 0.74\n",
      "Model is saved!!!\n",
      "Epoch: 3 / Batch: 0/55000 / Cost: 0.130821 / Training Accuracy: 0.785156 / Validation Accuracy: 0.73\n",
      "Epoch: 3 / Batch: 256/55000 / Cost: 0.121119 / Training Accuracy: 0.800781 / Validation Accuracy: 0.72\n",
      "Epoch: 3 / Batch: 512/55000 / Cost: 0.134932 / Training Accuracy: 0.765625 / Validation Accuracy: 0.72\n",
      "Epoch: 3 / Batch: 768/55000 / Cost: 0.131173 / Training Accuracy: 0.753906 / Validation Accuracy: 0.73\n",
      "Epoch: 3 / Batch: 1024/55000 / Cost: 0.125016 / Training Accuracy: 0.773438 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 1280/55000 / Cost: 0.143434 / Training Accuracy: 0.742188 / Validation Accuracy: 0.74\n",
      "Epoch: 3 / Batch: 1536/55000 / Cost: 0.147332 / Training Accuracy: 0.695313 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 1792/55000 / Cost: 0.136044 / Training Accuracy: 0.75 / Validation Accuracy: 0.74\n",
      "Epoch: 3 / Batch: 2048/55000 / Cost: 0.131501 / Training Accuracy: 0.738281 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 2304/55000 / Cost: 0.126398 / Training Accuracy: 0.78125 / Validation Accuracy: 0.74\n",
      "Epoch: 3 / Batch: 2560/55000 / Cost: 0.140936 / Training Accuracy: 0.746094 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 2816/55000 / Cost: 0.129796 / Training Accuracy: 0.777344 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 3072/55000 / Cost: 0.128382 / Training Accuracy: 0.761719 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 3328/55000 / Cost: 0.126838 / Training Accuracy: 0.765625 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 3584/55000 / Cost: 0.131765 / Training Accuracy: 0.792969 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 3840/55000 / Cost: 0.142418 / Training Accuracy: 0.746094 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 4096/55000 / Cost: 0.129798 / Training Accuracy: 0.789063 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 4352/55000 / Cost: 0.128872 / Training Accuracy: 0.785156 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 4608/55000 / Cost: 0.132098 / Training Accuracy: 0.777344 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 4864/55000 / Cost: 0.12928 / Training Accuracy: 0.804688 / Validation Accuracy: 0.72\n",
      "Epoch: 3 / Batch: 5120/55000 / Cost: 0.121821 / Training Accuracy: 0.78125 / Validation Accuracy: 0.73\n",
      "Epoch: 3 / Batch: 5376/55000 / Cost: 0.127879 / Training Accuracy: 0.78125 / Validation Accuracy: 0.74\n",
      "Epoch: 3 / Batch: 5632/55000 / Cost: 0.135989 / Training Accuracy: 0.746094 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 5888/55000 / Cost: 0.121802 / Training Accuracy: 0.792969 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 6144/55000 / Cost: 0.146204 / Training Accuracy: 0.703125 / Validation Accuracy: 0.74\n",
      "Epoch: 3 / Batch: 6400/55000 / Cost: 0.128772 / Training Accuracy: 0.773438 / Validation Accuracy: 0.74\n",
      "Epoch: 3 / Batch: 6656/55000 / Cost: 0.116606 / Training Accuracy: 0.804688 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 6912/55000 / Cost: 0.129311 / Training Accuracy: 0.773438 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 7168/55000 / Cost: 0.113173 / Training Accuracy: 0.792969 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 7424/55000 / Cost: 0.139312 / Training Accuracy: 0.730469 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 7680/55000 / Cost: 0.128254 / Training Accuracy: 0.78125 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 7936/55000 / Cost: 0.144749 / Training Accuracy: 0.714844 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 8192/55000 / Cost: 0.131678 / Training Accuracy: 0.761719 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 8448/55000 / Cost: 0.126009 / Training Accuracy: 0.78125 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 8704/55000 / Cost: 0.126944 / Training Accuracy: 0.773438 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 8960/55000 / Cost: 0.145206 / Training Accuracy: 0.6875 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 9216/55000 / Cost: 0.116516 / Training Accuracy: 0.808594 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 9472/55000 / Cost: 0.117151 / Training Accuracy: 0.785156 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 9728/55000 / Cost: 0.113382 / Training Accuracy: 0.796875 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 9984/55000 / Cost: 0.131397 / Training Accuracy: 0.777344 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 10240/55000 / Cost: 0.124971 / Training Accuracy: 0.769531 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 10496/55000 / Cost: 0.12357 / Training Accuracy: 0.777344 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 10752/55000 / Cost: 0.124254 / Training Accuracy: 0.789063 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 11008/55000 / Cost: 0.120607 / Training Accuracy: 0.792969 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 11264/55000 / Cost: 0.116407 / Training Accuracy: 0.832031 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 11520/55000 / Cost: 0.118703 / Training Accuracy: 0.78125 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 11776/55000 / Cost: 0.127949 / Training Accuracy: 0.769531 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 12032/55000 / Cost: 0.118184 / Training Accuracy: 0.789063 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 12288/55000 / Cost: 0.119089 / Training Accuracy: 0.800781 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 12544/55000 / Cost: 0.128452 / Training Accuracy: 0.777344 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 12800/55000 / Cost: 0.123798 / Training Accuracy: 0.789063 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 13056/55000 / Cost: 0.133465 / Training Accuracy: 0.765625 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 13312/55000 / Cost: 0.117761 / Training Accuracy: 0.765625 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 13568/55000 / Cost: 0.132832 / Training Accuracy: 0.753906 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 13824/55000 / Cost: 0.120931 / Training Accuracy: 0.785156 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 14080/55000 / Cost: 0.120211 / Training Accuracy: 0.808594 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 14336/55000 / Cost: 0.122411 / Training Accuracy: 0.789063 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 14592/55000 / Cost: 0.118104 / Training Accuracy: 0.796875 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 14848/55000 / Cost: 0.125447 / Training Accuracy: 0.78125 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 15104/55000 / Cost: 0.132127 / Training Accuracy: 0.789063 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 15360/55000 / Cost: 0.113122 / Training Accuracy: 0.792969 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 15616/55000 / Cost: 0.118493 / Training Accuracy: 0.800781 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 15872/55000 / Cost: 0.116358 / Training Accuracy: 0.796875 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 16128/55000 / Cost: 0.114246 / Training Accuracy: 0.808594 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 16384/55000 / Cost: 0.118573 / Training Accuracy: 0.792969 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 16640/55000 / Cost: 0.119691 / Training Accuracy: 0.757813 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 16896/55000 / Cost: 0.120194 / Training Accuracy: 0.789063 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 17152/55000 / Cost: 0.123499 / Training Accuracy: 0.777344 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 17408/55000 / Cost: 0.112901 / Training Accuracy: 0.808594 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 17664/55000 / Cost: 0.126141 / Training Accuracy: 0.78125 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 17920/55000 / Cost: 0.107363 / Training Accuracy: 0.820313 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 18176/55000 / Cost: 0.105451 / Training Accuracy: 0.808594 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 18432/55000 / Cost: 0.12728 / Training Accuracy: 0.785156 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 18688/55000 / Cost: 0.118767 / Training Accuracy: 0.800781 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 18944/55000 / Cost: 0.109817 / Training Accuracy: 0.816406 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 19200/55000 / Cost: 0.120552 / Training Accuracy: 0.777344 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 19456/55000 / Cost: 0.123198 / Training Accuracy: 0.757813 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 19712/55000 / Cost: 0.122239 / Training Accuracy: 0.78125 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 19968/55000 / Cost: 0.11342 / Training Accuracy: 0.789063 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 20224/55000 / Cost: 0.123462 / Training Accuracy: 0.800781 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 20480/55000 / Cost: 0.111367 / Training Accuracy: 0.808594 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 20736/55000 / Cost: 0.129042 / Training Accuracy: 0.753906 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 20992/55000 / Cost: 0.115995 / Training Accuracy: 0.808594 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 21248/55000 / Cost: 0.129866 / Training Accuracy: 0.75 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 21504/55000 / Cost: 0.125409 / Training Accuracy: 0.78125 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 21760/55000 / Cost: 0.107208 / Training Accuracy: 0.832031 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 22016/55000 / Cost: 0.114721 / Training Accuracy: 0.804688 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 22272/55000 / Cost: 0.113648 / Training Accuracy: 0.78125 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 22528/55000 / Cost: 0.125406 / Training Accuracy: 0.769531 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 22784/55000 / Cost: 0.116978 / Training Accuracy: 0.808594 / Validation Accuracy: 0.74\n",
      "Epoch: 3 / Batch: 23040/55000 / Cost: 0.120162 / Training Accuracy: 0.800781 / Validation Accuracy: 0.73\n",
      "Epoch: 3 / Batch: 23296/55000 / Cost: 0.119517 / Training Accuracy: 0.808594 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 23552/55000 / Cost: 0.123786 / Training Accuracy: 0.792969 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 23808/55000 / Cost: 0.125162 / Training Accuracy: 0.765625 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 24064/55000 / Cost: 0.106652 / Training Accuracy: 0.839844 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 24320/55000 / Cost: 0.110874 / Training Accuracy: 0.820313 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 24576/55000 / Cost: 0.108281 / Training Accuracy: 0.824219 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 24832/55000 / Cost: 0.118663 / Training Accuracy: 0.792969 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 25088/55000 / Cost: 0.104286 / Training Accuracy: 0.839844 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 25344/55000 / Cost: 0.129436 / Training Accuracy: 0.789063 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 25600/55000 / Cost: 0.104107 / Training Accuracy: 0.820313 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 25856/55000 / Cost: 0.116134 / Training Accuracy: 0.796875 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 26112/55000 / Cost: 0.112981 / Training Accuracy: 0.828125 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 26368/55000 / Cost: 0.110488 / Training Accuracy: 0.824219 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 26624/55000 / Cost: 0.116411 / Training Accuracy: 0.808594 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 26880/55000 / Cost: 0.113148 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 27136/55000 / Cost: 0.108564 / Training Accuracy: 0.824219 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 27392/55000 / Cost: 0.117316 / Training Accuracy: 0.78125 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 27648/55000 / Cost: 0.118997 / Training Accuracy: 0.785156 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 27904/55000 / Cost: 0.108427 / Training Accuracy: 0.824219 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 28160/55000 / Cost: 0.110221 / Training Accuracy: 0.785156 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 28416/55000 / Cost: 0.115409 / Training Accuracy: 0.820313 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 28672/55000 / Cost: 0.113243 / Training Accuracy: 0.816406 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 28928/55000 / Cost: 0.106573 / Training Accuracy: 0.792969 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 29184/55000 / Cost: 0.114936 / Training Accuracy: 0.816406 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 29440/55000 / Cost: 0.114973 / Training Accuracy: 0.816406 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 29696/55000 / Cost: 0.119654 / Training Accuracy: 0.78125 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 29952/55000 / Cost: 0.116382 / Training Accuracy: 0.761719 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 30208/55000 / Cost: 0.0980453 / Training Accuracy: 0.847656 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 30464/55000 / Cost: 0.100896 / Training Accuracy: 0.828125 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 30720/55000 / Cost: 0.111176 / Training Accuracy: 0.765625 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 30976/55000 / Cost: 0.12002 / Training Accuracy: 0.792969 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 31232/55000 / Cost: 0.120558 / Training Accuracy: 0.777344 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 31488/55000 / Cost: 0.10244 / Training Accuracy: 0.820313 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 31744/55000 / Cost: 0.108094 / Training Accuracy: 0.816406 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 32000/55000 / Cost: 0.115246 / Training Accuracy: 0.800781 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 32256/55000 / Cost: 0.108309 / Training Accuracy: 0.804688 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 32512/55000 / Cost: 0.103069 / Training Accuracy: 0.828125 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 32768/55000 / Cost: 0.116354 / Training Accuracy: 0.777344 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 33024/55000 / Cost: 0.112419 / Training Accuracy: 0.804688 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 33280/55000 / Cost: 0.115104 / Training Accuracy: 0.804688 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 33536/55000 / Cost: 0.106732 / Training Accuracy: 0.8125 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 33792/55000 / Cost: 0.125074 / Training Accuracy: 0.753906 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 34048/55000 / Cost: 0.120146 / Training Accuracy: 0.792969 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 34304/55000 / Cost: 0.101633 / Training Accuracy: 0.824219 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 34560/55000 / Cost: 0.106301 / Training Accuracy: 0.84375 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 34816/55000 / Cost: 0.121818 / Training Accuracy: 0.796875 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 35072/55000 / Cost: 0.12169 / Training Accuracy: 0.769531 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 35328/55000 / Cost: 0.119488 / Training Accuracy: 0.800781 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 35584/55000 / Cost: 0.112093 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 35840/55000 / Cost: 0.0897246 / Training Accuracy: 0.839844 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 36096/55000 / Cost: 0.110197 / Training Accuracy: 0.78125 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 36352/55000 / Cost: 0.114932 / Training Accuracy: 0.800781 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 36608/55000 / Cost: 0.109696 / Training Accuracy: 0.824219 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 36864/55000 / Cost: 0.10312 / Training Accuracy: 0.820313 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 37120/55000 / Cost: 0.110075 / Training Accuracy: 0.808594 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 37376/55000 / Cost: 0.107316 / Training Accuracy: 0.804688 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 37632/55000 / Cost: 0.114991 / Training Accuracy: 0.804688 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 37888/55000 / Cost: 0.103341 / Training Accuracy: 0.84375 / Validation Accuracy: 0.75\n",
      "Epoch: 3 / Batch: 38144/55000 / Cost: 0.110468 / Training Accuracy: 0.828125 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 38400/55000 / Cost: 0.0973292 / Training Accuracy: 0.835938 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 38656/55000 / Cost: 0.116754 / Training Accuracy: 0.789063 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 38912/55000 / Cost: 0.113477 / Training Accuracy: 0.777344 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 39168/55000 / Cost: 0.0988199 / Training Accuracy: 0.839844 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 39424/55000 / Cost: 0.0932574 / Training Accuracy: 0.839844 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 39680/55000 / Cost: 0.0953304 / Training Accuracy: 0.832031 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 39936/55000 / Cost: 0.115242 / Training Accuracy: 0.78125 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 40192/55000 / Cost: 0.106088 / Training Accuracy: 0.796875 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 40448/55000 / Cost: 0.119461 / Training Accuracy: 0.796875 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 40704/55000 / Cost: 0.116543 / Training Accuracy: 0.792969 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 40960/55000 / Cost: 0.0982584 / Training Accuracy: 0.851563 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 41216/55000 / Cost: 0.107409 / Training Accuracy: 0.808594 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 41472/55000 / Cost: 0.10825 / Training Accuracy: 0.804688 / Validation Accuracy: 0.78\n",
      "Epoch: 3 / Batch: 41728/55000 / Cost: 0.104834 / Training Accuracy: 0.820313 / Validation Accuracy: 0.77\n",
      "Epoch: 3 / Batch: 41984/55000 / Cost: 0.105321 / Training Accuracy: 0.835938 / Validation Accuracy: 0.76\n",
      "Epoch: 3 / Batch: 42240/55000 / Cost: 0.106017 / Training Accuracy: 0.816406 / Validation Accuracy: 0.79\n",
      "Epoch: 3 / Batch: 42496/55000 / Cost: 0.110612 / Training Accuracy: 0.78125 / Validation Accuracy: 0.85\n",
      "Epoch: 3 / Batch: 42752/55000 / Cost: 0.104844 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 3 / Batch: 43008/55000 / Cost: 0.0927934 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 3 / Batch: 43264/55000 / Cost: 0.113759 / Training Accuracy: 0.796875 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 43520/55000 / Cost: 0.116129 / Training Accuracy: 0.773438 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 43776/55000 / Cost: 0.105202 / Training Accuracy: 0.839844 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 44032/55000 / Cost: 0.106644 / Training Accuracy: 0.816406 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 44288/55000 / Cost: 0.111411 / Training Accuracy: 0.800781 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 44544/55000 / Cost: 0.0992191 / Training Accuracy: 0.8125 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 44800/55000 / Cost: 0.0894387 / Training Accuracy: 0.851563 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 45056/55000 / Cost: 0.105892 / Training Accuracy: 0.804688 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 45312/55000 / Cost: 0.109588 / Training Accuracy: 0.796875 / Validation Accuracy: 0.84\n",
      "Epoch: 3 / Batch: 45568/55000 / Cost: 0.116047 / Training Accuracy: 0.796875 / Validation Accuracy: 0.85\n",
      "Epoch: 3 / Batch: 45824/55000 / Cost: 0.113547 / Training Accuracy: 0.789063 / Validation Accuracy: 0.85\n",
      "Epoch: 3 / Batch: 46080/55000 / Cost: 0.0970245 / Training Accuracy: 0.839844 / Validation Accuracy: 0.84\n",
      "Epoch: 3 / Batch: 46336/55000 / Cost: 0.0964841 / Training Accuracy: 0.84375 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 46592/55000 / Cost: 0.101537 / Training Accuracy: 0.828125 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 46848/55000 / Cost: 0.099736 / Training Accuracy: 0.828125 / Validation Accuracy: 0.86\n",
      "Epoch: 3 / Batch: 47104/55000 / Cost: 0.0982007 / Training Accuracy: 0.816406 / Validation Accuracy: 0.84\n",
      "Epoch: 3 / Batch: 47360/55000 / Cost: 0.0889041 / Training Accuracy: 0.839844 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 47616/55000 / Cost: 0.108133 / Training Accuracy: 0.816406 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 47872/55000 / Cost: 0.101093 / Training Accuracy: 0.804688 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 48128/55000 / Cost: 0.111906 / Training Accuracy: 0.808594 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 48384/55000 / Cost: 0.096655 / Training Accuracy: 0.828125 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 48640/55000 / Cost: 0.0998206 / Training Accuracy: 0.832031 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 48896/55000 / Cost: 0.107413 / Training Accuracy: 0.8125 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 49152/55000 / Cost: 0.0877255 / Training Accuracy: 0.867188 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 49408/55000 / Cost: 0.09692 / Training Accuracy: 0.84375 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 49664/55000 / Cost: 0.108624 / Training Accuracy: 0.800781 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 49920/55000 / Cost: 0.0948083 / Training Accuracy: 0.859375 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 50176/55000 / Cost: 0.104378 / Training Accuracy: 0.808594 / Validation Accuracy: 0.87\n",
      "Epoch: 3 / Batch: 50432/55000 / Cost: 0.09773 / Training Accuracy: 0.847656 / Validation Accuracy: 0.87\n",
      "Epoch: 3 / Batch: 50688/55000 / Cost: 0.096519 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 3 / Batch: 50944/55000 / Cost: 0.0911529 / Training Accuracy: 0.863281 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 51200/55000 / Cost: 0.115768 / Training Accuracy: 0.789063 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 51456/55000 / Cost: 0.0989567 / Training Accuracy: 0.8125 / Validation Accuracy: 0.8\n",
      "Epoch: 3 / Batch: 51712/55000 / Cost: 0.10927 / Training Accuracy: 0.796875 / Validation Accuracy: 0.81\n",
      "Epoch: 3 / Batch: 51968/55000 / Cost: 0.0989204 / Training Accuracy: 0.839844 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 52224/55000 / Cost: 0.105913 / Training Accuracy: 0.816406 / Validation Accuracy: 0.84\n",
      "Epoch: 3 / Batch: 52480/55000 / Cost: 0.10104 / Training Accuracy: 0.8125 / Validation Accuracy: 0.85\n",
      "Epoch: 3 / Batch: 52736/55000 / Cost: 0.0967101 / Training Accuracy: 0.824219 / Validation Accuracy: 0.86\n",
      "Epoch: 3 / Batch: 52992/55000 / Cost: 0.104101 / Training Accuracy: 0.832031 / Validation Accuracy: 0.84\n",
      "Epoch: 3 / Batch: 53248/55000 / Cost: 0.112135 / Training Accuracy: 0.800781 / Validation Accuracy: 0.84\n",
      "Epoch: 3 / Batch: 53504/55000 / Cost: 0.106547 / Training Accuracy: 0.8125 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 53760/55000 / Cost: 0.109323 / Training Accuracy: 0.8125 / Validation Accuracy: 0.83\n",
      "Epoch: 3 / Batch: 54016/55000 / Cost: 0.0855777 / Training Accuracy: 0.863281 / Validation Accuracy: 0.85\n",
      "Epoch: 3 / Batch: 54272/55000 / Cost: 0.108362 / Training Accuracy: 0.800781 / Validation Accuracy: 0.87\n",
      "Epoch: 3 / Batch: 54528/55000 / Cost: 0.114076 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 3 / Batch: 54784/55000 / Cost: 0.0847533 / Training Accuracy: 0.856482 / Validation Accuracy: 0.82\n",
      "Model is saved!!!\n",
      "Epoch: 4 / Batch: 0/55000 / Cost: 0.0961113 / Training Accuracy: 0.828125 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 256/55000 / Cost: 0.0885306 / Training Accuracy: 0.851563 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 512/55000 / Cost: 0.0974657 / Training Accuracy: 0.820313 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 768/55000 / Cost: 0.0935458 / Training Accuracy: 0.855469 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 1024/55000 / Cost: 0.0837259 / Training Accuracy: 0.894531 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 1280/55000 / Cost: 0.0962713 / Training Accuracy: 0.816406 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 1536/55000 / Cost: 0.111918 / Training Accuracy: 0.808594 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 1792/55000 / Cost: 0.103391 / Training Accuracy: 0.816406 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 2048/55000 / Cost: 0.096674 / Training Accuracy: 0.832031 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 2304/55000 / Cost: 0.0947285 / Training Accuracy: 0.847656 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 2560/55000 / Cost: 0.0996435 / Training Accuracy: 0.851563 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 2816/55000 / Cost: 0.096495 / Training Accuracy: 0.8125 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 3072/55000 / Cost: 0.0797241 / Training Accuracy: 0.863281 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 3328/55000 / Cost: 0.0953758 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 3584/55000 / Cost: 0.0833565 / Training Accuracy: 0.863281 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 3840/55000 / Cost: 0.0906714 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 4096/55000 / Cost: 0.0892515 / Training Accuracy: 0.847656 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 4352/55000 / Cost: 0.100167 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 4608/55000 / Cost: 0.0951673 / Training Accuracy: 0.828125 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 4864/55000 / Cost: 0.0979642 / Training Accuracy: 0.835938 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 5120/55000 / Cost: 0.0949796 / Training Accuracy: 0.839844 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 5376/55000 / Cost: 0.0961681 / Training Accuracy: 0.839844 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 5632/55000 / Cost: 0.0922489 / Training Accuracy: 0.847656 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 5888/55000 / Cost: 0.0788341 / Training Accuracy: 0.867188 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 6144/55000 / Cost: 0.101001 / Training Accuracy: 0.808594 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 6400/55000 / Cost: 0.0931526 / Training Accuracy: 0.835938 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 6656/55000 / Cost: 0.0994081 / Training Accuracy: 0.835938 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 6912/55000 / Cost: 0.102365 / Training Accuracy: 0.824219 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 7168/55000 / Cost: 0.104762 / Training Accuracy: 0.800781 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 7424/55000 / Cost: 0.098266 / Training Accuracy: 0.816406 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 7680/55000 / Cost: 0.103954 / Training Accuracy: 0.796875 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 7936/55000 / Cost: 0.103121 / Training Accuracy: 0.785156 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 8192/55000 / Cost: 0.0928079 / Training Accuracy: 0.824219 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 8448/55000 / Cost: 0.0845742 / Training Accuracy: 0.851563 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 8704/55000 / Cost: 0.10429 / Training Accuracy: 0.816406 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 8960/55000 / Cost: 0.106603 / Training Accuracy: 0.824219 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 9216/55000 / Cost: 0.0993379 / Training Accuracy: 0.839844 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 9472/55000 / Cost: 0.0918987 / Training Accuracy: 0.832031 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 9728/55000 / Cost: 0.111736 / Training Accuracy: 0.777344 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 9984/55000 / Cost: 0.0881767 / Training Accuracy: 0.863281 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 10240/55000 / Cost: 0.0901328 / Training Accuracy: 0.84375 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 10496/55000 / Cost: 0.0825961 / Training Accuracy: 0.859375 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 10752/55000 / Cost: 0.0875409 / Training Accuracy: 0.867188 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 11008/55000 / Cost: 0.103017 / Training Accuracy: 0.828125 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 11264/55000 / Cost: 0.102457 / Training Accuracy: 0.789063 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 11520/55000 / Cost: 0.0858815 / Training Accuracy: 0.867188 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 11776/55000 / Cost: 0.0973243 / Training Accuracy: 0.8125 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 12032/55000 / Cost: 0.0771936 / Training Accuracy: 0.90625 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 12288/55000 / Cost: 0.100716 / Training Accuracy: 0.804688 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 12544/55000 / Cost: 0.103001 / Training Accuracy: 0.804688 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 12800/55000 / Cost: 0.107732 / Training Accuracy: 0.804688 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 13056/55000 / Cost: 0.0872562 / Training Accuracy: 0.878906 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 13312/55000 / Cost: 0.0870937 / Training Accuracy: 0.84375 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 13568/55000 / Cost: 0.0852325 / Training Accuracy: 0.859375 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 13824/55000 / Cost: 0.0945082 / Training Accuracy: 0.839844 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 14080/55000 / Cost: 0.11259 / Training Accuracy: 0.78125 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 14336/55000 / Cost: 0.0925735 / Training Accuracy: 0.832031 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 14592/55000 / Cost: 0.0960015 / Training Accuracy: 0.8125 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 14848/55000 / Cost: 0.0877624 / Training Accuracy: 0.871094 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 15104/55000 / Cost: 0.0901138 / Training Accuracy: 0.816406 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 15360/55000 / Cost: 0.099598 / Training Accuracy: 0.816406 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 15616/55000 / Cost: 0.097463 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 15872/55000 / Cost: 0.0777579 / Training Accuracy: 0.882813 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 16128/55000 / Cost: 0.0862103 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 16384/55000 / Cost: 0.0882257 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 16640/55000 / Cost: 0.111168 / Training Accuracy: 0.785156 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 16896/55000 / Cost: 0.0841805 / Training Accuracy: 0.863281 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 17152/55000 / Cost: 0.089402 / Training Accuracy: 0.851563 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 17408/55000 / Cost: 0.098269 / Training Accuracy: 0.820313 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 17664/55000 / Cost: 0.0895361 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 17920/55000 / Cost: 0.0865398 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 18176/55000 / Cost: 0.0804057 / Training Accuracy: 0.863281 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 18432/55000 / Cost: 0.0958575 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 18688/55000 / Cost: 0.0851179 / Training Accuracy: 0.851563 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 18944/55000 / Cost: 0.0842964 / Training Accuracy: 0.863281 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 19200/55000 / Cost: 0.0949216 / Training Accuracy: 0.832031 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 19456/55000 / Cost: 0.0723999 / Training Accuracy: 0.886719 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 19712/55000 / Cost: 0.0992578 / Training Accuracy: 0.8125 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 19968/55000 / Cost: 0.092285 / Training Accuracy: 0.820313 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 20224/55000 / Cost: 0.10042 / Training Accuracy: 0.808594 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 20480/55000 / Cost: 0.0862474 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 20736/55000 / Cost: 0.101571 / Training Accuracy: 0.8125 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 20992/55000 / Cost: 0.101604 / Training Accuracy: 0.800781 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 21248/55000 / Cost: 0.0912547 / Training Accuracy: 0.84375 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 21504/55000 / Cost: 0.0946999 / Training Accuracy: 0.824219 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 21760/55000 / Cost: 0.0869543 / Training Accuracy: 0.84375 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 22016/55000 / Cost: 0.0809932 / Training Accuracy: 0.871094 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 22272/55000 / Cost: 0.0893891 / Training Accuracy: 0.859375 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 22528/55000 / Cost: 0.0858717 / Training Accuracy: 0.867188 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 22784/55000 / Cost: 0.0911821 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 23040/55000 / Cost: 0.0941496 / Training Accuracy: 0.835938 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 23296/55000 / Cost: 0.0812125 / Training Accuracy: 0.839844 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 23552/55000 / Cost: 0.0886619 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 23808/55000 / Cost: 0.0932527 / Training Accuracy: 0.855469 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 24064/55000 / Cost: 0.0888687 / Training Accuracy: 0.820313 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 24320/55000 / Cost: 0.0962209 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 24576/55000 / Cost: 0.0962149 / Training Accuracy: 0.820313 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 24832/55000 / Cost: 0.0920602 / Training Accuracy: 0.847656 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 25088/55000 / Cost: 0.0908531 / Training Accuracy: 0.828125 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 25344/55000 / Cost: 0.101553 / Training Accuracy: 0.824219 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 25600/55000 / Cost: 0.0933749 / Training Accuracy: 0.816406 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 25856/55000 / Cost: 0.110742 / Training Accuracy: 0.785156 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 26112/55000 / Cost: 0.0756599 / Training Accuracy: 0.894531 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 26368/55000 / Cost: 0.0936553 / Training Accuracy: 0.820313 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 26624/55000 / Cost: 0.103534 / Training Accuracy: 0.808594 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 26880/55000 / Cost: 0.103767 / Training Accuracy: 0.804688 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 27136/55000 / Cost: 0.0782719 / Training Accuracy: 0.871094 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 27392/55000 / Cost: 0.0769845 / Training Accuracy: 0.882813 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 27648/55000 / Cost: 0.0717921 / Training Accuracy: 0.898438 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 27904/55000 / Cost: 0.08196 / Training Accuracy: 0.851563 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 28160/55000 / Cost: 0.0983397 / Training Accuracy: 0.8125 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 28416/55000 / Cost: 0.0932918 / Training Accuracy: 0.835938 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 28672/55000 / Cost: 0.0962635 / Training Accuracy: 0.839844 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 28928/55000 / Cost: 0.0923308 / Training Accuracy: 0.835938 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 29184/55000 / Cost: 0.0827821 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 29440/55000 / Cost: 0.0887165 / Training Accuracy: 0.859375 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 29696/55000 / Cost: 0.0862173 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 29952/55000 / Cost: 0.0839892 / Training Accuracy: 0.867188 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 30208/55000 / Cost: 0.101631 / Training Accuracy: 0.804688 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 30464/55000 / Cost: 0.109527 / Training Accuracy: 0.796875 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 30720/55000 / Cost: 0.0826941 / Training Accuracy: 0.847656 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 30976/55000 / Cost: 0.0929045 / Training Accuracy: 0.824219 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 31232/55000 / Cost: 0.0933803 / Training Accuracy: 0.816406 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 31488/55000 / Cost: 0.0865184 / Training Accuracy: 0.859375 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 31744/55000 / Cost: 0.0788421 / Training Accuracy: 0.855469 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 32000/55000 / Cost: 0.0814398 / Training Accuracy: 0.84375 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 32256/55000 / Cost: 0.0911191 / Training Accuracy: 0.847656 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 32512/55000 / Cost: 0.0805382 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 32768/55000 / Cost: 0.0802008 / Training Accuracy: 0.882813 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 33024/55000 / Cost: 0.082719 / Training Accuracy: 0.84375 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 33280/55000 / Cost: 0.0792245 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 33536/55000 / Cost: 0.0856533 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 33792/55000 / Cost: 0.0833816 / Training Accuracy: 0.839844 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 34048/55000 / Cost: 0.088826 / Training Accuracy: 0.835938 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 34304/55000 / Cost: 0.09732 / Training Accuracy: 0.816406 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 34560/55000 / Cost: 0.0804025 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 34816/55000 / Cost: 0.0917448 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 35072/55000 / Cost: 0.086869 / Training Accuracy: 0.84375 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 35328/55000 / Cost: 0.0920784 / Training Accuracy: 0.824219 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 35584/55000 / Cost: 0.0867153 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 35840/55000 / Cost: 0.0835008 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 36096/55000 / Cost: 0.0842493 / Training Accuracy: 0.851563 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 36352/55000 / Cost: 0.0938005 / Training Accuracy: 0.835938 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 36608/55000 / Cost: 0.0910651 / Training Accuracy: 0.839844 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 36864/55000 / Cost: 0.0851344 / Training Accuracy: 0.851563 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 37120/55000 / Cost: 0.0949645 / Training Accuracy: 0.84375 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 37376/55000 / Cost: 0.0770977 / Training Accuracy: 0.878906 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 37632/55000 / Cost: 0.0801434 / Training Accuracy: 0.855469 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 37888/55000 / Cost: 0.0844674 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 38144/55000 / Cost: 0.0894337 / Training Accuracy: 0.851563 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 38400/55000 / Cost: 0.0949141 / Training Accuracy: 0.800781 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 38656/55000 / Cost: 0.0817775 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 38912/55000 / Cost: 0.103424 / Training Accuracy: 0.808594 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 39168/55000 / Cost: 0.0911091 / Training Accuracy: 0.847656 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 39424/55000 / Cost: 0.0908145 / Training Accuracy: 0.824219 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 39680/55000 / Cost: 0.0788718 / Training Accuracy: 0.867188 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 39936/55000 / Cost: 0.0836698 / Training Accuracy: 0.855469 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 40192/55000 / Cost: 0.0977722 / Training Accuracy: 0.832031 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 40448/55000 / Cost: 0.0831696 / Training Accuracy: 0.863281 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 40704/55000 / Cost: 0.087482 / Training Accuracy: 0.839844 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 40960/55000 / Cost: 0.0856029 / Training Accuracy: 0.855469 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 41216/55000 / Cost: 0.0793578 / Training Accuracy: 0.851563 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 41472/55000 / Cost: 0.0767124 / Training Accuracy: 0.863281 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 41728/55000 / Cost: 0.077743 / Training Accuracy: 0.875 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 41984/55000 / Cost: 0.0915752 / Training Accuracy: 0.820313 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 42240/55000 / Cost: 0.0879327 / Training Accuracy: 0.835938 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 42496/55000 / Cost: 0.0998 / Training Accuracy: 0.8125 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 42752/55000 / Cost: 0.0787814 / Training Accuracy: 0.863281 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 43008/55000 / Cost: 0.0958961 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 43264/55000 / Cost: 0.0957881 / Training Accuracy: 0.835938 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 43520/55000 / Cost: 0.0807723 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 43776/55000 / Cost: 0.0804573 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 44032/55000 / Cost: 0.0846167 / Training Accuracy: 0.824219 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 44288/55000 / Cost: 0.0799019 / Training Accuracy: 0.871094 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 44544/55000 / Cost: 0.091975 / Training Accuracy: 0.835938 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 44800/55000 / Cost: 0.0885371 / Training Accuracy: 0.859375 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 45056/55000 / Cost: 0.0976022 / Training Accuracy: 0.816406 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 45312/55000 / Cost: 0.081433 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 45568/55000 / Cost: 0.0895038 / Training Accuracy: 0.828125 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 45824/55000 / Cost: 0.0877456 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 46080/55000 / Cost: 0.0748682 / Training Accuracy: 0.878906 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 46336/55000 / Cost: 0.0844494 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 46592/55000 / Cost: 0.0801552 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 46848/55000 / Cost: 0.0918654 / Training Accuracy: 0.835938 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 47104/55000 / Cost: 0.0848651 / Training Accuracy: 0.824219 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 47360/55000 / Cost: 0.0898441 / Training Accuracy: 0.839844 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 47616/55000 / Cost: 0.0840645 / Training Accuracy: 0.859375 / Validation Accuracy: 0.84\n",
      "Epoch: 4 / Batch: 47872/55000 / Cost: 0.0995846 / Training Accuracy: 0.828125 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 48128/55000 / Cost: 0.0847608 / Training Accuracy: 0.847656 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 48384/55000 / Cost: 0.0857746 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 48640/55000 / Cost: 0.0865327 / Training Accuracy: 0.835938 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 48896/55000 / Cost: 0.0884579 / Training Accuracy: 0.839844 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 49152/55000 / Cost: 0.0801519 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 49408/55000 / Cost: 0.0834725 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 49664/55000 / Cost: 0.0875141 / Training Accuracy: 0.84375 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 49920/55000 / Cost: 0.0861421 / Training Accuracy: 0.835938 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 50176/55000 / Cost: 0.0807927 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 50432/55000 / Cost: 0.0760233 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 50688/55000 / Cost: 0.0812037 / Training Accuracy: 0.84375 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 50944/55000 / Cost: 0.0788163 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 4 / Batch: 51200/55000 / Cost: 0.0899994 / Training Accuracy: 0.828125 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 51456/55000 / Cost: 0.0817043 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 51712/55000 / Cost: 0.0931868 / Training Accuracy: 0.84375 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 51968/55000 / Cost: 0.0891193 / Training Accuracy: 0.835938 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 52224/55000 / Cost: 0.0786791 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 52480/55000 / Cost: 0.0772126 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 52736/55000 / Cost: 0.0738046 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 52992/55000 / Cost: 0.0864783 / Training Accuracy: 0.84375 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 53248/55000 / Cost: 0.093309 / Training Accuracy: 0.847656 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 53504/55000 / Cost: 0.0854426 / Training Accuracy: 0.824219 / Validation Accuracy: 0.86\n",
      "Epoch: 4 / Batch: 53760/55000 / Cost: 0.0827086 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 4 / Batch: 54016/55000 / Cost: 0.0817736 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 4 / Batch: 54272/55000 / Cost: 0.0931125 / Training Accuracy: 0.835938 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 54528/55000 / Cost: 0.077323 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 4 / Batch: 54784/55000 / Cost: 0.0844173 / Training Accuracy: 0.842593 / Validation Accuracy: 0.87\n",
      "Model is saved!!!\n",
      "Epoch: 5 / Batch: 0/55000 / Cost: 0.073726 / Training Accuracy: 0.890625 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 256/55000 / Cost: 0.0676491 / Training Accuracy: 0.890625 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 512/55000 / Cost: 0.0802668 / Training Accuracy: 0.847656 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 768/55000 / Cost: 0.0784589 / Training Accuracy: 0.851563 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 1024/55000 / Cost: 0.0914181 / Training Accuracy: 0.847656 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 1280/55000 / Cost: 0.081448 / Training Accuracy: 0.867188 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 1536/55000 / Cost: 0.0763829 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 1792/55000 / Cost: 0.0748385 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 2048/55000 / Cost: 0.0843606 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 2304/55000 / Cost: 0.089629 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 2560/55000 / Cost: 0.0773154 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 2816/55000 / Cost: 0.0826605 / Training Accuracy: 0.867188 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 3072/55000 / Cost: 0.0809775 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 3328/55000 / Cost: 0.08199 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 3584/55000 / Cost: 0.0737128 / Training Accuracy: 0.882813 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 3840/55000 / Cost: 0.0730586 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 4096/55000 / Cost: 0.0896933 / Training Accuracy: 0.820313 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 4352/55000 / Cost: 0.0810376 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 4608/55000 / Cost: 0.0771185 / Training Accuracy: 0.855469 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 4864/55000 / Cost: 0.0770485 / Training Accuracy: 0.835938 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 5120/55000 / Cost: 0.0789991 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 5376/55000 / Cost: 0.0714247 / Training Accuracy: 0.871094 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 5632/55000 / Cost: 0.0715207 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 5888/55000 / Cost: 0.0764693 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 6144/55000 / Cost: 0.0738494 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 6400/55000 / Cost: 0.0796077 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 6656/55000 / Cost: 0.0717429 / Training Accuracy: 0.867188 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 6912/55000 / Cost: 0.0783631 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 7168/55000 / Cost: 0.0811608 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 7424/55000 / Cost: 0.0753094 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 7680/55000 / Cost: 0.0788754 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 7936/55000 / Cost: 0.0768091 / Training Accuracy: 0.851563 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 8192/55000 / Cost: 0.0721732 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 8448/55000 / Cost: 0.0688441 / Training Accuracy: 0.871094 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 8704/55000 / Cost: 0.0725064 / Training Accuracy: 0.851563 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 8960/55000 / Cost: 0.0748856 / Training Accuracy: 0.859375 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 9216/55000 / Cost: 0.0743185 / Training Accuracy: 0.875 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 9472/55000 / Cost: 0.0864206 / Training Accuracy: 0.839844 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 9728/55000 / Cost: 0.0694158 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 9984/55000 / Cost: 0.0774443 / Training Accuracy: 0.855469 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 10240/55000 / Cost: 0.0703799 / Training Accuracy: 0.871094 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 10496/55000 / Cost: 0.0684126 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 10752/55000 / Cost: 0.0813681 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 11008/55000 / Cost: 0.0899902 / Training Accuracy: 0.832031 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 11264/55000 / Cost: 0.0791406 / Training Accuracy: 0.851563 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 11520/55000 / Cost: 0.0760762 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 11776/55000 / Cost: 0.0957783 / Training Accuracy: 0.824219 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 12032/55000 / Cost: 0.0849762 / Training Accuracy: 0.839844 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 12288/55000 / Cost: 0.08268 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 12544/55000 / Cost: 0.0775274 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 12800/55000 / Cost: 0.0765344 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 13056/55000 / Cost: 0.0816785 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 13312/55000 / Cost: 0.0799063 / Training Accuracy: 0.835938 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 13568/55000 / Cost: 0.084751 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 13824/55000 / Cost: 0.0754913 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 14080/55000 / Cost: 0.0701913 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 14336/55000 / Cost: 0.0743327 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 14592/55000 / Cost: 0.0685517 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 14848/55000 / Cost: 0.069349 / Training Accuracy: 0.878906 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 15104/55000 / Cost: 0.0788661 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 15360/55000 / Cost: 0.0865287 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 15616/55000 / Cost: 0.0732224 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 15872/55000 / Cost: 0.07152 / Training Accuracy: 0.867188 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 16128/55000 / Cost: 0.0807819 / Training Accuracy: 0.859375 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 16384/55000 / Cost: 0.0919853 / Training Accuracy: 0.828125 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 16640/55000 / Cost: 0.0783045 / Training Accuracy: 0.851563 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 16896/55000 / Cost: 0.0856104 / Training Accuracy: 0.839844 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 17152/55000 / Cost: 0.0788417 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 17408/55000 / Cost: 0.0738904 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 17664/55000 / Cost: 0.065703 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 17920/55000 / Cost: 0.0819566 / Training Accuracy: 0.835938 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 18176/55000 / Cost: 0.0935717 / Training Accuracy: 0.820313 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 18432/55000 / Cost: 0.071825 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 18688/55000 / Cost: 0.084628 / Training Accuracy: 0.847656 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 18944/55000 / Cost: 0.0778377 / Training Accuracy: 0.859375 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 19200/55000 / Cost: 0.0786458 / Training Accuracy: 0.84375 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 19456/55000 / Cost: 0.063909 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 19712/55000 / Cost: 0.0710479 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 19968/55000 / Cost: 0.0671518 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 20224/55000 / Cost: 0.0712846 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 20480/55000 / Cost: 0.0769279 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 20736/55000 / Cost: 0.0718873 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 20992/55000 / Cost: 0.0769847 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 21248/55000 / Cost: 0.0901408 / Training Accuracy: 0.828125 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 21504/55000 / Cost: 0.0721406 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 21760/55000 / Cost: 0.0724835 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 22016/55000 / Cost: 0.0760435 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 22272/55000 / Cost: 0.0746887 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 22528/55000 / Cost: 0.0786964 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 22784/55000 / Cost: 0.083349 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 23040/55000 / Cost: 0.0711952 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 23296/55000 / Cost: 0.0806314 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 23552/55000 / Cost: 0.0763829 / Training Accuracy: 0.84375 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 23808/55000 / Cost: 0.0691051 / Training Accuracy: 0.863281 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 24064/55000 / Cost: 0.0798809 / Training Accuracy: 0.871094 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 24320/55000 / Cost: 0.0752285 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 24576/55000 / Cost: 0.0901967 / Training Accuracy: 0.839844 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 24832/55000 / Cost: 0.0735934 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 25088/55000 / Cost: 0.095177 / Training Accuracy: 0.84375 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 25344/55000 / Cost: 0.0715019 / Training Accuracy: 0.894531 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 25600/55000 / Cost: 0.0735569 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 25856/55000 / Cost: 0.0660492 / Training Accuracy: 0.902344 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 26112/55000 / Cost: 0.0673989 / Training Accuracy: 0.882813 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 26368/55000 / Cost: 0.0728515 / Training Accuracy: 0.882813 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 26624/55000 / Cost: 0.0838097 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 26880/55000 / Cost: 0.0845565 / Training Accuracy: 0.84375 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 27136/55000 / Cost: 0.0892067 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 27392/55000 / Cost: 0.0811676 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 27648/55000 / Cost: 0.0756933 / Training Accuracy: 0.890625 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 27904/55000 / Cost: 0.0795031 / Training Accuracy: 0.882813 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 28160/55000 / Cost: 0.073579 / Training Accuracy: 0.851563 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 28416/55000 / Cost: 0.076328 / Training Accuracy: 0.839844 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 28672/55000 / Cost: 0.0802695 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 28928/55000 / Cost: 0.0825714 / Training Accuracy: 0.835938 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 29184/55000 / Cost: 0.0777564 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 29440/55000 / Cost: 0.069508 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 29696/55000 / Cost: 0.0787566 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 29952/55000 / Cost: 0.0841933 / Training Accuracy: 0.84375 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 30208/55000 / Cost: 0.0844728 / Training Accuracy: 0.851563 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 30464/55000 / Cost: 0.0660957 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 30720/55000 / Cost: 0.0631684 / Training Accuracy: 0.910156 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 30976/55000 / Cost: 0.0767151 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 31232/55000 / Cost: 0.0833126 / Training Accuracy: 0.820313 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 31488/55000 / Cost: 0.0784843 / Training Accuracy: 0.84375 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 31744/55000 / Cost: 0.0766822 / Training Accuracy: 0.847656 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 32000/55000 / Cost: 0.0890764 / Training Accuracy: 0.871094 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 32256/55000 / Cost: 0.0904751 / Training Accuracy: 0.816406 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 32512/55000 / Cost: 0.066592 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 32768/55000 / Cost: 0.0857005 / Training Accuracy: 0.808594 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 33024/55000 / Cost: 0.0768075 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 33280/55000 / Cost: 0.077978 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 33536/55000 / Cost: 0.0842101 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 33792/55000 / Cost: 0.0837616 / Training Accuracy: 0.835938 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 34048/55000 / Cost: 0.0714246 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 34304/55000 / Cost: 0.0906268 / Training Accuracy: 0.84375 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 34560/55000 / Cost: 0.0891766 / Training Accuracy: 0.824219 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 34816/55000 / Cost: 0.0753597 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 35072/55000 / Cost: 0.0660691 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 35328/55000 / Cost: 0.0914543 / Training Accuracy: 0.855469 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 35584/55000 / Cost: 0.0822543 / Training Accuracy: 0.84375 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 35840/55000 / Cost: 0.0722564 / Training Accuracy: 0.882813 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 36096/55000 / Cost: 0.0813902 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 36352/55000 / Cost: 0.0741379 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 36608/55000 / Cost: 0.0758618 / Training Accuracy: 0.835938 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 36864/55000 / Cost: 0.0709882 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 37120/55000 / Cost: 0.076785 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 37376/55000 / Cost: 0.0802516 / Training Accuracy: 0.84375 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 37632/55000 / Cost: 0.0852119 / Training Accuracy: 0.828125 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 37888/55000 / Cost: 0.0689537 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 38144/55000 / Cost: 0.080308 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 38400/55000 / Cost: 0.0647751 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 38656/55000 / Cost: 0.0874436 / Training Accuracy: 0.839844 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 38912/55000 / Cost: 0.0627683 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 39168/55000 / Cost: 0.067201 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 39424/55000 / Cost: 0.0872779 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 39680/55000 / Cost: 0.0719137 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 39936/55000 / Cost: 0.078519 / Training Accuracy: 0.84375 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 40192/55000 / Cost: 0.0609987 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 40448/55000 / Cost: 0.0833833 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 40704/55000 / Cost: 0.074979 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 40960/55000 / Cost: 0.0834527 / Training Accuracy: 0.84375 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 41216/55000 / Cost: 0.0696874 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 41472/55000 / Cost: 0.0799944 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 41728/55000 / Cost: 0.0836892 / Training Accuracy: 0.828125 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 41984/55000 / Cost: 0.0663086 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 42240/55000 / Cost: 0.0854443 / Training Accuracy: 0.828125 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 42496/55000 / Cost: 0.0614055 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 42752/55000 / Cost: 0.089223 / Training Accuracy: 0.824219 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 43008/55000 / Cost: 0.0698131 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 43264/55000 / Cost: 0.0686484 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 43520/55000 / Cost: 0.0646514 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 43776/55000 / Cost: 0.0678043 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 44032/55000 / Cost: 0.0731736 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 44288/55000 / Cost: 0.068648 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 44544/55000 / Cost: 0.0695608 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 44800/55000 / Cost: 0.0704826 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 45056/55000 / Cost: 0.0723593 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 45312/55000 / Cost: 0.073905 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 45568/55000 / Cost: 0.0617313 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 45824/55000 / Cost: 0.0920599 / Training Accuracy: 0.824219 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 46080/55000 / Cost: 0.0774283 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 46336/55000 / Cost: 0.0818222 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 46592/55000 / Cost: 0.0780869 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 46848/55000 / Cost: 0.0918465 / Training Accuracy: 0.828125 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 47104/55000 / Cost: 0.0738348 / Training Accuracy: 0.847656 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 47360/55000 / Cost: 0.0763148 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 47616/55000 / Cost: 0.0716693 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 47872/55000 / Cost: 0.0550731 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 48128/55000 / Cost: 0.0782347 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 48384/55000 / Cost: 0.0774522 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 48640/55000 / Cost: 0.0776197 / Training Accuracy: 0.855469 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 48896/55000 / Cost: 0.0783955 / Training Accuracy: 0.851563 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 49152/55000 / Cost: 0.0877694 / Training Accuracy: 0.828125 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 49408/55000 / Cost: 0.0833481 / Training Accuracy: 0.863281 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 49664/55000 / Cost: 0.0703846 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 49920/55000 / Cost: 0.0784281 / Training Accuracy: 0.863281 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 50176/55000 / Cost: 0.0869071 / Training Accuracy: 0.847656 / Validation Accuracy: 0.92\n",
      "Epoch: 5 / Batch: 50432/55000 / Cost: 0.0804778 / Training Accuracy: 0.851563 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 50688/55000 / Cost: 0.0723867 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 50944/55000 / Cost: 0.0724086 / Training Accuracy: 0.855469 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 51200/55000 / Cost: 0.0771111 / Training Accuracy: 0.839844 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 51456/55000 / Cost: 0.0784891 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 51712/55000 / Cost: 0.077159 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 51968/55000 / Cost: 0.0749322 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 52224/55000 / Cost: 0.0676808 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 52480/55000 / Cost: 0.0699487 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 52736/55000 / Cost: 0.073272 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 52992/55000 / Cost: 0.072039 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 53248/55000 / Cost: 0.0693105 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 53504/55000 / Cost: 0.080898 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 53760/55000 / Cost: 0.075272 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 54016/55000 / Cost: 0.0671716 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 54272/55000 / Cost: 0.0627168 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 54528/55000 / Cost: 0.0698 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 54784/55000 / Cost: 0.076871 / Training Accuracy: 0.865741 / Validation Accuracy: 0.89\n",
      "Model is saved!!!\n",
      "Epoch: 6 / Batch: 0/55000 / Cost: 0.0606891 / Training Accuracy: 0.882813 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 256/55000 / Cost: 0.0746643 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 512/55000 / Cost: 0.066464 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 768/55000 / Cost: 0.0784784 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 1024/55000 / Cost: 0.0694532 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 1280/55000 / Cost: 0.0696109 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 1536/55000 / Cost: 0.0656341 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 1792/55000 / Cost: 0.0664687 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 2048/55000 / Cost: 0.0646636 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 2304/55000 / Cost: 0.0885177 / Training Accuracy: 0.835938 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 2560/55000 / Cost: 0.0692996 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 2816/55000 / Cost: 0.0751635 / Training Accuracy: 0.847656 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 3072/55000 / Cost: 0.0717908 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 3328/55000 / Cost: 0.0694596 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 3584/55000 / Cost: 0.0760377 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 3840/55000 / Cost: 0.077837 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 4096/55000 / Cost: 0.0722715 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 4352/55000 / Cost: 0.0707148 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 4608/55000 / Cost: 0.0773071 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 4864/55000 / Cost: 0.0749919 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 5120/55000 / Cost: 0.0723397 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 5376/55000 / Cost: 0.0733485 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 5632/55000 / Cost: 0.083445 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 5888/55000 / Cost: 0.0645205 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 6144/55000 / Cost: 0.0584376 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 6400/55000 / Cost: 0.0554452 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 6656/55000 / Cost: 0.0756196 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 6912/55000 / Cost: 0.0764766 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 7168/55000 / Cost: 0.0741506 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 7424/55000 / Cost: 0.0718983 / Training Accuracy: 0.894531 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 7680/55000 / Cost: 0.0571832 / Training Accuracy: 0.933594 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 7936/55000 / Cost: 0.0821927 / Training Accuracy: 0.863281 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 8192/55000 / Cost: 0.0722811 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 8448/55000 / Cost: 0.0674394 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 8704/55000 / Cost: 0.0670038 / Training Accuracy: 0.894531 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 8960/55000 / Cost: 0.0694185 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 9216/55000 / Cost: 0.0877866 / Training Accuracy: 0.808594 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 9472/55000 / Cost: 0.0594932 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 9728/55000 / Cost: 0.0739269 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 9984/55000 / Cost: 0.0631237 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 10240/55000 / Cost: 0.0630044 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 10496/55000 / Cost: 0.073374 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 10752/55000 / Cost: 0.0727723 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 11008/55000 / Cost: 0.0677721 / Training Accuracy: 0.882813 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 11264/55000 / Cost: 0.0765951 / Training Accuracy: 0.871094 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 11520/55000 / Cost: 0.069322 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 11776/55000 / Cost: 0.0759278 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 12032/55000 / Cost: 0.062579 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 12288/55000 / Cost: 0.0673841 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 12544/55000 / Cost: 0.060123 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 12800/55000 / Cost: 0.0656887 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 13056/55000 / Cost: 0.0630568 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 13312/55000 / Cost: 0.0561024 / Training Accuracy: 0.933594 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 13568/55000 / Cost: 0.074508 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 13824/55000 / Cost: 0.0678588 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 14080/55000 / Cost: 0.0688684 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 14336/55000 / Cost: 0.0704062 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 14592/55000 / Cost: 0.06969 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 14848/55000 / Cost: 0.0586723 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 15104/55000 / Cost: 0.0690374 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 15360/55000 / Cost: 0.0715657 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 15616/55000 / Cost: 0.0665921 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 15872/55000 / Cost: 0.0673584 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 16128/55000 / Cost: 0.0721304 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 16384/55000 / Cost: 0.0643084 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 16640/55000 / Cost: 0.0608959 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 16896/55000 / Cost: 0.0830659 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 17152/55000 / Cost: 0.0659751 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 17408/55000 / Cost: 0.0637953 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 17664/55000 / Cost: 0.0637296 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 17920/55000 / Cost: 0.0802713 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 18176/55000 / Cost: 0.0691266 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 18432/55000 / Cost: 0.0782695 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 18688/55000 / Cost: 0.0680545 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 18944/55000 / Cost: 0.0777634 / Training Accuracy: 0.851563 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 19200/55000 / Cost: 0.0777528 / Training Accuracy: 0.851563 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 19456/55000 / Cost: 0.0765887 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 19712/55000 / Cost: 0.0652327 / Training Accuracy: 0.910156 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 19968/55000 / Cost: 0.0733315 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 20224/55000 / Cost: 0.0696846 / Training Accuracy: 0.871094 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 20480/55000 / Cost: 0.0651632 / Training Accuracy: 0.894531 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 20736/55000 / Cost: 0.0882676 / Training Accuracy: 0.816406 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 20992/55000 / Cost: 0.0591051 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 21248/55000 / Cost: 0.0683486 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 21504/55000 / Cost: 0.0750974 / Training Accuracy: 0.851563 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 21760/55000 / Cost: 0.0661399 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 22016/55000 / Cost: 0.065922 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 22272/55000 / Cost: 0.0770061 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 22528/55000 / Cost: 0.0650615 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 22784/55000 / Cost: 0.0601131 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 23040/55000 / Cost: 0.0593247 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 23296/55000 / Cost: 0.0807626 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 23552/55000 / Cost: 0.0740779 / Training Accuracy: 0.871094 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 23808/55000 / Cost: 0.0659644 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 24064/55000 / Cost: 0.0673096 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 24320/55000 / Cost: 0.0744335 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 24576/55000 / Cost: 0.0685567 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 24832/55000 / Cost: 0.0723099 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 25088/55000 / Cost: 0.0587389 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 25344/55000 / Cost: 0.0724421 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 25600/55000 / Cost: 0.0627655 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 25856/55000 / Cost: 0.061584 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 26112/55000 / Cost: 0.0686404 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 26368/55000 / Cost: 0.0686415 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 26624/55000 / Cost: 0.0702297 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 26880/55000 / Cost: 0.0612095 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 27136/55000 / Cost: 0.0690883 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 27392/55000 / Cost: 0.0728588 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 27648/55000 / Cost: 0.060343 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 27904/55000 / Cost: 0.075427 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 28160/55000 / Cost: 0.0724448 / Training Accuracy: 0.863281 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 28416/55000 / Cost: 0.0780396 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 28672/55000 / Cost: 0.0660835 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 28928/55000 / Cost: 0.0628585 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 29184/55000 / Cost: 0.07462 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 29440/55000 / Cost: 0.0760547 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 29696/55000 / Cost: 0.0614453 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 29952/55000 / Cost: 0.0672618 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 30208/55000 / Cost: 0.0538406 / Training Accuracy: 0.90625 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 30464/55000 / Cost: 0.0664148 / Training Accuracy: 0.875 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 30720/55000 / Cost: 0.068969 / Training Accuracy: 0.863281 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 30976/55000 / Cost: 0.0622048 / Training Accuracy: 0.894531 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 31232/55000 / Cost: 0.0696157 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 31488/55000 / Cost: 0.0610992 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 31744/55000 / Cost: 0.0694741 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 32000/55000 / Cost: 0.0619415 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 32256/55000 / Cost: 0.0579315 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 32512/55000 / Cost: 0.0660193 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 32768/55000 / Cost: 0.070098 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 33024/55000 / Cost: 0.067205 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 33280/55000 / Cost: 0.0778036 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 33536/55000 / Cost: 0.0789701 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 33792/55000 / Cost: 0.0831738 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 34048/55000 / Cost: 0.0633842 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 34304/55000 / Cost: 0.0718751 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 34560/55000 / Cost: 0.0698393 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 34816/55000 / Cost: 0.0652783 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 35072/55000 / Cost: 0.0654814 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 35328/55000 / Cost: 0.061801 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 35584/55000 / Cost: 0.0734383 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 35840/55000 / Cost: 0.0593837 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 36096/55000 / Cost: 0.0641529 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 36352/55000 / Cost: 0.0602863 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 36608/55000 / Cost: 0.079267 / Training Accuracy: 0.851563 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 36864/55000 / Cost: 0.0735276 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 37120/55000 / Cost: 0.065151 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 37376/55000 / Cost: 0.0647588 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 37632/55000 / Cost: 0.0805655 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 37888/55000 / Cost: 0.0697741 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 38144/55000 / Cost: 0.0647002 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 38400/55000 / Cost: 0.0793472 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 38656/55000 / Cost: 0.0632934 / Training Accuracy: 0.894531 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 38912/55000 / Cost: 0.0600348 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 39168/55000 / Cost: 0.0651382 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 39424/55000 / Cost: 0.0647564 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 39680/55000 / Cost: 0.0537409 / Training Accuracy: 0.902344 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 39936/55000 / Cost: 0.0701051 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 40192/55000 / Cost: 0.0734193 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 40448/55000 / Cost: 0.0581745 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 40704/55000 / Cost: 0.0811073 / Training Accuracy: 0.839844 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 40960/55000 / Cost: 0.0534355 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 41216/55000 / Cost: 0.0732149 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 41472/55000 / Cost: 0.0690686 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 41728/55000 / Cost: 0.0685593 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 41984/55000 / Cost: 0.056075 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 42240/55000 / Cost: 0.0655754 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 42496/55000 / Cost: 0.0629314 / Training Accuracy: 0.882813 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 42752/55000 / Cost: 0.0656865 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 43008/55000 / Cost: 0.0636936 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 43264/55000 / Cost: 0.0769572 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 43520/55000 / Cost: 0.0651949 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 43776/55000 / Cost: 0.0598707 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 44032/55000 / Cost: 0.0743525 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 44288/55000 / Cost: 0.0658094 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 44544/55000 / Cost: 0.0645906 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 44800/55000 / Cost: 0.0753704 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 45056/55000 / Cost: 0.0658171 / Training Accuracy: 0.867188 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 45312/55000 / Cost: 0.0783371 / Training Accuracy: 0.835938 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 45568/55000 / Cost: 0.0768482 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 45824/55000 / Cost: 0.0649805 / Training Accuracy: 0.882813 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 46080/55000 / Cost: 0.0719002 / Training Accuracy: 0.859375 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 46336/55000 / Cost: 0.0690073 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 46592/55000 / Cost: 0.0755398 / Training Accuracy: 0.84375 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 46848/55000 / Cost: 0.0720726 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 47104/55000 / Cost: 0.0629643 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 47360/55000 / Cost: 0.0703886 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 47616/55000 / Cost: 0.0566411 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 47872/55000 / Cost: 0.0740737 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 48128/55000 / Cost: 0.0677042 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 48384/55000 / Cost: 0.0639144 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 48640/55000 / Cost: 0.0807744 / Training Accuracy: 0.832031 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 48896/55000 / Cost: 0.0492424 / Training Accuracy: 0.933594 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 49152/55000 / Cost: 0.0623797 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 49408/55000 / Cost: 0.057328 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 49664/55000 / Cost: 0.0700321 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 49920/55000 / Cost: 0.0648621 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 50176/55000 / Cost: 0.0714137 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 50432/55000 / Cost: 0.0725463 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 50688/55000 / Cost: 0.0668173 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 50944/55000 / Cost: 0.0744579 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 51200/55000 / Cost: 0.0595674 / Training Accuracy: 0.917969 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 51456/55000 / Cost: 0.0648447 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 51712/55000 / Cost: 0.0658838 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 51968/55000 / Cost: 0.0741826 / Training Accuracy: 0.882813 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 52224/55000 / Cost: 0.0659887 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 52480/55000 / Cost: 0.0686065 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 52736/55000 / Cost: 0.0566361 / Training Accuracy: 0.902344 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 52992/55000 / Cost: 0.0581815 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 53248/55000 / Cost: 0.0760783 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 53504/55000 / Cost: 0.0732809 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 53760/55000 / Cost: 0.0692923 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 54016/55000 / Cost: 0.0691635 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 54272/55000 / Cost: 0.0566808 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 54528/55000 / Cost: 0.0890182 / Training Accuracy: 0.832031 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 54784/55000 / Cost: 0.0851256 / Training Accuracy: 0.842593 / Validation Accuracy: 0.92\n",
      "Model is saved!!!\n",
      "Epoch: 7 / Batch: 0/55000 / Cost: 0.0607441 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 256/55000 / Cost: 0.0715059 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 512/55000 / Cost: 0.0645137 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 768/55000 / Cost: 0.0690913 / Training Accuracy: 0.875 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 1024/55000 / Cost: 0.0754054 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 1280/55000 / Cost: 0.0519424 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 1536/55000 / Cost: 0.0540055 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 1792/55000 / Cost: 0.0609633 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 2048/55000 / Cost: 0.0585509 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 2304/55000 / Cost: 0.0626742 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 2560/55000 / Cost: 0.0548523 / Training Accuracy: 0.921875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 2816/55000 / Cost: 0.0555333 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 3072/55000 / Cost: 0.068369 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 3328/55000 / Cost: 0.0663269 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 3584/55000 / Cost: 0.0601312 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 3840/55000 / Cost: 0.0525561 / Training Accuracy: 0.917969 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 4096/55000 / Cost: 0.0680485 / Training Accuracy: 0.851563 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 4352/55000 / Cost: 0.066451 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 4608/55000 / Cost: 0.0506925 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 4864/55000 / Cost: 0.0534074 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 5120/55000 / Cost: 0.0552688 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 5376/55000 / Cost: 0.0611222 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 5632/55000 / Cost: 0.0713521 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 5888/55000 / Cost: 0.0544122 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 6144/55000 / Cost: 0.0643441 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 6400/55000 / Cost: 0.0629668 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 6656/55000 / Cost: 0.0581175 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 6912/55000 / Cost: 0.0707808 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 7168/55000 / Cost: 0.066974 / Training Accuracy: 0.882813 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 7424/55000 / Cost: 0.0667279 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 7680/55000 / Cost: 0.051842 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 7936/55000 / Cost: 0.0708487 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 8192/55000 / Cost: 0.0726743 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 8448/55000 / Cost: 0.0716371 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 8704/55000 / Cost: 0.0687736 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 8960/55000 / Cost: 0.0581506 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 9216/55000 / Cost: 0.0645342 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 9472/55000 / Cost: 0.0605489 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 9728/55000 / Cost: 0.0646878 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 9984/55000 / Cost: 0.0751422 / Training Accuracy: 0.859375 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 10240/55000 / Cost: 0.0707269 / Training Accuracy: 0.855469 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 10496/55000 / Cost: 0.0545108 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 10752/55000 / Cost: 0.0666747 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 11008/55000 / Cost: 0.0627203 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 11264/55000 / Cost: 0.0634852 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 11520/55000 / Cost: 0.0524155 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 11776/55000 / Cost: 0.0543553 / Training Accuracy: 0.917969 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 12032/55000 / Cost: 0.062143 / Training Accuracy: 0.890625 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 12288/55000 / Cost: 0.0526744 / Training Accuracy: 0.921875 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 12544/55000 / Cost: 0.0640386 / Training Accuracy: 0.882813 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 12800/55000 / Cost: 0.0717107 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 13056/55000 / Cost: 0.0695572 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 13312/55000 / Cost: 0.0568127 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 13568/55000 / Cost: 0.0608297 / Training Accuracy: 0.886719 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 13824/55000 / Cost: 0.0778224 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 14080/55000 / Cost: 0.0571658 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 14336/55000 / Cost: 0.065724 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 14592/55000 / Cost: 0.0668725 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 14848/55000 / Cost: 0.0577222 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 15104/55000 / Cost: 0.0559558 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 15360/55000 / Cost: 0.0627406 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 15616/55000 / Cost: 0.0698686 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 15872/55000 / Cost: 0.0758472 / Training Accuracy: 0.875 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 16128/55000 / Cost: 0.0610976 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 16384/55000 / Cost: 0.0672756 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 16640/55000 / Cost: 0.0566912 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 16896/55000 / Cost: 0.0682875 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 17152/55000 / Cost: 0.0666022 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 17408/55000 / Cost: 0.0758633 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 17664/55000 / Cost: 0.0527665 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 17920/55000 / Cost: 0.0632074 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 18176/55000 / Cost: 0.0668012 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 18432/55000 / Cost: 0.0530158 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 18688/55000 / Cost: 0.0674656 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 18944/55000 / Cost: 0.065627 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 19200/55000 / Cost: 0.0659798 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 19456/55000 / Cost: 0.0532823 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 19712/55000 / Cost: 0.0691622 / Training Accuracy: 0.855469 / Validation Accuracy: 0.85\n",
      "Epoch: 7 / Batch: 19968/55000 / Cost: 0.0659158 / Training Accuracy: 0.898438 / Validation Accuracy: 0.85\n",
      "Epoch: 7 / Batch: 20224/55000 / Cost: 0.0658952 / Training Accuracy: 0.90625 / Validation Accuracy: 0.85\n",
      "Epoch: 7 / Batch: 20480/55000 / Cost: 0.0550132 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 20736/55000 / Cost: 0.0538017 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 20992/55000 / Cost: 0.0690963 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 21248/55000 / Cost: 0.0496791 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 21504/55000 / Cost: 0.0617468 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 21760/55000 / Cost: 0.0669464 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 22016/55000 / Cost: 0.0705036 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 22272/55000 / Cost: 0.0758753 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 22528/55000 / Cost: 0.0555282 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 22784/55000 / Cost: 0.0688264 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 23040/55000 / Cost: 0.0608958 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 23296/55000 / Cost: 0.0730126 / Training Accuracy: 0.863281 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 23552/55000 / Cost: 0.069212 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 23808/55000 / Cost: 0.0871347 / Training Accuracy: 0.847656 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 24064/55000 / Cost: 0.0638116 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 24320/55000 / Cost: 0.0503268 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 24576/55000 / Cost: 0.0656941 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 24832/55000 / Cost: 0.0614939 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 25088/55000 / Cost: 0.0704982 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 25344/55000 / Cost: 0.0587436 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 25600/55000 / Cost: 0.0717475 / Training Accuracy: 0.839844 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 25856/55000 / Cost: 0.0558873 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 26112/55000 / Cost: 0.0609116 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 26368/55000 / Cost: 0.0550578 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 26624/55000 / Cost: 0.0533277 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 26880/55000 / Cost: 0.0577852 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 27136/55000 / Cost: 0.066847 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 27392/55000 / Cost: 0.0618288 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 27648/55000 / Cost: 0.0550933 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 27904/55000 / Cost: 0.0697832 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 28160/55000 / Cost: 0.0686441 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 28416/55000 / Cost: 0.0627285 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 28672/55000 / Cost: 0.0626107 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 28928/55000 / Cost: 0.0556184 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 29184/55000 / Cost: 0.0628398 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 29440/55000 / Cost: 0.0557895 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 29696/55000 / Cost: 0.0575427 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 29952/55000 / Cost: 0.0731452 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 30208/55000 / Cost: 0.0646432 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 30464/55000 / Cost: 0.0641727 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 30720/55000 / Cost: 0.0628318 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 30976/55000 / Cost: 0.0574406 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 31232/55000 / Cost: 0.0700865 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 31488/55000 / Cost: 0.0710972 / Training Accuracy: 0.867188 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 31744/55000 / Cost: 0.0687673 / Training Accuracy: 0.867188 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 32000/55000 / Cost: 0.0668559 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 32256/55000 / Cost: 0.0508709 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 32512/55000 / Cost: 0.062467 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 32768/55000 / Cost: 0.0617654 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 33024/55000 / Cost: 0.0662641 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 33280/55000 / Cost: 0.0648601 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 33536/55000 / Cost: 0.0547171 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 33792/55000 / Cost: 0.0540379 / Training Accuracy: 0.921875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 34048/55000 / Cost: 0.0675413 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 34304/55000 / Cost: 0.0678558 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 34560/55000 / Cost: 0.0711081 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 34816/55000 / Cost: 0.0780404 / Training Accuracy: 0.851563 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 35072/55000 / Cost: 0.0656547 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 35328/55000 / Cost: 0.062772 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 35584/55000 / Cost: 0.068099 / Training Accuracy: 0.875 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 35840/55000 / Cost: 0.0494379 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 36096/55000 / Cost: 0.0613209 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 36352/55000 / Cost: 0.057686 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 36608/55000 / Cost: 0.0718528 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 36864/55000 / Cost: 0.0661513 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 37120/55000 / Cost: 0.0631052 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 37376/55000 / Cost: 0.0466872 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 37632/55000 / Cost: 0.0671764 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 37888/55000 / Cost: 0.0646974 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 38144/55000 / Cost: 0.0726172 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 38400/55000 / Cost: 0.0677339 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 38656/55000 / Cost: 0.0568989 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 38912/55000 / Cost: 0.0617516 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 39168/55000 / Cost: 0.0626826 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 39424/55000 / Cost: 0.0537883 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 39680/55000 / Cost: 0.0622282 / Training Accuracy: 0.890625 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 39936/55000 / Cost: 0.0671117 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 40192/55000 / Cost: 0.0671497 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 40448/55000 / Cost: 0.0542374 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 40704/55000 / Cost: 0.0645031 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 40960/55000 / Cost: 0.0537558 / Training Accuracy: 0.914063 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 41216/55000 / Cost: 0.0537266 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 41472/55000 / Cost: 0.0595768 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 41728/55000 / Cost: 0.0634841 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 41984/55000 / Cost: 0.0719517 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 42240/55000 / Cost: 0.0548191 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 42496/55000 / Cost: 0.0537092 / Training Accuracy: 0.921875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 42752/55000 / Cost: 0.0632787 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 43008/55000 / Cost: 0.0572196 / Training Accuracy: 0.914063 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 43264/55000 / Cost: 0.0675603 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 43520/55000 / Cost: 0.0642448 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 43776/55000 / Cost: 0.0655214 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 44032/55000 / Cost: 0.0559423 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 44288/55000 / Cost: 0.0613051 / Training Accuracy: 0.890625 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 44544/55000 / Cost: 0.0651979 / Training Accuracy: 0.882813 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 44800/55000 / Cost: 0.07493 / Training Accuracy: 0.855469 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 45056/55000 / Cost: 0.0520887 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 45312/55000 / Cost: 0.0571975 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 45568/55000 / Cost: 0.0612016 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 45824/55000 / Cost: 0.060273 / Training Accuracy: 0.925781 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 46080/55000 / Cost: 0.0560298 / Training Accuracy: 0.890625 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 46336/55000 / Cost: 0.0616229 / Training Accuracy: 0.898438 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 46592/55000 / Cost: 0.0616787 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 46848/55000 / Cost: 0.0723135 / Training Accuracy: 0.882813 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 47104/55000 / Cost: 0.0572452 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 47360/55000 / Cost: 0.0662926 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 47616/55000 / Cost: 0.0581514 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 47872/55000 / Cost: 0.0734011 / Training Accuracy: 0.882813 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 48128/55000 / Cost: 0.0642434 / Training Accuracy: 0.871094 / Validation Accuracy: 0.85\n",
      "Epoch: 7 / Batch: 48384/55000 / Cost: 0.0571678 / Training Accuracy: 0.910156 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 48640/55000 / Cost: 0.0632809 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 48896/55000 / Cost: 0.0632625 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 49152/55000 / Cost: 0.0566723 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 49408/55000 / Cost: 0.0566728 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 49664/55000 / Cost: 0.0643931 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 49920/55000 / Cost: 0.0606258 / Training Accuracy: 0.90625 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 50176/55000 / Cost: 0.0603856 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 50432/55000 / Cost: 0.0556567 / Training Accuracy: 0.898438 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 50688/55000 / Cost: 0.0550957 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 50944/55000 / Cost: 0.0673562 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 51200/55000 / Cost: 0.0611911 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 51456/55000 / Cost: 0.0639092 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 51712/55000 / Cost: 0.0650715 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 51968/55000 / Cost: 0.0669649 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 52224/55000 / Cost: 0.0831867 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 52480/55000 / Cost: 0.0621321 / Training Accuracy: 0.875 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 52736/55000 / Cost: 0.0483363 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 52992/55000 / Cost: 0.0662617 / Training Accuracy: 0.878906 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 53248/55000 / Cost: 0.0642899 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 53504/55000 / Cost: 0.0585039 / Training Accuracy: 0.882813 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 53760/55000 / Cost: 0.0592104 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 54016/55000 / Cost: 0.0647152 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 54272/55000 / Cost: 0.0676021 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 54528/55000 / Cost: 0.0713059 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 54784/55000 / Cost: 0.0621247 / Training Accuracy: 0.87037 / Validation Accuracy: 0.92\n",
      "Model is saved!!!\n",
      "Epoch: 8 / Batch: 0/55000 / Cost: 0.0528168 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 256/55000 / Cost: 0.0630306 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 512/55000 / Cost: 0.0592514 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 768/55000 / Cost: 0.0469615 / Training Accuracy: 0.9375 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 1024/55000 / Cost: 0.0567526 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 1280/55000 / Cost: 0.0454477 / Training Accuracy: 0.941406 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 1536/55000 / Cost: 0.0686574 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 1792/55000 / Cost: 0.0504618 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 2048/55000 / Cost: 0.055287 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 2304/55000 / Cost: 0.0585331 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 2560/55000 / Cost: 0.0526113 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 2816/55000 / Cost: 0.0554001 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 3072/55000 / Cost: 0.0652833 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 3328/55000 / Cost: 0.0545823 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 3584/55000 / Cost: 0.0612192 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 3840/55000 / Cost: 0.0586079 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 4096/55000 / Cost: 0.0631848 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 4352/55000 / Cost: 0.0474886 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 4608/55000 / Cost: 0.0542257 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 4864/55000 / Cost: 0.0562986 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 5120/55000 / Cost: 0.0558802 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 5376/55000 / Cost: 0.0559093 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 5632/55000 / Cost: 0.0561848 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 5888/55000 / Cost: 0.0535713 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 6144/55000 / Cost: 0.0520282 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 6400/55000 / Cost: 0.0688329 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 6656/55000 / Cost: 0.054427 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 6912/55000 / Cost: 0.0564081 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 7168/55000 / Cost: 0.0620501 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 7424/55000 / Cost: 0.0497998 / Training Accuracy: 0.925781 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 7680/55000 / Cost: 0.0716035 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 7936/55000 / Cost: 0.0570491 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 8192/55000 / Cost: 0.058263 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 8448/55000 / Cost: 0.0490595 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 8704/55000 / Cost: 0.0704053 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 8960/55000 / Cost: 0.0561793 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 9216/55000 / Cost: 0.0587583 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 9472/55000 / Cost: 0.061071 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 9728/55000 / Cost: 0.0595903 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 9984/55000 / Cost: 0.0573736 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 10240/55000 / Cost: 0.0486968 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 10496/55000 / Cost: 0.066607 / Training Accuracy: 0.871094 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 10752/55000 / Cost: 0.056955 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 11008/55000 / Cost: 0.0671282 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 11264/55000 / Cost: 0.0650542 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 11520/55000 / Cost: 0.0448659 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 11776/55000 / Cost: 0.0612734 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 12032/55000 / Cost: 0.0516689 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 12288/55000 / Cost: 0.050638 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 12544/55000 / Cost: 0.061822 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 12800/55000 / Cost: 0.0536275 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 13056/55000 / Cost: 0.0493428 / Training Accuracy: 0.925781 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 13312/55000 / Cost: 0.0607406 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 13568/55000 / Cost: 0.0592693 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 13824/55000 / Cost: 0.0523872 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 14080/55000 / Cost: 0.0768754 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 14336/55000 / Cost: 0.0434502 / Training Accuracy: 0.929688 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 14592/55000 / Cost: 0.0729354 / Training Accuracy: 0.84375 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 14848/55000 / Cost: 0.0518876 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 15104/55000 / Cost: 0.0710628 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 15360/55000 / Cost: 0.0535974 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 15616/55000 / Cost: 0.0447984 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 15872/55000 / Cost: 0.0652115 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 16128/55000 / Cost: 0.0590427 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 16384/55000 / Cost: 0.0491875 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 16640/55000 / Cost: 0.0528492 / Training Accuracy: 0.902344 / Validation Accuracy: 0.86\n",
      "Epoch: 8 / Batch: 16896/55000 / Cost: 0.0563709 / Training Accuracy: 0.910156 / Validation Accuracy: 0.85\n",
      "Epoch: 8 / Batch: 17152/55000 / Cost: 0.0583604 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 17408/55000 / Cost: 0.0709547 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 17664/55000 / Cost: 0.0475523 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 17920/55000 / Cost: 0.0653991 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 18176/55000 / Cost: 0.0504024 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 18432/55000 / Cost: 0.0612047 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 18688/55000 / Cost: 0.0659199 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 18944/55000 / Cost: 0.0729434 / Training Accuracy: 0.851563 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 19200/55000 / Cost: 0.0516441 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 19456/55000 / Cost: 0.0683708 / Training Accuracy: 0.882813 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 19712/55000 / Cost: 0.0604423 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 19968/55000 / Cost: 0.0472385 / Training Accuracy: 0.921875 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 20224/55000 / Cost: 0.0584184 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 20480/55000 / Cost: 0.051983 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 20736/55000 / Cost: 0.0595178 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 20992/55000 / Cost: 0.050642 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 21248/55000 / Cost: 0.0681424 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 21504/55000 / Cost: 0.0519556 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 21760/55000 / Cost: 0.0653104 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 22016/55000 / Cost: 0.0457617 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 22272/55000 / Cost: 0.057163 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 22528/55000 / Cost: 0.0566954 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 22784/55000 / Cost: 0.0618521 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 23040/55000 / Cost: 0.0567821 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 23296/55000 / Cost: 0.0474242 / Training Accuracy: 0.933594 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 23552/55000 / Cost: 0.0601257 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 23808/55000 / Cost: 0.0677493 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 24064/55000 / Cost: 0.0454685 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 24320/55000 / Cost: 0.0556512 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 24576/55000 / Cost: 0.0545022 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 24832/55000 / Cost: 0.0464164 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 25088/55000 / Cost: 0.0586491 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 25344/55000 / Cost: 0.0648281 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 25600/55000 / Cost: 0.055868 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 25856/55000 / Cost: 0.0606624 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 26112/55000 / Cost: 0.0645096 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 26368/55000 / Cost: 0.0621916 / Training Accuracy: 0.882813 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 26624/55000 / Cost: 0.0502424 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 26880/55000 / Cost: 0.0505088 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 27136/55000 / Cost: 0.0650347 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 27392/55000 / Cost: 0.0627115 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 27648/55000 / Cost: 0.0602152 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 27904/55000 / Cost: 0.0532826 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 28160/55000 / Cost: 0.053636 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 28416/55000 / Cost: 0.0626508 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 28672/55000 / Cost: 0.0521681 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 28928/55000 / Cost: 0.0601197 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 29184/55000 / Cost: 0.0650642 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 8 / Batch: 29440/55000 / Cost: 0.0599626 / Training Accuracy: 0.878906 / Validation Accuracy: 0.85\n",
      "Epoch: 8 / Batch: 29696/55000 / Cost: 0.0513947 / Training Accuracy: 0.917969 / Validation Accuracy: 0.86\n",
      "Epoch: 8 / Batch: 29952/55000 / Cost: 0.0801158 / Training Accuracy: 0.855469 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 30208/55000 / Cost: 0.0520093 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 30464/55000 / Cost: 0.0536735 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 30720/55000 / Cost: 0.0608428 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 30976/55000 / Cost: 0.0499387 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 31232/55000 / Cost: 0.0587475 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 31488/55000 / Cost: 0.0515571 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 31744/55000 / Cost: 0.0645862 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 32000/55000 / Cost: 0.0653195 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 32256/55000 / Cost: 0.0597787 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 32512/55000 / Cost: 0.056484 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 32768/55000 / Cost: 0.0491908 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 33024/55000 / Cost: 0.0695249 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 33280/55000 / Cost: 0.058412 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 33536/55000 / Cost: 0.0462742 / Training Accuracy: 0.929688 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 33792/55000 / Cost: 0.0567459 / Training Accuracy: 0.914063 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 34048/55000 / Cost: 0.0479051 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 34304/55000 / Cost: 0.0613014 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 34560/55000 / Cost: 0.0594169 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 34816/55000 / Cost: 0.0623253 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 35072/55000 / Cost: 0.0592517 / Training Accuracy: 0.90625 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 35328/55000 / Cost: 0.0587458 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 35584/55000 / Cost: 0.0493741 / Training Accuracy: 0.90625 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 35840/55000 / Cost: 0.057266 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 36096/55000 / Cost: 0.0614022 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 36352/55000 / Cost: 0.0651225 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 36608/55000 / Cost: 0.054697 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 36864/55000 / Cost: 0.0543131 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 37120/55000 / Cost: 0.0622079 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 37376/55000 / Cost: 0.0583056 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 37632/55000 / Cost: 0.0651672 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 37888/55000 / Cost: 0.0647059 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 38144/55000 / Cost: 0.0673928 / Training Accuracy: 0.859375 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 38400/55000 / Cost: 0.0534362 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 38656/55000 / Cost: 0.0655075 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 38912/55000 / Cost: 0.06373 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 39168/55000 / Cost: 0.058043 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 39424/55000 / Cost: 0.0419459 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 39680/55000 / Cost: 0.0693338 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 39936/55000 / Cost: 0.0675898 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 40192/55000 / Cost: 0.0611943 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 40448/55000 / Cost: 0.0619438 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 40704/55000 / Cost: 0.0529178 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 40960/55000 / Cost: 0.0680975 / Training Accuracy: 0.859375 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 41216/55000 / Cost: 0.0588741 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 41472/55000 / Cost: 0.07362 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 41728/55000 / Cost: 0.0616636 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 41984/55000 / Cost: 0.0491569 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 42240/55000 / Cost: 0.0626952 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 42496/55000 / Cost: 0.054056 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 42752/55000 / Cost: 0.0590301 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 43008/55000 / Cost: 0.0612601 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 43264/55000 / Cost: 0.0558615 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 43520/55000 / Cost: 0.0617007 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 43776/55000 / Cost: 0.0673023 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 44032/55000 / Cost: 0.0483769 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 44288/55000 / Cost: 0.0711408 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 44544/55000 / Cost: 0.062316 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 44800/55000 / Cost: 0.0606651 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 45056/55000 / Cost: 0.0530573 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 45312/55000 / Cost: 0.0607116 / Training Accuracy: 0.894531 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 45568/55000 / Cost: 0.0684859 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 45824/55000 / Cost: 0.059613 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 46080/55000 / Cost: 0.0575538 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 46336/55000 / Cost: 0.0561671 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 46592/55000 / Cost: 0.0452437 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 46848/55000 / Cost: 0.0571688 / Training Accuracy: 0.882813 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 47104/55000 / Cost: 0.058963 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 47360/55000 / Cost: 0.0449407 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 47616/55000 / Cost: 0.0572703 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 47872/55000 / Cost: 0.056989 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 48128/55000 / Cost: 0.0518369 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 48384/55000 / Cost: 0.0625402 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 48640/55000 / Cost: 0.0532542 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 48896/55000 / Cost: 0.0661977 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 49152/55000 / Cost: 0.0514048 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 49408/55000 / Cost: 0.0665534 / Training Accuracy: 0.863281 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 49664/55000 / Cost: 0.0631733 / Training Accuracy: 0.882813 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 49920/55000 / Cost: 0.0490802 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 50176/55000 / Cost: 0.0462584 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 50432/55000 / Cost: 0.0563365 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 50688/55000 / Cost: 0.0672577 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 50944/55000 / Cost: 0.0593768 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 51200/55000 / Cost: 0.0625769 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 51456/55000 / Cost: 0.0549957 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 51712/55000 / Cost: 0.0520048 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 51968/55000 / Cost: 0.0535981 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 52224/55000 / Cost: 0.0504731 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 52480/55000 / Cost: 0.0562951 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 52736/55000 / Cost: 0.053234 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 52992/55000 / Cost: 0.0514638 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 53248/55000 / Cost: 0.0584109 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 53504/55000 / Cost: 0.0537153 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 53760/55000 / Cost: 0.057798 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 54016/55000 / Cost: 0.0444697 / Training Accuracy: 0.941406 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 54272/55000 / Cost: 0.0625254 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 54528/55000 / Cost: 0.069214 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 54784/55000 / Cost: 0.0615876 / Training Accuracy: 0.888889 / Validation Accuracy: 0.91\n",
      "Model is saved!!!\n",
      "Epoch: 9 / Batch: 0/55000 / Cost: 0.056993 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 256/55000 / Cost: 0.0448655 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 512/55000 / Cost: 0.0521132 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 768/55000 / Cost: 0.0464379 / Training Accuracy: 0.941406 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 1024/55000 / Cost: 0.0512007 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 1280/55000 / Cost: 0.0419886 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 1536/55000 / Cost: 0.0506364 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 1792/55000 / Cost: 0.0452339 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 2048/55000 / Cost: 0.0638225 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 2304/55000 / Cost: 0.0527738 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 2560/55000 / Cost: 0.0463555 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 2816/55000 / Cost: 0.0568753 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 3072/55000 / Cost: 0.0512612 / Training Accuracy: 0.914063 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 3328/55000 / Cost: 0.050064 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 3584/55000 / Cost: 0.0492761 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 3840/55000 / Cost: 0.0659419 / Training Accuracy: 0.863281 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 4096/55000 / Cost: 0.0434001 / Training Accuracy: 0.9375 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 4352/55000 / Cost: 0.0701765 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 4608/55000 / Cost: 0.0526574 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 4864/55000 / Cost: 0.054184 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 5120/55000 / Cost: 0.0570497 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 5376/55000 / Cost: 0.0647729 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 5632/55000 / Cost: 0.0626613 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 5888/55000 / Cost: 0.0655143 / Training Accuracy: 0.871094 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 6144/55000 / Cost: 0.0516571 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 6400/55000 / Cost: 0.0567202 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 6656/55000 / Cost: 0.0580116 / Training Accuracy: 0.875 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 6912/55000 / Cost: 0.0534731 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 7168/55000 / Cost: 0.0547557 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 7424/55000 / Cost: 0.0493024 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 7680/55000 / Cost: 0.0507944 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 7936/55000 / Cost: 0.0648602 / Training Accuracy: 0.851563 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 8192/55000 / Cost: 0.0565586 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 8448/55000 / Cost: 0.055294 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 8704/55000 / Cost: 0.0552688 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 8960/55000 / Cost: 0.0635365 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 9216/55000 / Cost: 0.0526692 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 9472/55000 / Cost: 0.0487577 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 9728/55000 / Cost: 0.0527035 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 9984/55000 / Cost: 0.0720421 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 10240/55000 / Cost: 0.0497864 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 10496/55000 / Cost: 0.0509312 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 10752/55000 / Cost: 0.061308 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 11008/55000 / Cost: 0.0461303 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 11264/55000 / Cost: 0.0538639 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 11520/55000 / Cost: 0.0564006 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 11776/55000 / Cost: 0.0544786 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 12032/55000 / Cost: 0.0483993 / Training Accuracy: 0.9375 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 12288/55000 / Cost: 0.0547232 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 12544/55000 / Cost: 0.0375407 / Training Accuracy: 0.945313 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 12800/55000 / Cost: 0.0454031 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 13056/55000 / Cost: 0.0502351 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 13312/55000 / Cost: 0.0524757 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 13568/55000 / Cost: 0.0432652 / Training Accuracy: 0.9375 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 13824/55000 / Cost: 0.048249 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 14080/55000 / Cost: 0.0477433 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 14336/55000 / Cost: 0.0526627 / Training Accuracy: 0.914063 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 14592/55000 / Cost: 0.0645594 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 14848/55000 / Cost: 0.0622104 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 15104/55000 / Cost: 0.0509061 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 15360/55000 / Cost: 0.0420053 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 15616/55000 / Cost: 0.0603143 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 15872/55000 / Cost: 0.0475002 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 16128/55000 / Cost: 0.0499263 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 16384/55000 / Cost: 0.0526126 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 16640/55000 / Cost: 0.0553114 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 16896/55000 / Cost: 0.055267 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 17152/55000 / Cost: 0.0485912 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 17408/55000 / Cost: 0.0488764 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 17664/55000 / Cost: 0.0480777 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 17920/55000 / Cost: 0.056223 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 18176/55000 / Cost: 0.0521427 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 18432/55000 / Cost: 0.0479027 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 18688/55000 / Cost: 0.0598406 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 18944/55000 / Cost: 0.062853 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 19200/55000 / Cost: 0.0580051 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 19456/55000 / Cost: 0.0472078 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 19712/55000 / Cost: 0.0403817 / Training Accuracy: 0.949219 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 19968/55000 / Cost: 0.0579881 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 20224/55000 / Cost: 0.0456301 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 20480/55000 / Cost: 0.047453 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 20736/55000 / Cost: 0.0728097 / Training Accuracy: 0.847656 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 20992/55000 / Cost: 0.0487858 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 21248/55000 / Cost: 0.0535149 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 21504/55000 / Cost: 0.062709 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 21760/55000 / Cost: 0.0532284 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 22016/55000 / Cost: 0.045951 / Training Accuracy: 0.917969 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 22272/55000 / Cost: 0.0474819 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 22528/55000 / Cost: 0.0557033 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 22784/55000 / Cost: 0.0549808 / Training Accuracy: 0.914063 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 23040/55000 / Cost: 0.0590038 / Training Accuracy: 0.890625 / Validation Accuracy: 0.86\n",
      "Epoch: 9 / Batch: 23296/55000 / Cost: 0.0473036 / Training Accuracy: 0.910156 / Validation Accuracy: 0.86\n",
      "Epoch: 9 / Batch: 23552/55000 / Cost: 0.0443072 / Training Accuracy: 0.933594 / Validation Accuracy: 0.84\n",
      "Epoch: 9 / Batch: 23808/55000 / Cost: 0.0592143 / Training Accuracy: 0.898438 / Validation Accuracy: 0.84\n",
      "Epoch: 9 / Batch: 24064/55000 / Cost: 0.0552955 / Training Accuracy: 0.914063 / Validation Accuracy: 0.86\n",
      "Epoch: 9 / Batch: 24320/55000 / Cost: 0.0567144 / Training Accuracy: 0.917969 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 24576/55000 / Cost: 0.0516191 / Training Accuracy: 0.917969 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 24832/55000 / Cost: 0.0679346 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 25088/55000 / Cost: 0.0598305 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 25344/55000 / Cost: 0.0638449 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 25600/55000 / Cost: 0.0509661 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 25856/55000 / Cost: 0.0482707 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 26112/55000 / Cost: 0.0486438 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 26368/55000 / Cost: 0.0559505 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 26624/55000 / Cost: 0.0530813 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 26880/55000 / Cost: 0.0514241 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 27136/55000 / Cost: 0.0557342 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 27392/55000 / Cost: 0.0420072 / Training Accuracy: 0.921875 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 27648/55000 / Cost: 0.0513692 / Training Accuracy: 0.925781 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 27904/55000 / Cost: 0.0427647 / Training Accuracy: 0.925781 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 28160/55000 / Cost: 0.0501025 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 28416/55000 / Cost: 0.0413646 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 28672/55000 / Cost: 0.063357 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 28928/55000 / Cost: 0.0586535 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 29184/55000 / Cost: 0.0459116 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 29440/55000 / Cost: 0.0396814 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 29696/55000 / Cost: 0.0622048 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 29952/55000 / Cost: 0.0473848 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 30208/55000 / Cost: 0.0571979 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 30464/55000 / Cost: 0.0518692 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 30720/55000 / Cost: 0.0553146 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 30976/55000 / Cost: 0.0460325 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 31232/55000 / Cost: 0.0512054 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 31488/55000 / Cost: 0.0593097 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 31744/55000 / Cost: 0.0597854 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 32000/55000 / Cost: 0.0542334 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 32256/55000 / Cost: 0.063602 / Training Accuracy: 0.882813 / Validation Accuracy: 0.86\n",
      "Epoch: 9 / Batch: 32512/55000 / Cost: 0.0583863 / Training Accuracy: 0.878906 / Validation Accuracy: 0.86\n",
      "Epoch: 9 / Batch: 32768/55000 / Cost: 0.047378 / Training Accuracy: 0.925781 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 33024/55000 / Cost: 0.051323 / Training Accuracy: 0.910156 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 33280/55000 / Cost: 0.0598074 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 33536/55000 / Cost: 0.0495949 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 33792/55000 / Cost: 0.0482647 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 34048/55000 / Cost: 0.048807 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 34304/55000 / Cost: 0.0632824 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 34560/55000 / Cost: 0.0491195 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 34816/55000 / Cost: 0.0646285 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 35072/55000 / Cost: 0.0513641 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 35328/55000 / Cost: 0.0531084 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 35584/55000 / Cost: 0.0649528 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 35840/55000 / Cost: 0.0615349 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 36096/55000 / Cost: 0.0699178 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 36352/55000 / Cost: 0.052974 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 36608/55000 / Cost: 0.0571023 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 36864/55000 / Cost: 0.0549476 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 37120/55000 / Cost: 0.0551382 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 37376/55000 / Cost: 0.0431996 / Training Accuracy: 0.914063 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 37632/55000 / Cost: 0.0575329 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 37888/55000 / Cost: 0.0478525 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 38144/55000 / Cost: 0.0485324 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 38400/55000 / Cost: 0.061993 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 38656/55000 / Cost: 0.053282 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 38912/55000 / Cost: 0.0503516 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 39168/55000 / Cost: 0.0553224 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 39424/55000 / Cost: 0.0413636 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 39680/55000 / Cost: 0.0503759 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 39936/55000 / Cost: 0.0532974 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 40192/55000 / Cost: 0.0468602 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 40448/55000 / Cost: 0.0526259 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 40704/55000 / Cost: 0.0416783 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 40960/55000 / Cost: 0.0614326 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 41216/55000 / Cost: 0.0435189 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 41472/55000 / Cost: 0.0639708 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 41728/55000 / Cost: 0.0566003 / Training Accuracy: 0.875 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 41984/55000 / Cost: 0.0461836 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 42240/55000 / Cost: 0.0497747 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 42496/55000 / Cost: 0.066621 / Training Accuracy: 0.867188 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 42752/55000 / Cost: 0.0628361 / Training Accuracy: 0.867188 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 43008/55000 / Cost: 0.0579231 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 43264/55000 / Cost: 0.0637848 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 43520/55000 / Cost: 0.0403999 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 43776/55000 / Cost: 0.0550746 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 44032/55000 / Cost: 0.0528202 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 44288/55000 / Cost: 0.0499842 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 44544/55000 / Cost: 0.0515763 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 44800/55000 / Cost: 0.0390285 / Training Accuracy: 0.9375 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 45056/55000 / Cost: 0.0507732 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 45312/55000 / Cost: 0.0434345 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 45568/55000 / Cost: 0.0579545 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 45824/55000 / Cost: 0.0441211 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 46080/55000 / Cost: 0.0589457 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 46336/55000 / Cost: 0.0531247 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 46592/55000 / Cost: 0.0517415 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 46848/55000 / Cost: 0.0521855 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 47104/55000 / Cost: 0.0395104 / Training Accuracy: 0.945313 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 47360/55000 / Cost: 0.0425636 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 47616/55000 / Cost: 0.050654 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 47872/55000 / Cost: 0.0479187 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 48128/55000 / Cost: 0.0708814 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 48384/55000 / Cost: 0.0553938 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 48640/55000 / Cost: 0.0501579 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 48896/55000 / Cost: 0.0554874 / Training Accuracy: 0.878906 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 49152/55000 / Cost: 0.0536444 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 49408/55000 / Cost: 0.051158 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 49664/55000 / Cost: 0.0594698 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 49920/55000 / Cost: 0.0522675 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 50176/55000 / Cost: 0.051978 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 50432/55000 / Cost: 0.0486754 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 50688/55000 / Cost: 0.0592869 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 50944/55000 / Cost: 0.0360938 / Training Accuracy: 0.945313 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 51200/55000 / Cost: 0.0519049 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 51456/55000 / Cost: 0.0530562 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 51712/55000 / Cost: 0.05228 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 51968/55000 / Cost: 0.0538919 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 52224/55000 / Cost: 0.0395334 / Training Accuracy: 0.925781 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 52480/55000 / Cost: 0.0537598 / Training Accuracy: 0.914063 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 52736/55000 / Cost: 0.0350195 / Training Accuracy: 0.941406 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 52992/55000 / Cost: 0.0647052 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 53248/55000 / Cost: 0.0546738 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 53504/55000 / Cost: 0.0554316 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 53760/55000 / Cost: 0.0533524 / Training Accuracy: 0.894531 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 54016/55000 / Cost: 0.054917 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 54272/55000 / Cost: 0.0597922 / Training Accuracy: 0.882813 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 54528/55000 / Cost: 0.0442943 / Training Accuracy: 0.921875 / Validation Accuracy: 0.87\n",
      "Epoch: 9 / Batch: 54784/55000 / Cost: 0.0450916 / Training Accuracy: 0.912037 / Validation Accuracy: 0.88\n",
      "Model is saved!!!\n",
      "Epoch: 10 / Batch: 0/55000 / Cost: 0.047079 / Training Accuracy: 0.914063 / Validation Accuracy: 0.87\n",
      "Epoch: 10 / Batch: 256/55000 / Cost: 0.0361278 / Training Accuracy: 0.929688 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 512/55000 / Cost: 0.054262 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 768/55000 / Cost: 0.0432291 / Training Accuracy: 0.921875 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 1024/55000 / Cost: 0.0371952 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 1280/55000 / Cost: 0.0461703 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 1536/55000 / Cost: 0.0562968 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 1792/55000 / Cost: 0.0557079 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 2048/55000 / Cost: 0.0578893 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 2304/55000 / Cost: 0.0513987 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 2560/55000 / Cost: 0.0608497 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 2816/55000 / Cost: 0.0418783 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 3072/55000 / Cost: 0.0518241 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 3328/55000 / Cost: 0.0456144 / Training Accuracy: 0.933594 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 3584/55000 / Cost: 0.0487987 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 3840/55000 / Cost: 0.0504858 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 4096/55000 / Cost: 0.0419604 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 4352/55000 / Cost: 0.0465246 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 4608/55000 / Cost: 0.0461698 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 4864/55000 / Cost: 0.0418049 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 5120/55000 / Cost: 0.0514188 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 5376/55000 / Cost: 0.0517786 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 5632/55000 / Cost: 0.0447247 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 5888/55000 / Cost: 0.0443263 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 6144/55000 / Cost: 0.0484029 / Training Accuracy: 0.914063 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 6400/55000 / Cost: 0.0473508 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 6656/55000 / Cost: 0.0369515 / Training Accuracy: 0.957031 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 6912/55000 / Cost: 0.0423372 / Training Accuracy: 0.957031 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 7168/55000 / Cost: 0.0557148 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 7424/55000 / Cost: 0.0570264 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 7680/55000 / Cost: 0.0449816 / Training Accuracy: 0.941406 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 7936/55000 / Cost: 0.0466219 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 8192/55000 / Cost: 0.0435631 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 8448/55000 / Cost: 0.0532755 / Training Accuracy: 0.886719 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 8704/55000 / Cost: 0.0427163 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 8960/55000 / Cost: 0.0555983 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 9216/55000 / Cost: 0.0477599 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 9472/55000 / Cost: 0.0560198 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 9728/55000 / Cost: 0.050967 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 9984/55000 / Cost: 0.0484812 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 10240/55000 / Cost: 0.0380923 / Training Accuracy: 0.945313 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 10496/55000 / Cost: 0.0353567 / Training Accuracy: 0.949219 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 10752/55000 / Cost: 0.0486489 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 11008/55000 / Cost: 0.0461566 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 11264/55000 / Cost: 0.055613 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 11520/55000 / Cost: 0.0541486 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 11776/55000 / Cost: 0.0539274 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 12032/55000 / Cost: 0.0528231 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 12288/55000 / Cost: 0.0477735 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 12544/55000 / Cost: 0.0497813 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 12800/55000 / Cost: 0.0490711 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 13056/55000 / Cost: 0.0468817 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 13312/55000 / Cost: 0.04027 / Training Accuracy: 0.941406 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 13568/55000 / Cost: 0.0536229 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 13824/55000 / Cost: 0.0482115 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 14080/55000 / Cost: 0.0525179 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 14336/55000 / Cost: 0.0468658 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 14592/55000 / Cost: 0.0546666 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 14848/55000 / Cost: 0.0576993 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 15104/55000 / Cost: 0.0493726 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 15360/55000 / Cost: 0.0503298 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 15616/55000 / Cost: 0.0490631 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 15872/55000 / Cost: 0.0490304 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 16128/55000 / Cost: 0.042532 / Training Accuracy: 0.9375 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 16384/55000 / Cost: 0.0574685 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 16640/55000 / Cost: 0.0484922 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 16896/55000 / Cost: 0.0500258 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 17152/55000 / Cost: 0.0490192 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 17408/55000 / Cost: 0.0606358 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 17664/55000 / Cost: 0.0420669 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 17920/55000 / Cost: 0.0545033 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 18176/55000 / Cost: 0.038668 / Training Accuracy: 0.945313 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 18432/55000 / Cost: 0.0551517 / Training Accuracy: 0.933594 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 18688/55000 / Cost: 0.0508164 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 18944/55000 / Cost: 0.0470417 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 19200/55000 / Cost: 0.0415003 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 19456/55000 / Cost: 0.0583288 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 19712/55000 / Cost: 0.064688 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 19968/55000 / Cost: 0.0564336 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 20224/55000 / Cost: 0.0566099 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 20480/55000 / Cost: 0.0595745 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 20736/55000 / Cost: 0.0546726 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 20992/55000 / Cost: 0.0447643 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 21248/55000 / Cost: 0.0512426 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 21504/55000 / Cost: 0.0370819 / Training Accuracy: 0.957031 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 21760/55000 / Cost: 0.0534583 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 22016/55000 / Cost: 0.0509354 / Training Accuracy: 0.914063 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 22272/55000 / Cost: 0.0438467 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 22528/55000 / Cost: 0.0485587 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 22784/55000 / Cost: 0.047268 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 23040/55000 / Cost: 0.0415075 / Training Accuracy: 0.933594 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 23296/55000 / Cost: 0.0462172 / Training Accuracy: 0.917969 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 23552/55000 / Cost: 0.0676101 / Training Accuracy: 0.863281 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 23808/55000 / Cost: 0.0534228 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 24064/55000 / Cost: 0.0445578 / Training Accuracy: 0.925781 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 24320/55000 / Cost: 0.0423629 / Training Accuracy: 0.933594 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 24576/55000 / Cost: 0.0526259 / Training Accuracy: 0.921875 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 24832/55000 / Cost: 0.0507105 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 25088/55000 / Cost: 0.0410187 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 25344/55000 / Cost: 0.0629023 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 25600/55000 / Cost: 0.0494504 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 25856/55000 / Cost: 0.047674 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 26112/55000 / Cost: 0.0464746 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 26368/55000 / Cost: 0.0568939 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 26624/55000 / Cost: 0.0483534 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 26880/55000 / Cost: 0.0604901 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 27136/55000 / Cost: 0.0496767 / Training Accuracy: 0.914063 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 27392/55000 / Cost: 0.0531172 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 27648/55000 / Cost: 0.0451722 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 27904/55000 / Cost: 0.0395856 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 28160/55000 / Cost: 0.0351387 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 28416/55000 / Cost: 0.0595914 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 28672/55000 / Cost: 0.0497335 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 28928/55000 / Cost: 0.0489013 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 29184/55000 / Cost: 0.0418482 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 29440/55000 / Cost: 0.0446054 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 29696/55000 / Cost: 0.0391046 / Training Accuracy: 0.9375 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 29952/55000 / Cost: 0.0456205 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 30208/55000 / Cost: 0.0442932 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 30464/55000 / Cost: 0.0452102 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 30720/55000 / Cost: 0.0423051 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 30976/55000 / Cost: 0.0531726 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 31232/55000 / Cost: 0.0440824 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 31488/55000 / Cost: 0.0422348 / Training Accuracy: 0.929688 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 31744/55000 / Cost: 0.0533531 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 32000/55000 / Cost: 0.0571878 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 32256/55000 / Cost: 0.0397932 / Training Accuracy: 0.9375 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 32512/55000 / Cost: 0.0467676 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 32768/55000 / Cost: 0.0498964 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 33024/55000 / Cost: 0.0501709 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 33280/55000 / Cost: 0.0541093 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 33536/55000 / Cost: 0.0415844 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 33792/55000 / Cost: 0.0552536 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 34048/55000 / Cost: 0.0469353 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 34304/55000 / Cost: 0.0617427 / Training Accuracy: 0.871094 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 34560/55000 / Cost: 0.0565961 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 34816/55000 / Cost: 0.0596838 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 35072/55000 / Cost: 0.0440383 / Training Accuracy: 0.933594 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 35328/55000 / Cost: 0.0523764 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 35584/55000 / Cost: 0.0500936 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 35840/55000 / Cost: 0.0443488 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 36096/55000 / Cost: 0.0417415 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 36352/55000 / Cost: 0.0496032 / Training Accuracy: 0.914063 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 36608/55000 / Cost: 0.0512068 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 36864/55000 / Cost: 0.0599107 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 37120/55000 / Cost: 0.0543562 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 37376/55000 / Cost: 0.0587273 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 37632/55000 / Cost: 0.0549719 / Training Accuracy: 0.882813 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 37888/55000 / Cost: 0.06516 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 38144/55000 / Cost: 0.0468279 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 38400/55000 / Cost: 0.05313 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 38656/55000 / Cost: 0.0511835 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 38912/55000 / Cost: 0.0520023 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 39168/55000 / Cost: 0.0552004 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 39424/55000 / Cost: 0.0554411 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 39680/55000 / Cost: 0.0484848 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 39936/55000 / Cost: 0.0510988 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 40192/55000 / Cost: 0.0573489 / Training Accuracy: 0.890625 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 40448/55000 / Cost: 0.0390415 / Training Accuracy: 0.9375 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 40704/55000 / Cost: 0.0498711 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 40960/55000 / Cost: 0.057415 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 41216/55000 / Cost: 0.054191 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 41472/55000 / Cost: 0.0477176 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 10 / Batch: 41728/55000 / Cost: 0.0494588 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 41984/55000 / Cost: 0.054922 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 42240/55000 / Cost: 0.0617435 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 42496/55000 / Cost: 0.056201 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 42752/55000 / Cost: 0.0527357 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 43008/55000 / Cost: 0.0502732 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 43264/55000 / Cost: 0.0493484 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 43520/55000 / Cost: 0.0421048 / Training Accuracy: 0.945313 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 43776/55000 / Cost: 0.0541691 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 44032/55000 / Cost: 0.0514086 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 44288/55000 / Cost: 0.0408213 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 44544/55000 / Cost: 0.0454947 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 44800/55000 / Cost: 0.0477365 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 45056/55000 / Cost: 0.0485983 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 45312/55000 / Cost: 0.0549218 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 45568/55000 / Cost: 0.0392968 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 45824/55000 / Cost: 0.044249 / Training Accuracy: 0.933594 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 46080/55000 / Cost: 0.0530574 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 46336/55000 / Cost: 0.0525563 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 46592/55000 / Cost: 0.0444494 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 46848/55000 / Cost: 0.0507379 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 47104/55000 / Cost: 0.0524641 / Training Accuracy: 0.898438 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 47360/55000 / Cost: 0.0515707 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 47616/55000 / Cost: 0.0489459 / Training Accuracy: 0.914063 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 47872/55000 / Cost: 0.0371226 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 48128/55000 / Cost: 0.0433566 / Training Accuracy: 0.9375 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 48384/55000 / Cost: 0.0444526 / Training Accuracy: 0.929688 / Validation Accuracy: 0.89\n",
      "Epoch: 10 / Batch: 48640/55000 / Cost: 0.0436276 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 48896/55000 / Cost: 0.0451059 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 49152/55000 / Cost: 0.0473516 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 49408/55000 / Cost: 0.0497354 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 49664/55000 / Cost: 0.0541547 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 49920/55000 / Cost: 0.0563426 / Training Accuracy: 0.878906 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 50176/55000 / Cost: 0.0461802 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 50432/55000 / Cost: 0.0524483 / Training Accuracy: 0.914063 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 50688/55000 / Cost: 0.0440915 / Training Accuracy: 0.933594 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 50944/55000 / Cost: 0.0640487 / Training Accuracy: 0.871094 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 51200/55000 / Cost: 0.0502085 / Training Accuracy: 0.914063 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 51456/55000 / Cost: 0.0469546 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 51712/55000 / Cost: 0.0496941 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 51968/55000 / Cost: 0.05671 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 52224/55000 / Cost: 0.0603406 / Training Accuracy: 0.882813 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 52480/55000 / Cost: 0.05137 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 52736/55000 / Cost: 0.0433815 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 52992/55000 / Cost: 0.0515749 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 53248/55000 / Cost: 0.0495863 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 53504/55000 / Cost: 0.0460366 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 53760/55000 / Cost: 0.0491337 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 54016/55000 / Cost: 0.0527452 / Training Accuracy: 0.882813 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 54272/55000 / Cost: 0.0470436 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 54528/55000 / Cost: 0.059572 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 54784/55000 / Cost: 0.0554144 / Training Accuracy: 0.916667 / Validation Accuracy: 0.91\n",
      "Model is saved!!!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "if Is_train == True:\n",
    "    train_data_num = train_x.shape[0]\n",
    "\n",
    "    for i in range(num_epoch):\n",
    "        # Making batches\n",
    "        random_idx = np.arange(train_data_num)\n",
    "        np.random.shuffle(random_idx)\n",
    "\n",
    "        batch_count = 1\n",
    "        for j in range(0, train_data_num, batch_size):\n",
    "            if j + batch_size < train_data_num:\n",
    "                batch_index = [j, j + batch_size]\n",
    "\n",
    "                batch_x_train = train_x[random_idx[batch_index[0]:batch_index[1]],:,:]\n",
    "                batch_y_train = train_y[random_idx[batch_index[0]:batch_index[1]],:]\n",
    "            else:\n",
    "                batch_index = [j, j + train_data_num-1]\n",
    "\n",
    "                batch_x_train = train_x[random_idx[batch_index[0]:batch_index[-1]],:,:]\n",
    "                batch_y_train = train_y[random_idx[batch_index[0]:batch_index[-1]],:]\n",
    "\n",
    "\n",
    "            # Make image as fractions for attention\n",
    "            train_fraction = np.zeros([batch_x_train.shape[0], img_fraction_size, img_fraction_size, len_stack])\n",
    "            validation_fraction = np.zeros([validation_x.shape[0], img_fraction_size, img_fraction_size, len_stack])\n",
    "\n",
    "            index_fraction = 0\n",
    "            for m in range(len_vertical):\n",
    "                start_v = stride * m\n",
    "                for n in range(len_horizontal):\n",
    "                    start_h = stride * n\n",
    "\n",
    "                    train_fraction[:,:,:,index_fraction] = batch_x_train[:, \n",
    "                                                                         start_v : start_v + img_fraction_size, \n",
    "                                                                         start_h : start_h + img_fraction_size]\n",
    "\n",
    "                    validation_fraction[:,:,:,index_fraction] = validation_x[:, \n",
    "                                                                            start_v : start_v + img_fraction_size, \n",
    "                                                                            start_h : start_h + img_fraction_size]\n",
    "                    index_fraction += 1\n",
    "\n",
    "            # Training\n",
    "            optimizer.run(feed_dict = {x_image: train_fraction, y_target: batch_y_train})\n",
    "            cost = sess.run(Cost, feed_dict = {x_image: train_fraction, y_target: batch_y_train})\n",
    "            acc = sess.run(accuracy, feed_dict = {x_image: train_fraction, y_target: batch_y_train})\n",
    "            val_acc = sess.run(accuracy, feed_dict = {x_image: validation_fraction, y_target: validation_y})\n",
    "\n",
    "            # Print Progress\n",
    "            print(\"Epoch: \" + str(i+1) + ' / ' + \n",
    "                  \"Batch: \" + str(j) + '/' + str(train_data_num) + ' / ' + \n",
    "                  \"Cost: \" + str(cost) + ' / ' + \n",
    "                  \"Training Accuracy: \" + str(acc) + ' / ' + \n",
    "                  \"Validation Accuracy: \" + str(val_acc))  \n",
    "\n",
    "        saver.save(sess, 'saved_networks/' + save_name)\n",
    "        print('Model is saved!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEsOBJEkq+f++C2eN9nbB4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1a6ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d1b1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3ba5cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEkFw4EkSSoYDiRJUuH/AeK8IFjcWyDSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x451b8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x45b8cf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIKhgNJklQwHEiSpILhQJIkFf4fynoq6pnWG0kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4665dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ37IYW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4ce68f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAF/1JREFUeJzt3XmUXOV9p/Hn14s2C0kgNWAWyQiQMjZb8MjjYTBYbEas\nxh4sCHYgmcTJODZezonhxEvIeIyTM3EmBhsQkEBgMIMVAWPADsQGBWM5KHECtqMjhCwJrQEJqbW3\n1Ms7f7y3Rd1yt7pL1aLU4vmcU0fqW+99661bb1V973vfeytSSkiSJPVqanQDJEnSgcVwIEmSSgwH\nkiSpxHAgSZJKDAeSJKnEcCBJkkoMB5IkqcRwIEmSSgwHkiSpxHAgSYMUETdFRE+j2yHtb4aDQYqI\nayOiJyJO7+f++RHxs/34+LMi4o/3V/0aeo3uM8VjDPt+ExErIuK7/dx3drGNP/QmNScVN1WoeB3O\nanRb3kwRcW9EbB3iOudHxNNDWee+MBzUZm8fCvv7A+Mi4Mv7+TE09BrZZ+Dg6DcDbae39Jd1RQjt\nve2MiJci4taIOPxNbErdr0NEzI6IBRGxLSI2RcSPI+L9Nax/aUR07+157y1s7oP9ERaHYjseHhFz\nImJ10R+WR8TdtdTRUm8j9KaJRjdAw9Jbod8M2XOMiDEppR1DVd+bKAFfAlYAo4Azgf8OzIqIk1JK\nHQ1s26BExE3k5zAXuAdoBU4Cjq6hmouAf04pvbaXMgd1mIyIY4AFQA9wO7AGOAp4Ty31OHKwH0XE\nRyPinyNiR0S8HhEPFi9cZZkzI+I7EfFKRHRExMqI+IuIGFVR5h7gE8X/e/cOuou/pxR/fy4iPhER\nv4yI7RHxZEQcXZT5UkSsKtrxaERMqGrDZRHxeESsKdqwNCK+GBFNVeXmR8TPIuL0ItHviIhlEfF7\n+2kTviXZb+refpMj4raIWFw81oZiW02pKte7x31WUf5VYFXF/WdGxD8Ve14vR8TH90d7h9DfpZS+\nnVL665TSbwN/CRwHXN7fChEx5k1r3V5ExHvJweCzKaWrUkp3pZRuSyl9IqX0QA1VXQQ8sX9aOWzc\nCewGTkspfTWldG9K6eaU0gdrqcSRg9qNj4iJVcuCnHLfWBDxBeB/AP8XuAtoA64H/iEifj2ltKUo\neiUwGrgNeJ2c7j5FTsuzizJ3kJPfecA19L2n9NGiDbcAhwE3AHMjH7s6G/hT4ISiDX8O/E7FutcB\nW4GvA9uAc4q2H1LU0ysVdT8BfAf4NvAR4PaI2JVSurePdmmQfQbsN3vR2sc2BJjQx7IZwHuBB4HV\nwDvIIemZiHhnH3vRtwGvAX8CvA0gIk4GniyWf5m8jW4q/h4ungY+Rw4IRMR1wF8D7weuAj5M/g6Y\nWNx/FPA/yV+wE4ClwNdTSvdUVlqEx2+R+9V24AHg76jqXxExGpgMbEgpvT5AWz8DrEsp3VKs+7aU\n0vZanmzxmh3LEISDiDiT3Of/E3AE+XX/W+CP+hqFiYjjyO+3/wJsBu5IKX2lqkwAnya/h44vyj0K\n3JhSah+gPccCY1JKLw1QbjpwIfD7KaX2iBgJdKeUugZ+1lVSSt4GcQOuJQ/T7O32s6LsFKATuKGq\njneSE92NFctG9vFYNwBdwDEVy24tXuTqslOKx/53YGzF8q8Wy/8FaKpY/gCwE2gdoA23kz/4K8s9\nA3QDn65Y1lo8xjqgudGv04F0q6XPFOUn22/63I7LB9iG3cCHBmjXe4qy1/Tx+swHoqr8I+QvvqMr\nlk0vXp9f2Z4HQD/rBk6vWn598fx+t+r5/oIcHD4B/GFx3+HkUZMVwB8BHy+2QQ9wfUWdo4CXim1z\nMzmQLgReKNpwVkXZs4v1vzyI5/Ba8XifBtYX660F/qCG7XADOWAMVG458N0BynwDeKyo83fIe+Od\nwENV5e4BdhTb5F7yoZz/V7T/pqqydwG7ivfI7xbbbyvwj5XvgeL98nTVuvOBnkE8tz8oXocrgB8W\n7egEvgdMqaVfOXJQm0R+Q73cx31/wRuHaT5ETtFzq/Z2XivWnUneIyOltKv3zmKIbzTwk6KuXyfv\n+QzGd1JK2yr+fr749/6UUk/V8qvIe5gr+mjDWGAk8Bz5A+LXgJ9XrN9FfqNQrNsZEXPIe1/vJn9Q\n6A2D7TOQ9+TsN337R+AL/Orox2nA/6pcUNWuFmAcsAxoB04nB509xYG7UvHJWqzTBFwAPJJSWlNR\n70sR8SQwa4C2NkrvCFXvnIMvkb+4Hq8qtwE4t/I5k7+ogjwU3bsXe2dEfBu4KSLmFNv198gjSVem\nlB4GiIi7gP7Ouhlwwl5xuGpS0eZzyCM0q4DfAm6NiN0ppbsGevLkEY/vD6LcYHy+sh8Bd0fEL4Gv\nRsQxKaXK99dI4Hsppc8Wf98eEY8BN0TELSmljcVIxH8Drk4pPdS7YkQ8Qx6hupI8WtifRP6iH8iJ\n5NfxTvJ76iPknY6bgL+PiFPSIOefGA5q908ppX+pXhgRmyiG58hvnibysFy1RN4L7F3vWOArwKXA\noVXlxtfQrlVVf28u/q3+kuhdfijFh3xEvJO8xziT/EG6tzasTSntrFq2hNwh34HhoC+D6TNgv9mb\nDSmlZ6oXFnMoqoezR5H3fq8jh5ne+/vbNiuq/m4jh62+XoeXODDDQZD3FHsl8vO6OqW0rmr5XVXB\nAPIOzUNAc1UwfYocCk8nh89Z5L3zh/dUmFJHRNwJ/FllhSmlfwCaB9H2scW/hwGzU0p/CxAR88gB\n84vkve5+RcR44D+T9/jrtg/h+1tVf38TuJh86OU75C//duCHVdv3X8mH5Gayl3CQUpo5yKb3bsu1\nKaWLK57DGvJhtt8gH1oakOFg/2gip7wL6TvtbYM9eyg/IB/f+xpvDNcdDfwNtU0Y7a5xeRRtGA88\nS+64XyTvYXWQ9+b+tMY2qD72m6HxTfIQ+v8mjzhsJn8pPtRPu6pDy3BUOULVBbya+j8+vaLyj4ho\nI/elj5NHBvqqu/fUwCn0H5r2Ve/27wTm7XnQlFJEPEQeuajeW692YdHOv6+jHXvUGL57yP2/0pLi\n33cU/55A3sZ9zVmp3L712lnUN7dq+VzgfuAMDAcN9Uvyh+iKlFJfb6ReJ5OHgT6WKmbkRsR5fZTd\nX6ffvJ/c+S9PKf24og3H91P+qIgYXbUXOJ039lS07+w3Q+PDwL0ppc9XtGskfU9e7Mt68ofsiX3c\n92v1N2+/6XOEqg/VYag3MP0fcrjsy/68WNdGcrDc1MeIRu+X6aHs/VDZLODHKaW6L0g0xOG7VxPw\nKnnPva+Jwev3qbG/am3x76uVC1NKPRHxOuWgs1fuFe4fD5PTZJ9XpouIw4r/9u6dVb8On+FXP9S3\nF+uOY2j1DsvuaUNEjKA4Ba4PLcDvV5RtJe9trAd+OsRte6ux3wxd26q3zfUMboibYq7Fk8AHo+IU\n0oj4D+S5CAeb9eSJcc0ppaf7uW0oyr5CnmlfbZ9DUxEIXgDaijkilXqvcTDQl+eFDN0pjL3h+3Mp\npT9PKT2WUnqaPHm2L03A1Kpl04t/lxf//pJ8CHFBP9v35wyNn5Lfl6VrQxTvt0nUEEIcOajNoC62\nklJaFhFfBG4uTnF5lPzmmwp8EJhDnoy2mNxpvl58CG0h7/X0tYfT+6LfWkyK6q6c2FLH81gAbALu\ni4hbimUfpf89zrXA5yPiHeShs6uAU8gzovsbin4rG/QFeuw3Q+Zx4GMRsQVYRD4WfS55Il61/l6f\nPyZ/4TwXEbeRz674JHmm/ylD3N6GKvYq5wFXR8TXUkr/Vnl/REyqCAffA86PiA+nlOYV948hz76n\nar1aTmV8iHza4LXAXxXrjyKfgvtvKaV/72/FiHgPeZ7IUIWDWsJ3r08W91f+vZt8VgjkeQefIJ8W\n+4XKFSOimXzG0Gb6MdhTGclnNbwGXBMRN6eUeucp/VbxfJ4aYP09DAe1GfRlXFNKfxYRLwGf5Y3L\n164inw/83aJMV0RcQj7H/Eby0NrD5MktL1bV/XBR7ireOGe990O+vxnB/bW3sp0bI+Ji8rnqXyF/\n4N9P7tRP9rHuJvIb+JvkU3xeJZ9uNKjjWG9Bg+4zYL/Zy+PubTtW33c9+bj7b5Bn7j9Hnhj2ZB9l\n+6w3pfTziLiAHMb+hDyk/WXydSMOxHAw2BDaX7kbyYeKni/OPlhEniD4bvIZBJOKcneRv/juj4j/\nSN6b/hjFCFWV95BPy7uJfP2LvZlD7hffKs7VXwn8Jvm6BZcMsO5F5ENxiwcoV+mE4poi1f6V/AU6\n2PAN+fTECyPiXvJZPReRD3N8tTcUpZSeLc7OuTEiTiseoxOYBvxXcp99uI+6e90PnMUAo/0ppd0R\n8Yfk0yp/FBH3k+eJXE+eI/TI3tavrsybt0HdyG/0nzW6Hd6G181+s9+3b5/XOai1HDkA3EKeA9JB\nvuzuU8BvV5U7pviS2UoOeV8Hzqfv6xx0A18a5POYRJ4st558CuYC4LxBrLcQuLWG7bW8aFdftzuL\nMtPJYXJz8RxvJ1/KuRv4zYq67inKvIMc4LeSR8n6fM7k0xkXkicXt5MPp9wMHFFR5hngh1XrPQN0\n1fAcP0K+jsiOoj1/Cbytln4VRUXSgIpzciemlA7EPScdoOw32l8i/8DSWuDilFJfI1baR05IlCQN\nV+PJhyzmN7gdBx3nHKhWDjVpX9hvNORSSi8z8HwG7QMPK0iSpBIPK0iSpBLDgSRJKhk2cw4iou7j\nH5MnT+aQQw6pq47u7m56egbz41j9iwhaW1vrqgOgubmZ/BPhw9/mzZtZvnz5wAUHkFJ6UzbIUPRH\nHfzsjzqQ1NIfHTmQJEklhgNJklRiOJAkSSWGA0mSVGI4kCRJJYYDSZJUYjiQJEklhgNJklRiOJAk\nSSWGA0mSVGI4kCRJJYYDSZJUYjiQJEklhgNJklRiOJAkSSUtjW7AYE2bNq3uOi655BKmTJlSVx2t\nra20tNS32To7O9m6dWtddaSU6OjoIKWD42fc16xZw49+9KNGN0OSxDAKB2PGjKm7jkmTJnHUUUfV\nVceIESMYOXJkXXV0dHSwadOmuuro6elhx44dB0042LFjx5C8xpKk+nlYQZIklRgOJElSieFAkiSV\nGA4kSVKJ4UCSJJUYDiRJUonhQJIklRgOJElSieFAkiSVGA4kSftNW1sb1157LU8++SQPPPAA06dP\np7m5udHN0gCGzeWTJUnDR1NTE6effjrnn38+s2bN4t3vfjc7duzgjjvuYMWKFXR3dze6idoLw4Ek\naUi1trYyZcoUZs+ezaxZs5g6dSqQf0Olu7v7oPlNmIOZ4UCSNGRaWlpoa2vjsssu44orrmDKlCls\n3LiRJUuWsHDhQtatW+eowTBgOJAkDZnx48dzxhln8KlPfYq3v/3ttLe38/TTTzNnzhzmz5/f6OZp\nkAwHkqQh0dzczLve9S4++clPcuSRR5JS4r777uPuu+9m+fLljW6eajBswsGECRPqrmPy5Ml7jn3t\nq3HjxjFu3Li66ti6dSurVq2qq47Ozk6WLl1KV1dXXfVoeLv66qu5+uqrG90MNm7cyGc+8xna29sb\n3RQ1SEtLCzNmzGD27Nmceuqp9PT0MG/ePB5//HGWLVvGrl27Gt1E1WDYhINRo0bVXcfYsWMZP358\nXXUceuihHHbYYXXVMWLECDZv3lxXHbt37yYi6qpDw9/06dO59NJLG90M1q1bx4gRIxrdDDXQ0Ucf\nzXnnnccHPvABRo4cyS9+8QseeeQRXnzxRYPBMDRswoEk6cATEUyYMIGZM2dy7rnnctRRR7FixQrm\nzp3LwoUL2bhxY6ObqH1gOJAk7bPW1lZmzJjBNddcwymnnMLKlSt54okneOCBB2hvb2fUqFGklOju\n7vYw6DBiOJAk7ZOmpiYmTJjAddddxymnnMKGDRuYN28e3/jGN+js7GTq1KmMGTOGjo4ONm7cyOrV\nqxvdZA2S4UCSVLPm5maOP/54rr32Wt73vvcxevRovv/977NgwQLOOOMMrrjiCqZPn87YsWPZuXMn\nS5YsYc6cObz44ots2bLFCyEd4AwHkqSajR49mhNPPJErr7ySww8/nFdffRWAGTNm8N73vpfTTjuN\nQw89lNbWVrq6upg8eTITJ07kxhtvZNGiRezevbvBz0B74w8vSZJqNnbsWCZPnswJJ5xAa2sr7e3t\nHH300Vx88cWcddZZtLW10draCrxx1cQLLriASZMm+cNLw4AjB5KkmkQERxxxBCeccAIpJTo6Omhq\namLq1Kl7Ln60Zs0aNm3axGGHHUZbWxstLS3s3r3b31YYJgwHkqSajBkzZs8vLnZ3d7Ny5UqOOeYY\nRo8ezbZt21i9ejWPP/44zzzzDJdddhmzZ8/mkEMOYeXKlWzfvp2enp5GPwUNwHAgSarJzJkzufzy\ny5k2bRqdnZ08++yznHPOOSxbtoyHHnqIF198kRUrVjB16lQmTpzIuHHj2LRpEw8++CCrVq1yvsEw\nYDiQJNVk4sSJe+YObNq0iYULF/KTn/yEtWvXsmjRIjZt2sTIkSO56KKLOO2001i9ejWPPfYYDz74\noBdFGiYMB5KkmrS0tNDS0kJnZyfr16/nhRde4JVXXmHnzp10dXUxYcIEzjzzTM4991wmTZrEggUL\nePjhh1m6dKmHFIYJw4EkaZ90dXWxZcsW1qxZw+bNm5kwYQKTJ0/m1FNP5dJLL+W4447j5Zdf5qmn\nnuKFF14wGAwjhgNJ0qBFBK2trTQ3N9PU1MTIkSOZMmUKRx55JCeddBJnn302Z599NsceeywvvfQS\n9913H/PmzWPbtm2NbrpqYDiQJA3a6NGjOfbYYzn88MMZNWoUJ598Mo8++iiQz2Lo/S2FdevW8bWv\nfY0f/OAHvP766w1utWplOJAkDVpHRwdr165lw4YNHHPMMbS2tjJx4kQg/9bC7t27eeWVV5g7dy4/\n/elPaW9vb3CLtS+GTTgYimNVmzdvZv369XXV0dHRUffw2M6dO9m+fXtddXR1dXkhEUlvup6eHp57\n7jnGjRvH1q1bmTZtGm1tbSxbtoylS5eyaNEinn/+eRYtWsSaNWvo7u5udJO1D4ZNOBgKO3bsYMuW\nLXXV0dXVxa5du+qqY/fu3XWf59vZ2Wk4kNQQixcvZteuXSxfvpwTTzyRtrY2li9fztKlS3n55ZdZ\nsmSJkw+HubdUOJAk1W/Xrl0sXryYxYsXN7op2k/84SVJklRiOJAkSSWGA0mSVGI4kCRJJYYDSZJU\nYjiQJEklhgNJklRiOJAkSSWGA0mSVGI4kCRJJYYDSZJUYjiQJEklhgNJklRiOJAkSSXD5iebt23b\nVncdr7/+OmPHjq2rjhEjRjBixIi66uju7qazs7OuOnp6evy9dDF//vxGNwGArVu3sn379kY3Q9IQ\necuFgzFjxtRVR0TQ1FT/gEu9daSU6m6Dhr/58+cfMAFB0sHDwwqSJKnEcCBJkkoMB5IkqcRwIEmS\nSgwHkiSpxHAgSZJKDAeSJKnEcCBJkkoMB5IkqcRwIEmSSgwHkiSpxHAgSZJKDAeSJKnEcCBJkkoM\nB5IkqaSl0Q14MzU1NRERddVR7/q9UkpDUo8kSUNt2ISDpqb6Bzmamppobm4egtZIknTw8rCCJEkq\nMRxIkqQSw4EkSSoxHEiSpBLDgSRJKjEcSJKkEsOBJEkqMRxIkqQSw4EkSSoxHEiSpBLDgSRJKjEc\nSJKkEsOBJEkqMRxIkqQSw4EkSSoxHEiSpBLDgSRJKjEcSJKkEsOBJEkqMRxIkqQSw4EkSSoxHEiS\npBLDgSRJKjEcSJKkEsOBJEkqMRxIkqQSw4EkSSoxHEiSpBLDgSRJKjEcSJKkEsOBJEkqMRxIkqSS\nlkY3YLB27NhRdx3t7e2MGTNmCFqjodbe3j4kr7EkqX6RUmp0GwYlIupu6HHHHcf48eOHojkaYps3\nb2b58uV115NSiiFozoCGoj/q4Gd/1IGklv7oYQVJklRiOJAkSSWGA0mSVGI4kCRJJYYDSZJUYjiQ\nJEklhgNJklRiOJAkSSWGA0mSVGI4kCRJJYYDSZJUYjiQJEklhgNJklRiOJAkSSWGA0mSVGI4kCRJ\nJZFSanQbJEnSAcSRA0mSVGI4kCRJJYYDSZJUYjiQJEklhgNJklRiOJAkSSWGA0mSVGI4kCRJJYYD\nSZJUYjiQJEklhgNJklRiOJAkSSWGA0mSVGI4kCRJJYYDSZJUYjiQJEklhgNJklRiOJAkSSWGA0mS\nVGI4kCRJJYYDSZJUYjiQJEklhgNJklRiOJAkSSWGA0mSVGI4kCRJJYYDSZJUYjiQJEklhgNJklTy\n/wHtSPqqWh2mswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4d0d0f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4ce59f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAADFCAYAAADAHlGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3ba66b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Sampling test indexes\n",
    "idx = random.sample(range(test_x.shape[0]), num_test_sample)\n",
    "\n",
    "# Initialize fraction of test images and heatmap\n",
    "test_fraction = np.zeros([10, img_fraction_size, img_fraction_size, len_stack])\n",
    "heat_map = np.zeros([num_test_sample, img_size, img_size])\n",
    "heat_map_hard = np.zeros([num_test_sample, img_size, img_size]) \n",
    "num_correct = 0.\n",
    "\n",
    "# Test for Sampling data\n",
    "for idx_sample in range(num_test_sample):\n",
    "    \n",
    "    # Making test fractions\n",
    "    index_fraction = 0\n",
    "    for m in range(len_vertical):\n",
    "        start_v = stride * m\n",
    "        for n in range(len_horizontal):\n",
    "            start_h = stride * n\n",
    "\n",
    "            test_fraction[idx_sample,:,:,index_fraction] = test_x[idx[idx_sample], \n",
    "                                                                  start_v : start_v + img_fraction_size, \n",
    "                                                                  start_h : start_h + img_fraction_size]\n",
    "\n",
    "            index_fraction += 1\n",
    "\n",
    "    # Get alpha(weight of fractions) and output for sample test data\n",
    "    alpha_hard_, output_, z_, alpha_ = sess.run([alpha_hard, output, z, alpha],feed_dict = {x_image: [test_fraction[idx_sample,:,:,:]], y_target: [test_y[idx[idx_sample],:]]})\n",
    "    \n",
    "    alpha_hard_reshape = np.reshape(alpha_hard_, (1, len_vertical, len_horizontal))\n",
    "    alpha_reshape = np.reshape(alpha_, (1, len_vertical, len_horizontal))\n",
    "\n",
    "    # Make heatmap with alpha\n",
    "    for i in range(len_vertical):\n",
    "        for j in range(len_horizontal):\n",
    "            heat_map[idx_sample, stride * i : (stride * i + img_fraction_size), stride * j : (stride * j + img_fraction_size)] += alpha_reshape[:, i, j]\n",
    "            heat_map_hard[idx_sample, stride * i : (stride * i + img_fraction_size), stride * j : (stride * j + img_fraction_size)] += alpha_hard_reshape[:, i, j]\n",
    "\n",
    "    heat_map[idx_sample,:,:] = heat_map[idx_sample,:,:] / np.max(heat_map[idx_sample,:,:])\n",
    "    heat_map_hard[idx_sample,:,:] = heat_map_hard[idx_sample,:,:] / np.max(heat_map_hard[idx_sample,:,:])\n",
    "\n",
    "    # Get labels for test samples\n",
    "    y_test_pred = np.argmax(output_[:])\n",
    "    y_test_true = np.argmax(test_y[idx[idx_sample], :])\n",
    "    \n",
    "    # Draw subplot for each sample \n",
    "    f1, ax = plt.subplots(1,3)\n",
    "    ax[0].imshow(heat_map[idx_sample,:,:], cmap='gray')\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title('Heatmap')\n",
    "    ax[1].imshow(heat_map_hard[idx_sample,:,:], cmap='gray')\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title('Heatmap Hard')    \n",
    "    ax[2].imshow(test_x[idx[idx_sample],:,:], cmap='gray')\n",
    "    ax[2].axis(\"off\")\n",
    "    ax[2].set_title('Pred: ' + str(y_test_pred) + ' / ' + 'Label: ' + str(y_test_true))\n",
    "    \n",
    "\n",
    "    # Show results \n",
    "    plt.show()\n",
    "    \n",
    "    # Count correct\n",
    "    if y_test_pred == y_test_true:\n",
    "        num_correct += 1.\n",
    "\n",
    "print('Sample Accuracy: ' + str(num_correct / num_test_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
