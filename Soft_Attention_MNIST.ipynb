{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Soft Attention MNIST\n",
    "\n",
    "This is jupyter notebook for `Soft Attention` from paper [Show, Attend and Tell](https://arxiv.org/abs/1502.03044). \n",
    "This Algorithm will be tested by `Modified MNIST dataset` Which is made by [Jongwon Park](https://github.com/jwpark116). This modified MNIST dataset is good for verifying attention algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (55000, 112, 112)\n",
      "Train label shape: (55000, 10)\n",
      "Test data shape: (9900, 112, 112)\n",
      "Test label shape: (9900, 10)\n",
      "Validation data shape: (100, 112, 112)\n",
      "Validation label shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "\n",
    "mat_data_train = scipy.io.loadmat('MNIST_data_train_re.mat')\n",
    "mat_data_test = scipy.io.loadmat('MNIST_data_test_re.mat')\n",
    "\n",
    "train_x = mat_data_train['X_train']\n",
    "train_y = mat_data_train['Y_train']\n",
    "\n",
    "test_x = mat_data_test['X_test'][:9900, :]\n",
    "test_y = mat_data_test['Y_test'][:9900, :]\n",
    "\n",
    "validation_x = mat_data_test['X_test'][9900:, :]\n",
    "validation_y = mat_data_test['Y_test'][9900:, :]\n",
    "\n",
    "del mat_data_train\n",
    "del mat_data_test\n",
    "\n",
    "print(\"Train data shape: \" + str(train_x.shape))\n",
    "print(\"Train label shape: \" + str(train_y.shape))\n",
    "print(\"Test data shape: \" + str(test_x.shape))\n",
    "print(\"Test label shape: \" + str(test_y.shape))\n",
    "print(\"Validation data shape: \" + str(validation_x.shape))\n",
    "print(\"Validation label shape: \" + str(validation_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal Length: 7\n",
      "Vertical Length: 7\n",
      "Window Length: 49\n"
     ]
    }
   ],
   "source": [
    "# Parameters \n",
    "img_size = train_x.shape[1]\n",
    "img_flat_size = img_size * img_size\n",
    "\n",
    "# If you want to train the model -> True, otherwise -> False\n",
    "Is_train = True\n",
    "\n",
    "# If you want to load saved model -> True, otherwise -> False \n",
    "Load_model = False\n",
    "\n",
    "# Name of the save file\n",
    "save_name = '1'\n",
    "\n",
    "# Numbers of sampling to test the code \n",
    "num_test_sample = 10\n",
    "\n",
    "# labels: 0 - 9\n",
    "num_label = 10\n",
    "\n",
    "# Parameters for training\n",
    "num_epoch = 10\n",
    "\n",
    "learning_rate = 5e-4\n",
    "epsilon = 1e-8\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Parameter for LSTM\n",
    "lstm_size = 256\n",
    "step_size = 4\n",
    "flatten_size = img_size\n",
    "\n",
    "gpu_fraction = 0.5\n",
    "\n",
    "# parameter for attention\n",
    "img_fraction_size = 28\n",
    "stride = 14\n",
    "\n",
    "len_horizontal = int((img_size - img_fraction_size) / stride + 1)\n",
    "len_vertical   = int((img_size - img_fraction_size) / stride + 1)\n",
    "len_stack = len_horizontal * len_vertical\n",
    "\n",
    "print(\"Horizontal Length: \" + str(len_horizontal))\n",
    "print(\"Vertical Length: \" +str(len_vertical))\n",
    "print(\"Window Length: \" +str(len_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Sample Image (Modified MNIST for Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAD/CAYAAAAXKqhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEJFAgSAigQJBRAIFgogECgQRCf4/qLX2YhHnxhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7fc95a190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Plotting example image\n",
    "img = train_x[0, :, :]\n",
    "# img_resize = img.reshape((img_size, img_size))\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()\n",
    "print('Label: ' + str(train_y[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Sample Image Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAEACAYAAACEfgxsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa73928ea10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(len_vertical, len_horizontal)\n",
    "\n",
    "img_fraction = np.zeros([img_fraction_size, img_fraction_size, len_stack])\n",
    "index_fraction = 0\n",
    "for i in range(len_vertical):\n",
    "    start_v = stride * i\n",
    "    for j in range(len_horizontal):\n",
    "        start_h = stride * j\n",
    "                \n",
    "        img_fraction[:,:,index_fraction] = img[start_v : start_v + img_fraction_size, \n",
    "                                               start_h : start_h + img_fraction_size]\n",
    "        \n",
    "        ax[i, j].imshow(img_fraction[:,:,index_fraction], cmap = 'gray')\n",
    "        ax[i, j].axis('off')\n",
    "        \n",
    "        index_fraction += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias \n",
    "def conv2d(x,w, stride):\n",
    "\treturn tf.nn.conv2d(x,w,strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Get Variables\n",
    "def weight_variable(name, shape):\n",
    "    return tf.get_variable(name,shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    return tf.get_variable(name,shape=shape, initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM and Attention function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# LSTM function\n",
    "def LSTM_cell(C_prev, h_prev, x_lstm, Wf, Wi, Wc, Wo, bf, bi, bc, bo):\n",
    "    # C_prev: Cell state from lstm of previous time step (shape: [batch_size, lstm_size])\n",
    "    # h_prev: output from lstm of previous time step (shape: [batch_size, lstm_size])\n",
    "    # x_lstm: input of lstm (shape: [batch_size, data_flatten_size])\n",
    "\n",
    "    input_concat = tf.concat([x_lstm, h_prev], 1)\n",
    "    f = tf.sigmoid(tf.matmul(input_concat, Wf) + bf)\n",
    "    i = tf.sigmoid(tf.matmul(input_concat, Wi) + bi)\n",
    "    c = tf.tanh(tf.matmul(input_concat, Wc) + bc)\n",
    "    o = tf.sigmoid(tf.matmul(input_concat, Wo) + bo)\n",
    "    \n",
    "    C_t = tf.multiply(f, C_prev) + tf.multiply(i, c) \n",
    "    h_t = tf.multiply(o, tf.tanh(C_t))\n",
    "    \n",
    "    return C_t, h_t # Cell state, Output\n",
    "\n",
    "# Soft Attention function\n",
    "def soft_attention(h_prev, a, Wa):\n",
    "    # h_prev: output from lstm of previous time step (shape: [batch_size, lstm_size])\n",
    "    # a: Image windows after CNN. List of convolution window images \n",
    "    # (List len: number of windows, element shape: [batch_size, convolution flatten size])\n",
    "    \n",
    "    m_list = [tf.tanh(tf.matmul(tf.concat([h_prev, a[i]], axis = 1), Wa)) for i in range(len(a))]\n",
    "    m_concat = tf.concat([m_list[i] for i in range(len(a))], axis = 1)\n",
    "    alpha = tf.nn.softmax(m_concat)\n",
    "    z_list = [tf.multiply(a[i], tf.slice(alpha, (0, i), (-1, 1))) for i in range(len(a))]\n",
    "    z_stack = tf.stack(z_list, axis = 2)\n",
    "    z = tf.reduce_sum(z_stack, axis = 2)\n",
    "    return alpha, z\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "# Input \n",
    "x_image  = tf.placeholder(tf.float32, shape = [None, img_fraction_size, img_fraction_size, len_stack])\n",
    "y_target = tf.placeholder(tf.float32, shape=[None, num_label])\n",
    "\n",
    "x_unstack = tf.unstack(x_image, axis = 3)\n",
    "\n",
    "# Convolution variables\n",
    "w_conv1 = weight_variable('W_conv1', [5, 5, 1, 32])\n",
    "b_conv1 = bias_variable('b_conv1', [32])\n",
    "w_conv2 = weight_variable('W_conv2', [1, 1, 32, 16])\n",
    "b_conv2 = bias_variable('b_conv2', [16])\n",
    "\n",
    "conv_list = []\n",
    "for i in range(len_stack):\n",
    "    x_conv = tf.reshape(x_unstack[i], (-1, img_fraction_size, img_fraction_size, 1))\n",
    "    conv1 = tf.nn.relu(conv2d(x_conv, w_conv1, 2) + b_conv1)\n",
    "    pool1 = max_pool_2x2(conv1)\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, w_conv2, 1) + b_conv2)\n",
    "    pool2 = max_pool_2x2(conv2)\n",
    "    conv_result_flat = tf.contrib.layers.flatten(pool2)\n",
    "    conv_list.append(conv_result_flat)\n",
    "\n",
    "len_conv = int(conv_list[0].get_shape()[1])\n",
    "\n",
    "#LSTM Variables\n",
    "Wf = weight_variable('Wf', [len_conv + lstm_size, lstm_size])\n",
    "Wi = weight_variable('Wi', [len_conv + lstm_size, lstm_size])\n",
    "Wc = weight_variable('Wc', [len_conv + lstm_size, lstm_size])\n",
    "Wo = weight_variable('Wo', [len_conv + lstm_size, lstm_size])\n",
    "\n",
    "bf = bias_variable('bf', [lstm_size])\n",
    "bi = bias_variable('bi', [lstm_size])\n",
    "bc = bias_variable('bc', [lstm_size])\n",
    "bo = bias_variable('bo', [lstm_size]) \n",
    "\n",
    "# Attention Variables\n",
    "Wa = weight_variable('Wa', [lstm_size + len_conv, 1])\n",
    "\n",
    "rnn_batch_size = tf.shape(x_image)[0]\n",
    "\n",
    "# Initial lstm cell state and output \n",
    "rnn_state = tf.zeros([rnn_batch_size, lstm_size], tf.float32)\n",
    "rnn_out = tf.zeros([rnn_batch_size, lstm_size], tf.float32)\n",
    "\n",
    "#################################### Attention!!! ####################################\n",
    "for i in range(step_size):\n",
    "    alpha, z = soft_attention(rnn_out, conv_list, Wa)\n",
    "    rnn_state, rnn_out = LSTM_cell(rnn_state, rnn_out, z, Wf, Wi, Wc, Wo, bf, bi, bc, bo)\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "# Densely connect layer variables \n",
    "w_fc1 = weight_variable('w_fc1', [lstm_size, num_label])\n",
    "b_fc1 = bias_variable('b_fc1', [num_label])\n",
    "\n",
    "output = tf.matmul(rnn_out, w_fc1)+b_fc1\n",
    "\n",
    "# Training \n",
    "Loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y_target, logits = output)\n",
    "Cost = tf.reduce_mean(Loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon = epsilon).minimize(Cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_target,1), tf.argmax(output,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "if Load_model == True:\n",
    "    checkpoint = tf.train.get_checkpoint_state(\"saved_networks/\")\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        print(\"Successfully loaded:\", checkpoint.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Could not find old network weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 0/55000 / Cost: 0.59822 / Training Accuracy: 0.0820312 / Validation Accuracy: 0.06\n",
      "Epoch: 1 / Batch: 256/55000 / Cost: 0.556034 / Training Accuracy: 0.0703125 / Validation Accuracy: 0.06\n",
      "Epoch: 1 / Batch: 512/55000 / Cost: 0.513444 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 768/55000 / Cost: 0.47305 / Training Accuracy: 0.113281 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 1024/55000 / Cost: 0.43887 / Training Accuracy: 0.109375 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 1280/55000 / Cost: 0.402899 / Training Accuracy: 0.101562 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 1536/55000 / Cost: 0.374652 / Training Accuracy: 0.0976562 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 1792/55000 / Cost: 0.349168 / Training Accuracy: 0.113281 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 2048/55000 / Cost: 0.33647 / Training Accuracy: 0.0976562 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 2304/55000 / Cost: 0.327807 / Training Accuracy: 0.101562 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 2560/55000 / Cost: 0.32853 / Training Accuracy: 0.09375 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 2816/55000 / Cost: 0.330038 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 3072/55000 / Cost: 0.334514 / Training Accuracy: 0.0742188 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 3328/55000 / Cost: 0.337942 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 3584/55000 / Cost: 0.339278 / Training Accuracy: 0.101562 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 3840/55000 / Cost: 0.341021 / Training Accuracy: 0.105469 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 4096/55000 / Cost: 0.338636 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 4352/55000 / Cost: 0.341443 / Training Accuracy: 0.09375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 4608/55000 / Cost: 0.335527 / Training Accuracy: 0.125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 4864/55000 / Cost: 0.332266 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5120/55000 / Cost: 0.333816 / Training Accuracy: 0.078125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5376/55000 / Cost: 0.32913 / Training Accuracy: 0.125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5632/55000 / Cost: 0.327089 / Training Accuracy: 0.136719 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 5888/55000 / Cost: 0.32794 / Training Accuracy: 0.09375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6144/55000 / Cost: 0.328467 / Training Accuracy: 0.109375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6400/55000 / Cost: 0.329476 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6656/55000 / Cost: 0.33018 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 6912/55000 / Cost: 0.325664 / Training Accuracy: 0.121094 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7168/55000 / Cost: 0.32454 / Training Accuracy: 0.144531 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7424/55000 / Cost: 0.32621 / Training Accuracy: 0.113281 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7680/55000 / Cost: 0.326648 / Training Accuracy: 0.0976562 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 7936/55000 / Cost: 0.325861 / Training Accuracy: 0.140625 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 8192/55000 / Cost: 0.326092 / Training Accuracy: 0.105469 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 8448/55000 / Cost: 0.325604 / Training Accuracy: 0.117188 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 8704/55000 / Cost: 0.326189 / Training Accuracy: 0.109375 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 8960/55000 / Cost: 0.326998 / Training Accuracy: 0.0625 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 9216/55000 / Cost: 0.327023 / Training Accuracy: 0.0742188 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 9472/55000 / Cost: 0.324849 / Training Accuracy: 0.128906 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 9728/55000 / Cost: 0.325368 / Training Accuracy: 0.125 / Validation Accuracy: 0.1\n",
      "Epoch: 1 / Batch: 9984/55000 / Cost: 0.325765 / Training Accuracy: 0.09375 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 10240/55000 / Cost: 0.327358 / Training Accuracy: 0.09375 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 10496/55000 / Cost: 0.325778 / Training Accuracy: 0.109375 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 10752/55000 / Cost: 0.326435 / Training Accuracy: 0.0976562 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 11008/55000 / Cost: 0.324206 / Training Accuracy: 0.113281 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 11264/55000 / Cost: 0.324338 / Training Accuracy: 0.128906 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 11520/55000 / Cost: 0.325427 / Training Accuracy: 0.132812 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 11776/55000 / Cost: 0.325062 / Training Accuracy: 0.105469 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 12032/55000 / Cost: 0.324795 / Training Accuracy: 0.0976562 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 12288/55000 / Cost: 0.326264 / Training Accuracy: 0.0625 / Validation Accuracy: 0.07\n",
      "Epoch: 1 / Batch: 12544/55000 / Cost: 0.325332 / Training Accuracy: 0.09375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 12800/55000 / Cost: 0.32507 / Training Accuracy: 0.128906 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 13056/55000 / Cost: 0.324693 / Training Accuracy: 0.113281 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 13312/55000 / Cost: 0.325376 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 13568/55000 / Cost: 0.325681 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 13824/55000 / Cost: 0.325419 / Training Accuracy: 0.113281 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 14080/55000 / Cost: 0.324998 / Training Accuracy: 0.101562 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 14336/55000 / Cost: 0.324064 / Training Accuracy: 0.128906 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 14592/55000 / Cost: 0.325402 / Training Accuracy: 0.109375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 14848/55000 / Cost: 0.324893 / Training Accuracy: 0.132812 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 15104/55000 / Cost: 0.325274 / Training Accuracy: 0.128906 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 15360/55000 / Cost: 0.326358 / Training Accuracy: 0.0898438 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 15616/55000 / Cost: 0.326639 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 15872/55000 / Cost: 0.326371 / Training Accuracy: 0.105469 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 16128/55000 / Cost: 0.324586 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 16384/55000 / Cost: 0.325331 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 16640/55000 / Cost: 0.324822 / Training Accuracy: 0.113281 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 16896/55000 / Cost: 0.326073 / Training Accuracy: 0.109375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 17152/55000 / Cost: 0.325138 / Training Accuracy: 0.113281 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 17408/55000 / Cost: 0.325292 / Training Accuracy: 0.121094 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 17664/55000 / Cost: 0.324791 / Training Accuracy: 0.132812 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 17920/55000 / Cost: 0.324693 / Training Accuracy: 0.101562 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 18176/55000 / Cost: 0.323769 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 18432/55000 / Cost: 0.32544 / Training Accuracy: 0.09375 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 18688/55000 / Cost: 0.32445 / Training Accuracy: 0.078125 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 18944/55000 / Cost: 0.324848 / Training Accuracy: 0.128906 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 19200/55000 / Cost: 0.325188 / Training Accuracy: 0.117188 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 19456/55000 / Cost: 0.327307 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 19712/55000 / Cost: 0.324986 / Training Accuracy: 0.132812 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 19968/55000 / Cost: 0.324803 / Training Accuracy: 0.128906 / Validation Accuracy: 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 20224/55000 / Cost: 0.32568 / Training Accuracy: 0.109375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 20480/55000 / Cost: 0.324075 / Training Accuracy: 0.109375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 20736/55000 / Cost: 0.324669 / Training Accuracy: 0.09375 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 20992/55000 / Cost: 0.325614 / Training Accuracy: 0.0820312 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 21248/55000 / Cost: 0.324216 / Training Accuracy: 0.1875 / Validation Accuracy: 0.18\n",
      "Epoch: 1 / Batch: 21504/55000 / Cost: 0.325419 / Training Accuracy: 0.0703125 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 21760/55000 / Cost: 0.32508 / Training Accuracy: 0.144531 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 22016/55000 / Cost: 0.324778 / Training Accuracy: 0.125 / Validation Accuracy: 0.11\n",
      "Epoch: 1 / Batch: 22272/55000 / Cost: 0.324418 / Training Accuracy: 0.160156 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 22528/55000 / Cost: 0.32463 / Training Accuracy: 0.125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 22784/55000 / Cost: 0.324877 / Training Accuracy: 0.105469 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 23040/55000 / Cost: 0.324206 / Training Accuracy: 0.101562 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 23296/55000 / Cost: 0.326018 / Training Accuracy: 0.132812 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 23552/55000 / Cost: 0.323977 / Training Accuracy: 0.148438 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 23808/55000 / Cost: 0.326202 / Training Accuracy: 0.0976562 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 24064/55000 / Cost: 0.324633 / Training Accuracy: 0.105469 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 24320/55000 / Cost: 0.324722 / Training Accuracy: 0.125 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 24576/55000 / Cost: 0.324231 / Training Accuracy: 0.121094 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 24832/55000 / Cost: 0.324544 / Training Accuracy: 0.113281 / Validation Accuracy: 0.12\n",
      "Epoch: 1 / Batch: 25088/55000 / Cost: 0.326727 / Training Accuracy: 0.0976562 / Validation Accuracy: 0.13\n",
      "Epoch: 1 / Batch: 25344/55000 / Cost: 0.325188 / Training Accuracy: 0.128906 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 25600/55000 / Cost: 0.325559 / Training Accuracy: 0.144531 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 25856/55000 / Cost: 0.324839 / Training Accuracy: 0.144531 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 26112/55000 / Cost: 0.324963 / Training Accuracy: 0.113281 / Validation Accuracy: 0.14\n",
      "Epoch: 1 / Batch: 26368/55000 / Cost: 0.324169 / Training Accuracy: 0.121094 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 26624/55000 / Cost: 0.324903 / Training Accuracy: 0.101562 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 26880/55000 / Cost: 0.325179 / Training Accuracy: 0.109375 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 27136/55000 / Cost: 0.324641 / Training Accuracy: 0.0859375 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 27392/55000 / Cost: 0.324677 / Training Accuracy: 0.078125 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 27648/55000 / Cost: 0.324004 / Training Accuracy: 0.117188 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 27904/55000 / Cost: 0.324901 / Training Accuracy: 0.0820312 / Validation Accuracy: 0.09\n",
      "Epoch: 1 / Batch: 28160/55000 / Cost: 0.324588 / Training Accuracy: 0.113281 / Validation Accuracy: 0.16\n",
      "Epoch: 1 / Batch: 28416/55000 / Cost: 0.324341 / Training Accuracy: 0.105469 / Validation Accuracy: 0.13\n",
      "Epoch: 1 / Batch: 28672/55000 / Cost: 0.323586 / Training Accuracy: 0.144531 / Validation Accuracy: 0.14\n",
      "Epoch: 1 / Batch: 28928/55000 / Cost: 0.324259 / Training Accuracy: 0.121094 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 29184/55000 / Cost: 0.322656 / Training Accuracy: 0.144531 / Validation Accuracy: 0.14\n",
      "Epoch: 1 / Batch: 29440/55000 / Cost: 0.322592 / Training Accuracy: 0.128906 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 29696/55000 / Cost: 0.323786 / Training Accuracy: 0.160156 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 29952/55000 / Cost: 0.322188 / Training Accuracy: 0.234375 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 30208/55000 / Cost: 0.321989 / Training Accuracy: 0.238281 / Validation Accuracy: 0.19\n",
      "Epoch: 1 / Batch: 30464/55000 / Cost: 0.321823 / Training Accuracy: 0.195312 / Validation Accuracy: 0.18\n",
      "Epoch: 1 / Batch: 30720/55000 / Cost: 0.3227 / Training Accuracy: 0.195312 / Validation Accuracy: 0.15\n",
      "Epoch: 1 / Batch: 30976/55000 / Cost: 0.321351 / Training Accuracy: 0.210938 / Validation Accuracy: 0.19\n",
      "Epoch: 1 / Batch: 31232/55000 / Cost: 0.321925 / Training Accuracy: 0.179688 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 31488/55000 / Cost: 0.320916 / Training Accuracy: 0.195312 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 31744/55000 / Cost: 0.318365 / Training Accuracy: 0.222656 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 32000/55000 / Cost: 0.319082 / Training Accuracy: 0.203125 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 32256/55000 / Cost: 0.322228 / Training Accuracy: 0.15625 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 32512/55000 / Cost: 0.317635 / Training Accuracy: 0.210938 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 32768/55000 / Cost: 0.318783 / Training Accuracy: 0.15625 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 33024/55000 / Cost: 0.317862 / Training Accuracy: 0.1875 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 33280/55000 / Cost: 0.316584 / Training Accuracy: 0.191406 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 33536/55000 / Cost: 0.316233 / Training Accuracy: 0.175781 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 33792/55000 / Cost: 0.31542 / Training Accuracy: 0.195312 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 34048/55000 / Cost: 0.313658 / Training Accuracy: 0.230469 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 34304/55000 / Cost: 0.311718 / Training Accuracy: 0.214844 / Validation Accuracy: 0.19\n",
      "Epoch: 1 / Batch: 34560/55000 / Cost: 0.312954 / Training Accuracy: 0.230469 / Validation Accuracy: 0.2\n",
      "Epoch: 1 / Batch: 34816/55000 / Cost: 0.311352 / Training Accuracy: 0.191406 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 35072/55000 / Cost: 0.311411 / Training Accuracy: 0.214844 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 35328/55000 / Cost: 0.311594 / Training Accuracy: 0.210938 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 35584/55000 / Cost: 0.311017 / Training Accuracy: 0.226562 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 35840/55000 / Cost: 0.307232 / Training Accuracy: 0.214844 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 36096/55000 / Cost: 0.310353 / Training Accuracy: 0.21875 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 36352/55000 / Cost: 0.30597 / Training Accuracy: 0.210938 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 36608/55000 / Cost: 0.311547 / Training Accuracy: 0.179688 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 36864/55000 / Cost: 0.306217 / Training Accuracy: 0.207031 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 37120/55000 / Cost: 0.306492 / Training Accuracy: 0.203125 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 37376/55000 / Cost: 0.309368 / Training Accuracy: 0.199219 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 37632/55000 / Cost: 0.302617 / Training Accuracy: 0.242188 / Validation Accuracy: 0.19\n",
      "Epoch: 1 / Batch: 37888/55000 / Cost: 0.308607 / Training Accuracy: 0.171875 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 38144/55000 / Cost: 0.309461 / Training Accuracy: 0.195312 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 38400/55000 / Cost: 0.302096 / Training Accuracy: 0.222656 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 38656/55000 / Cost: 0.310034 / Training Accuracy: 0.230469 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 38912/55000 / Cost: 0.307595 / Training Accuracy: 0.234375 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 39168/55000 / Cost: 0.311206 / Training Accuracy: 0.175781 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 39424/55000 / Cost: 0.294418 / Training Accuracy: 0.277344 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 39680/55000 / Cost: 0.304823 / Training Accuracy: 0.210938 / Validation Accuracy: 0.33\n",
      "Epoch: 1 / Batch: 39936/55000 / Cost: 0.30444 / Training Accuracy: 0.238281 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 40192/55000 / Cost: 0.304508 / Training Accuracy: 0.203125 / Validation Accuracy: 0.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 40448/55000 / Cost: 0.303533 / Training Accuracy: 0.179688 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 40704/55000 / Cost: 0.312688 / Training Accuracy: 0.167969 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 40960/55000 / Cost: 0.309529 / Training Accuracy: 0.164062 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 41216/55000 / Cost: 0.303984 / Training Accuracy: 0.226562 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 41472/55000 / Cost: 0.308787 / Training Accuracy: 0.183594 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 41728/55000 / Cost: 0.311859 / Training Accuracy: 0.191406 / Validation Accuracy: 0.21\n",
      "Epoch: 1 / Batch: 41984/55000 / Cost: 0.299838 / Training Accuracy: 0.257812 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 42240/55000 / Cost: 0.300017 / Training Accuracy: 0.226562 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 42496/55000 / Cost: 0.303196 / Training Accuracy: 0.214844 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 42752/55000 / Cost: 0.309151 / Training Accuracy: 0.152344 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 43008/55000 / Cost: 0.307278 / Training Accuracy: 0.183594 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 43264/55000 / Cost: 0.305805 / Training Accuracy: 0.199219 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 43520/55000 / Cost: 0.303367 / Training Accuracy: 0.203125 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 43776/55000 / Cost: 0.306402 / Training Accuracy: 0.203125 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 44032/55000 / Cost: 0.299525 / Training Accuracy: 0.230469 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 44288/55000 / Cost: 0.302146 / Training Accuracy: 0.222656 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 44544/55000 / Cost: 0.305885 / Training Accuracy: 0.195312 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 44800/55000 / Cost: 0.299956 / Training Accuracy: 0.234375 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 45056/55000 / Cost: 0.304438 / Training Accuracy: 0.257812 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 45312/55000 / Cost: 0.30815 / Training Accuracy: 0.25 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 45568/55000 / Cost: 0.312535 / Training Accuracy: 0.195312 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 45824/55000 / Cost: 0.297414 / Training Accuracy: 0.285156 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 46080/55000 / Cost: 0.301023 / Training Accuracy: 0.25 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 46336/55000 / Cost: 0.300388 / Training Accuracy: 0.230469 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 46592/55000 / Cost: 0.298515 / Training Accuracy: 0.226562 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 46848/55000 / Cost: 0.309695 / Training Accuracy: 0.214844 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 47104/55000 / Cost: 0.304563 / Training Accuracy: 0.230469 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 47360/55000 / Cost: 0.297858 / Training Accuracy: 0.257812 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 47616/55000 / Cost: 0.30347 / Training Accuracy: 0.238281 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 47872/55000 / Cost: 0.301158 / Training Accuracy: 0.234375 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 48128/55000 / Cost: 0.300437 / Training Accuracy: 0.246094 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 48384/55000 / Cost: 0.29929 / Training Accuracy: 0.199219 / Validation Accuracy: 0.26\n",
      "Epoch: 1 / Batch: 48640/55000 / Cost: 0.302663 / Training Accuracy: 0.222656 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 48896/55000 / Cost: 0.30021 / Training Accuracy: 0.242188 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 49152/55000 / Cost: 0.303586 / Training Accuracy: 0.226562 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 49408/55000 / Cost: 0.308047 / Training Accuracy: 0.210938 / Validation Accuracy: 0.28\n",
      "Epoch: 1 / Batch: 49664/55000 / Cost: 0.299452 / Training Accuracy: 0.226562 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 49920/55000 / Cost: 0.300782 / Training Accuracy: 0.21875 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 50176/55000 / Cost: 0.300584 / Training Accuracy: 0.214844 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 50432/55000 / Cost: 0.30379 / Training Accuracy: 0.210938 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 50688/55000 / Cost: 0.294601 / Training Accuracy: 0.292969 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 50944/55000 / Cost: 0.298707 / Training Accuracy: 0.253906 / Validation Accuracy: 0.25\n",
      "Epoch: 1 / Batch: 51200/55000 / Cost: 0.298035 / Training Accuracy: 0.21875 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 51456/55000 / Cost: 0.29549 / Training Accuracy: 0.21875 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 51712/55000 / Cost: 0.295335 / Training Accuracy: 0.222656 / Validation Accuracy: 0.22\n",
      "Epoch: 1 / Batch: 51968/55000 / Cost: 0.300617 / Training Accuracy: 0.199219 / Validation Accuracy: 0.23\n",
      "Epoch: 1 / Batch: 52224/55000 / Cost: 0.299719 / Training Accuracy: 0.238281 / Validation Accuracy: 0.24\n",
      "Epoch: 1 / Batch: 52480/55000 / Cost: 0.301014 / Training Accuracy: 0.246094 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 52736/55000 / Cost: 0.295376 / Training Accuracy: 0.222656 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 52992/55000 / Cost: 0.301043 / Training Accuracy: 0.230469 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 53248/55000 / Cost: 0.299363 / Training Accuracy: 0.222656 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 53504/55000 / Cost: 0.297649 / Training Accuracy: 0.253906 / Validation Accuracy: 0.31\n",
      "Epoch: 1 / Batch: 53760/55000 / Cost: 0.298796 / Training Accuracy: 0.242188 / Validation Accuracy: 0.29\n",
      "Epoch: 1 / Batch: 54016/55000 / Cost: 0.290588 / Training Accuracy: 0.246094 / Validation Accuracy: 0.27\n",
      "Epoch: 1 / Batch: 54272/55000 / Cost: 0.307358 / Training Accuracy: 0.207031 / Validation Accuracy: 0.3\n",
      "Epoch: 1 / Batch: 54528/55000 / Cost: 0.295415 / Training Accuracy: 0.257812 / Validation Accuracy: 0.32\n",
      "Epoch: 1 / Batch: 54784/55000 / Cost: 0.297944 / Training Accuracy: 0.259259 / Validation Accuracy: 0.3\n",
      "Model is saved!!!\n",
      "Epoch: 2 / Batch: 0/55000 / Cost: 0.296173 / Training Accuracy: 0.226562 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 256/55000 / Cost: 0.301176 / Training Accuracy: 0.207031 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 512/55000 / Cost: 0.301737 / Training Accuracy: 0.226562 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 768/55000 / Cost: 0.295351 / Training Accuracy: 0.285156 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 1024/55000 / Cost: 0.298206 / Training Accuracy: 0.253906 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 1280/55000 / Cost: 0.293414 / Training Accuracy: 0.261719 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 1536/55000 / Cost: 0.29994 / Training Accuracy: 0.234375 / Validation Accuracy: 0.25\n",
      "Epoch: 2 / Batch: 1792/55000 / Cost: 0.297776 / Training Accuracy: 0.242188 / Validation Accuracy: 0.25\n",
      "Epoch: 2 / Batch: 2048/55000 / Cost: 0.294395 / Training Accuracy: 0.234375 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 2304/55000 / Cost: 0.299208 / Training Accuracy: 0.242188 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 2560/55000 / Cost: 0.303612 / Training Accuracy: 0.203125 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 2816/55000 / Cost: 0.29828 / Training Accuracy: 0.199219 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 3072/55000 / Cost: 0.295759 / Training Accuracy: 0.25 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 3328/55000 / Cost: 0.295303 / Training Accuracy: 0.21875 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 3584/55000 / Cost: 0.294914 / Training Accuracy: 0.230469 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 3840/55000 / Cost: 0.292178 / Training Accuracy: 0.207031 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 4096/55000 / Cost: 0.29703 / Training Accuracy: 0.226562 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 4352/55000 / Cost: 0.290376 / Training Accuracy: 0.246094 / Validation Accuracy: 0.25\n",
      "Epoch: 2 / Batch: 4608/55000 / Cost: 0.292165 / Training Accuracy: 0.226562 / Validation Accuracy: 0.24\n",
      "Epoch: 2 / Batch: 4864/55000 / Cost: 0.296111 / Training Accuracy: 0.191406 / Validation Accuracy: 0.22\n",
      "Epoch: 2 / Batch: 5120/55000 / Cost: 0.293374 / Training Accuracy: 0.210938 / Validation Accuracy: 0.2\n",
      "Epoch: 2 / Batch: 5376/55000 / Cost: 0.293043 / Training Accuracy: 0.269531 / Validation Accuracy: 0.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / Batch: 5632/55000 / Cost: 0.296033 / Training Accuracy: 0.226562 / Validation Accuracy: 0.23\n",
      "Epoch: 2 / Batch: 5888/55000 / Cost: 0.300476 / Training Accuracy: 0.230469 / Validation Accuracy: 0.25\n",
      "Epoch: 2 / Batch: 6144/55000 / Cost: 0.30248 / Training Accuracy: 0.222656 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 6400/55000 / Cost: 0.297679 / Training Accuracy: 0.207031 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 6656/55000 / Cost: 0.298947 / Training Accuracy: 0.222656 / Validation Accuracy: 0.27\n",
      "Epoch: 2 / Batch: 6912/55000 / Cost: 0.285773 / Training Accuracy: 0.277344 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 7168/55000 / Cost: 0.292915 / Training Accuracy: 0.242188 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 7424/55000 / Cost: 0.292365 / Training Accuracy: 0.28125 / Validation Accuracy: 0.26\n",
      "Epoch: 2 / Batch: 7680/55000 / Cost: 0.299283 / Training Accuracy: 0.210938 / Validation Accuracy: 0.26\n",
      "Epoch: 2 / Batch: 7936/55000 / Cost: 0.289018 / Training Accuracy: 0.25 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 8192/55000 / Cost: 0.289885 / Training Accuracy: 0.25 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 8448/55000 / Cost: 0.295488 / Training Accuracy: 0.179688 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 8704/55000 / Cost: 0.288277 / Training Accuracy: 0.261719 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 8960/55000 / Cost: 0.281231 / Training Accuracy: 0.289062 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 9216/55000 / Cost: 0.295711 / Training Accuracy: 0.25 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 9472/55000 / Cost: 0.288651 / Training Accuracy: 0.226562 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 9728/55000 / Cost: 0.299151 / Training Accuracy: 0.226562 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 9984/55000 / Cost: 0.295035 / Training Accuracy: 0.242188 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 10240/55000 / Cost: 0.292891 / Training Accuracy: 0.234375 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 10496/55000 / Cost: 0.296252 / Training Accuracy: 0.25 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 10752/55000 / Cost: 0.291408 / Training Accuracy: 0.277344 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 11008/55000 / Cost: 0.287395 / Training Accuracy: 0.261719 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 11264/55000 / Cost: 0.295133 / Training Accuracy: 0.265625 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 11520/55000 / Cost: 0.284469 / Training Accuracy: 0.261719 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 11776/55000 / Cost: 0.29792 / Training Accuracy: 0.195312 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 12032/55000 / Cost: 0.283951 / Training Accuracy: 0.253906 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 12288/55000 / Cost: 0.276005 / Training Accuracy: 0.296875 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 12544/55000 / Cost: 0.284652 / Training Accuracy: 0.277344 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 12800/55000 / Cost: 0.279398 / Training Accuracy: 0.277344 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 13056/55000 / Cost: 0.286868 / Training Accuracy: 0.253906 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 13312/55000 / Cost: 0.282586 / Training Accuracy: 0.277344 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 13568/55000 / Cost: 0.285108 / Training Accuracy: 0.261719 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 13824/55000 / Cost: 0.287631 / Training Accuracy: 0.25 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 14080/55000 / Cost: 0.285011 / Training Accuracy: 0.261719 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 14336/55000 / Cost: 0.28815 / Training Accuracy: 0.246094 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 14592/55000 / Cost: 0.301415 / Training Accuracy: 0.21875 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 14848/55000 / Cost: 0.276876 / Training Accuracy: 0.261719 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 15104/55000 / Cost: 0.28193 / Training Accuracy: 0.28125 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 15360/55000 / Cost: 0.289934 / Training Accuracy: 0.21875 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 15616/55000 / Cost: 0.274208 / Training Accuracy: 0.304688 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 15872/55000 / Cost: 0.280821 / Training Accuracy: 0.285156 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 16128/55000 / Cost: 0.288154 / Training Accuracy: 0.230469 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 16384/55000 / Cost: 0.286254 / Training Accuracy: 0.273438 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 16640/55000 / Cost: 0.282375 / Training Accuracy: 0.289062 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 16896/55000 / Cost: 0.278576 / Training Accuracy: 0.28125 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 17152/55000 / Cost: 0.278276 / Training Accuracy: 0.269531 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 17408/55000 / Cost: 0.284532 / Training Accuracy: 0.277344 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 17664/55000 / Cost: 0.286638 / Training Accuracy: 0.269531 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 17920/55000 / Cost: 0.288928 / Training Accuracy: 0.242188 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 18176/55000 / Cost: 0.272159 / Training Accuracy: 0.328125 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 18432/55000 / Cost: 0.280165 / Training Accuracy: 0.269531 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 18688/55000 / Cost: 0.283696 / Training Accuracy: 0.273438 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 18944/55000 / Cost: 0.292794 / Training Accuracy: 0.25 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 19200/55000 / Cost: 0.278305 / Training Accuracy: 0.273438 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 19456/55000 / Cost: 0.277807 / Training Accuracy: 0.269531 / Validation Accuracy: 0.27\n",
      "Epoch: 2 / Batch: 19712/55000 / Cost: 0.280174 / Training Accuracy: 0.300781 / Validation Accuracy: 0.27\n",
      "Epoch: 2 / Batch: 19968/55000 / Cost: 0.27651 / Training Accuracy: 0.292969 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 20224/55000 / Cost: 0.28376 / Training Accuracy: 0.261719 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 20480/55000 / Cost: 0.270024 / Training Accuracy: 0.3125 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 20736/55000 / Cost: 0.285035 / Training Accuracy: 0.269531 / Validation Accuracy: 0.28\n",
      "Epoch: 2 / Batch: 20992/55000 / Cost: 0.28131 / Training Accuracy: 0.269531 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 21248/55000 / Cost: 0.289829 / Training Accuracy: 0.25 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 21504/55000 / Cost: 0.278047 / Training Accuracy: 0.273438 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 21760/55000 / Cost: 0.277364 / Training Accuracy: 0.296875 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 22016/55000 / Cost: 0.272809 / Training Accuracy: 0.320312 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 22272/55000 / Cost: 0.275318 / Training Accuracy: 0.273438 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 22528/55000 / Cost: 0.276964 / Training Accuracy: 0.296875 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 22784/55000 / Cost: 0.271359 / Training Accuracy: 0.269531 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 23040/55000 / Cost: 0.27361 / Training Accuracy: 0.285156 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 23296/55000 / Cost: 0.281115 / Training Accuracy: 0.269531 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 23552/55000 / Cost: 0.271293 / Training Accuracy: 0.289062 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 23808/55000 / Cost: 0.261782 / Training Accuracy: 0.34375 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 24064/55000 / Cost: 0.27318 / Training Accuracy: 0.277344 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 24320/55000 / Cost: 0.278174 / Training Accuracy: 0.292969 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 24576/55000 / Cost: 0.26933 / Training Accuracy: 0.289062 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 24832/55000 / Cost: 0.263768 / Training Accuracy: 0.300781 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 25088/55000 / Cost: 0.275932 / Training Accuracy: 0.269531 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 25344/55000 / Cost: 0.272846 / Training Accuracy: 0.28125 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 25600/55000 / Cost: 0.263767 / Training Accuracy: 0.34375 / Validation Accuracy: 0.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / Batch: 25856/55000 / Cost: 0.263419 / Training Accuracy: 0.324219 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 26112/55000 / Cost: 0.258209 / Training Accuracy: 0.324219 / Validation Accuracy: 0.29\n",
      "Epoch: 2 / Batch: 26368/55000 / Cost: 0.270191 / Training Accuracy: 0.304688 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 26624/55000 / Cost: 0.272288 / Training Accuracy: 0.28125 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 26880/55000 / Cost: 0.266985 / Training Accuracy: 0.308594 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 27136/55000 / Cost: 0.265656 / Training Accuracy: 0.332031 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 27392/55000 / Cost: 0.258707 / Training Accuracy: 0.359375 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 27648/55000 / Cost: 0.269175 / Training Accuracy: 0.316406 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 27904/55000 / Cost: 0.271623 / Training Accuracy: 0.296875 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 28160/55000 / Cost: 0.273579 / Training Accuracy: 0.28125 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 28416/55000 / Cost: 0.280245 / Training Accuracy: 0.292969 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 28672/55000 / Cost: 0.258218 / Training Accuracy: 0.363281 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 28928/55000 / Cost: 0.272141 / Training Accuracy: 0.289062 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 29184/55000 / Cost: 0.268211 / Training Accuracy: 0.335938 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 29440/55000 / Cost: 0.271783 / Training Accuracy: 0.285156 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 29696/55000 / Cost: 0.253265 / Training Accuracy: 0.351562 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 29952/55000 / Cost: 0.26305 / Training Accuracy: 0.324219 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 30208/55000 / Cost: 0.278984 / Training Accuracy: 0.257812 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 30464/55000 / Cost: 0.270116 / Training Accuracy: 0.253906 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 30720/55000 / Cost: 0.27407 / Training Accuracy: 0.285156 / Validation Accuracy: 0.26\n",
      "Epoch: 2 / Batch: 30976/55000 / Cost: 0.278961 / Training Accuracy: 0.242188 / Validation Accuracy: 0.26\n",
      "Epoch: 2 / Batch: 31232/55000 / Cost: 0.269789 / Training Accuracy: 0.320312 / Validation Accuracy: 0.3\n",
      "Epoch: 2 / Batch: 31488/55000 / Cost: 0.278982 / Training Accuracy: 0.257812 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 31744/55000 / Cost: 0.268518 / Training Accuracy: 0.34375 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 32000/55000 / Cost: 0.261751 / Training Accuracy: 0.34375 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 32256/55000 / Cost: 0.278388 / Training Accuracy: 0.285156 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 32512/55000 / Cost: 0.260883 / Training Accuracy: 0.304688 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 32768/55000 / Cost: 0.260974 / Training Accuracy: 0.320312 / Validation Accuracy: 0.4\n",
      "Epoch: 2 / Batch: 33024/55000 / Cost: 0.265547 / Training Accuracy: 0.316406 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 33280/55000 / Cost: 0.272201 / Training Accuracy: 0.335938 / Validation Accuracy: 0.32\n",
      "Epoch: 2 / Batch: 33536/55000 / Cost: 0.263957 / Training Accuracy: 0.304688 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 33792/55000 / Cost: 0.253465 / Training Accuracy: 0.316406 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 34048/55000 / Cost: 0.25063 / Training Accuracy: 0.359375 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 34304/55000 / Cost: 0.252695 / Training Accuracy: 0.378906 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 34560/55000 / Cost: 0.259732 / Training Accuracy: 0.3125 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 34816/55000 / Cost: 0.251328 / Training Accuracy: 0.375 / Validation Accuracy: 0.4\n",
      "Epoch: 2 / Batch: 35072/55000 / Cost: 0.250401 / Training Accuracy: 0.363281 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 35328/55000 / Cost: 0.246184 / Training Accuracy: 0.359375 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 35584/55000 / Cost: 0.241544 / Training Accuracy: 0.359375 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 35840/55000 / Cost: 0.262619 / Training Accuracy: 0.300781 / Validation Accuracy: 0.34\n",
      "Epoch: 2 / Batch: 36096/55000 / Cost: 0.25406 / Training Accuracy: 0.378906 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 36352/55000 / Cost: 0.251474 / Training Accuracy: 0.351562 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 36608/55000 / Cost: 0.25937 / Training Accuracy: 0.351562 / Validation Accuracy: 0.36\n",
      "Epoch: 2 / Batch: 36864/55000 / Cost: 0.248455 / Training Accuracy: 0.40625 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 37120/55000 / Cost: 0.253091 / Training Accuracy: 0.351562 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 37376/55000 / Cost: 0.26254 / Training Accuracy: 0.339844 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 37632/55000 / Cost: 0.242063 / Training Accuracy: 0.382812 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 37888/55000 / Cost: 0.251525 / Training Accuracy: 0.402344 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 38144/55000 / Cost: 0.245782 / Training Accuracy: 0.390625 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 38400/55000 / Cost: 0.256255 / Training Accuracy: 0.363281 / Validation Accuracy: 0.31\n",
      "Epoch: 2 / Batch: 38656/55000 / Cost: 0.248844 / Training Accuracy: 0.386719 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 38912/55000 / Cost: 0.257754 / Training Accuracy: 0.34375 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 39168/55000 / Cost: 0.260421 / Training Accuracy: 0.324219 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 39424/55000 / Cost: 0.249338 / Training Accuracy: 0.339844 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 39680/55000 / Cost: 0.25539 / Training Accuracy: 0.339844 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 39936/55000 / Cost: 0.237109 / Training Accuracy: 0.441406 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 40192/55000 / Cost: 0.248851 / Training Accuracy: 0.402344 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 40448/55000 / Cost: 0.264458 / Training Accuracy: 0.296875 / Validation Accuracy: 0.39\n",
      "Epoch: 2 / Batch: 40704/55000 / Cost: 0.239015 / Training Accuracy: 0.394531 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 40960/55000 / Cost: 0.230777 / Training Accuracy: 0.441406 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 41216/55000 / Cost: 0.243094 / Training Accuracy: 0.414062 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 41472/55000 / Cost: 0.23837 / Training Accuracy: 0.4375 / Validation Accuracy: 0.39\n",
      "Epoch: 2 / Batch: 41728/55000 / Cost: 0.245066 / Training Accuracy: 0.382812 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 41984/55000 / Cost: 0.244815 / Training Accuracy: 0.390625 / Validation Accuracy: 0.33\n",
      "Epoch: 2 / Batch: 42240/55000 / Cost: 0.240187 / Training Accuracy: 0.351562 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 42496/55000 / Cost: 0.250585 / Training Accuracy: 0.390625 / Validation Accuracy: 0.39\n",
      "Epoch: 2 / Batch: 42752/55000 / Cost: 0.24412 / Training Accuracy: 0.386719 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 43008/55000 / Cost: 0.240309 / Training Accuracy: 0.394531 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 43264/55000 / Cost: 0.249286 / Training Accuracy: 0.359375 / Validation Accuracy: 0.37\n",
      "Epoch: 2 / Batch: 43520/55000 / Cost: 0.244489 / Training Accuracy: 0.386719 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 43776/55000 / Cost: 0.235768 / Training Accuracy: 0.410156 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 44032/55000 / Cost: 0.246549 / Training Accuracy: 0.402344 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 44288/55000 / Cost: 0.241378 / Training Accuracy: 0.429688 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 44544/55000 / Cost: 0.247588 / Training Accuracy: 0.351562 / Validation Accuracy: 0.35\n",
      "Epoch: 2 / Batch: 44800/55000 / Cost: 0.245356 / Training Accuracy: 0.367188 / Validation Accuracy: 0.4\n",
      "Epoch: 2 / Batch: 45056/55000 / Cost: 0.230414 / Training Accuracy: 0.460938 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 45312/55000 / Cost: 0.2385 / Training Accuracy: 0.414062 / Validation Accuracy: 0.41\n",
      "Epoch: 2 / Batch: 45568/55000 / Cost: 0.239879 / Training Accuracy: 0.402344 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 45824/55000 / Cost: 0.243889 / Training Accuracy: 0.417969 / Validation Accuracy: 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / Batch: 46080/55000 / Cost: 0.235779 / Training Accuracy: 0.425781 / Validation Accuracy: 0.38\n",
      "Epoch: 2 / Batch: 46336/55000 / Cost: 0.24172 / Training Accuracy: 0.386719 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 46592/55000 / Cost: 0.240247 / Training Accuracy: 0.398438 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 46848/55000 / Cost: 0.221809 / Training Accuracy: 0.515625 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 47104/55000 / Cost: 0.2495 / Training Accuracy: 0.371094 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 47360/55000 / Cost: 0.256089 / Training Accuracy: 0.332031 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 47616/55000 / Cost: 0.231673 / Training Accuracy: 0.445312 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 47872/55000 / Cost: 0.229271 / Training Accuracy: 0.453125 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 48128/55000 / Cost: 0.239621 / Training Accuracy: 0.414062 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 48384/55000 / Cost: 0.222568 / Training Accuracy: 0.46875 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 48640/55000 / Cost: 0.243003 / Training Accuracy: 0.355469 / Validation Accuracy: 0.39\n",
      "Epoch: 2 / Batch: 48896/55000 / Cost: 0.224396 / Training Accuracy: 0.484375 / Validation Accuracy: 0.4\n",
      "Epoch: 2 / Batch: 49152/55000 / Cost: 0.237044 / Training Accuracy: 0.421875 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 49408/55000 / Cost: 0.234716 / Training Accuracy: 0.441406 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 49664/55000 / Cost: 0.227751 / Training Accuracy: 0.480469 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 49920/55000 / Cost: 0.236981 / Training Accuracy: 0.421875 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 50176/55000 / Cost: 0.226394 / Training Accuracy: 0.460938 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 50432/55000 / Cost: 0.22333 / Training Accuracy: 0.472656 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 50688/55000 / Cost: 0.231244 / Training Accuracy: 0.414062 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 50944/55000 / Cost: 0.235679 / Training Accuracy: 0.414062 / Validation Accuracy: 0.43\n",
      "Epoch: 2 / Batch: 51200/55000 / Cost: 0.222388 / Training Accuracy: 0.445312 / Validation Accuracy: 0.44\n",
      "Epoch: 2 / Batch: 51456/55000 / Cost: 0.233854 / Training Accuracy: 0.472656 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 51712/55000 / Cost: 0.227863 / Training Accuracy: 0.433594 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 51968/55000 / Cost: 0.237451 / Training Accuracy: 0.410156 / Validation Accuracy: 0.49\n",
      "Epoch: 2 / Batch: 52224/55000 / Cost: 0.22953 / Training Accuracy: 0.460938 / Validation Accuracy: 0.47\n",
      "Epoch: 2 / Batch: 52480/55000 / Cost: 0.216401 / Training Accuracy: 0.460938 / Validation Accuracy: 0.46\n",
      "Epoch: 2 / Batch: 52736/55000 / Cost: 0.217487 / Training Accuracy: 0.519531 / Validation Accuracy: 0.47\n",
      "Epoch: 2 / Batch: 52992/55000 / Cost: 0.223316 / Training Accuracy: 0.433594 / Validation Accuracy: 0.47\n",
      "Epoch: 2 / Batch: 53248/55000 / Cost: 0.221106 / Training Accuracy: 0.492188 / Validation Accuracy: 0.45\n",
      "Epoch: 2 / Batch: 53504/55000 / Cost: 0.221992 / Training Accuracy: 0.453125 / Validation Accuracy: 0.42\n",
      "Epoch: 2 / Batch: 53760/55000 / Cost: 0.225662 / Training Accuracy: 0.433594 / Validation Accuracy: 0.49\n",
      "Epoch: 2 / Batch: 54016/55000 / Cost: 0.224686 / Training Accuracy: 0.476562 / Validation Accuracy: 0.5\n",
      "Epoch: 2 / Batch: 54272/55000 / Cost: 0.234415 / Training Accuracy: 0.402344 / Validation Accuracy: 0.48\n",
      "Epoch: 2 / Batch: 54528/55000 / Cost: 0.227712 / Training Accuracy: 0.484375 / Validation Accuracy: 0.49\n",
      "Epoch: 2 / Batch: 54784/55000 / Cost: 0.242291 / Training Accuracy: 0.365741 / Validation Accuracy: 0.46\n",
      "Model is saved!!!\n",
      "Epoch: 3 / Batch: 0/55000 / Cost: 0.226136 / Training Accuracy: 0.429688 / Validation Accuracy: 0.41\n",
      "Epoch: 3 / Batch: 256/55000 / Cost: 0.22992 / Training Accuracy: 0.441406 / Validation Accuracy: 0.41\n",
      "Epoch: 3 / Batch: 512/55000 / Cost: 0.221397 / Training Accuracy: 0.441406 / Validation Accuracy: 0.46\n",
      "Epoch: 3 / Batch: 768/55000 / Cost: 0.231563 / Training Accuracy: 0.410156 / Validation Accuracy: 0.46\n",
      "Epoch: 3 / Batch: 1024/55000 / Cost: 0.223078 / Training Accuracy: 0.441406 / Validation Accuracy: 0.5\n",
      "Epoch: 3 / Batch: 1280/55000 / Cost: 0.218081 / Training Accuracy: 0.480469 / Validation Accuracy: 0.51\n",
      "Epoch: 3 / Batch: 1536/55000 / Cost: 0.221607 / Training Accuracy: 0.4375 / Validation Accuracy: 0.43\n",
      "Epoch: 3 / Batch: 1792/55000 / Cost: 0.223143 / Training Accuracy: 0.425781 / Validation Accuracy: 0.43\n",
      "Epoch: 3 / Batch: 2048/55000 / Cost: 0.229576 / Training Accuracy: 0.449219 / Validation Accuracy: 0.47\n",
      "Epoch: 3 / Batch: 2304/55000 / Cost: 0.213335 / Training Accuracy: 0.503906 / Validation Accuracy: 0.49\n",
      "Epoch: 3 / Batch: 2560/55000 / Cost: 0.21166 / Training Accuracy: 0.484375 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 2816/55000 / Cost: 0.229839 / Training Accuracy: 0.429688 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 3072/55000 / Cost: 0.220215 / Training Accuracy: 0.472656 / Validation Accuracy: 0.48\n",
      "Epoch: 3 / Batch: 3328/55000 / Cost: 0.223421 / Training Accuracy: 0.4375 / Validation Accuracy: 0.46\n",
      "Epoch: 3 / Batch: 3584/55000 / Cost: 0.215226 / Training Accuracy: 0.496094 / Validation Accuracy: 0.43\n",
      "Epoch: 3 / Batch: 3840/55000 / Cost: 0.232517 / Training Accuracy: 0.433594 / Validation Accuracy: 0.43\n",
      "Epoch: 3 / Batch: 4096/55000 / Cost: 0.215859 / Training Accuracy: 0.464844 / Validation Accuracy: 0.5\n",
      "Epoch: 3 / Batch: 4352/55000 / Cost: 0.216536 / Training Accuracy: 0.5 / Validation Accuracy: 0.46\n",
      "Epoch: 3 / Batch: 4608/55000 / Cost: 0.208094 / Training Accuracy: 0.503906 / Validation Accuracy: 0.49\n",
      "Epoch: 3 / Batch: 4864/55000 / Cost: 0.212427 / Training Accuracy: 0.503906 / Validation Accuracy: 0.47\n",
      "Epoch: 3 / Batch: 5120/55000 / Cost: 0.215584 / Training Accuracy: 0.492188 / Validation Accuracy: 0.45\n",
      "Epoch: 3 / Batch: 5376/55000 / Cost: 0.202767 / Training Accuracy: 0.539062 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 5632/55000 / Cost: 0.21454 / Training Accuracy: 0.476562 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 5888/55000 / Cost: 0.220068 / Training Accuracy: 0.441406 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 6144/55000 / Cost: 0.23025 / Training Accuracy: 0.449219 / Validation Accuracy: 0.51\n",
      "Epoch: 3 / Batch: 6400/55000 / Cost: 0.223487 / Training Accuracy: 0.507812 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 6656/55000 / Cost: 0.230375 / Training Accuracy: 0.441406 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 6912/55000 / Cost: 0.210381 / Training Accuracy: 0.480469 / Validation Accuracy: 0.5\n",
      "Epoch: 3 / Batch: 7168/55000 / Cost: 0.22507 / Training Accuracy: 0.476562 / Validation Accuracy: 0.47\n",
      "Epoch: 3 / Batch: 7424/55000 / Cost: 0.224054 / Training Accuracy: 0.492188 / Validation Accuracy: 0.45\n",
      "Epoch: 3 / Batch: 7680/55000 / Cost: 0.203615 / Training Accuracy: 0.519531 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 7936/55000 / Cost: 0.211845 / Training Accuracy: 0.53125 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 8192/55000 / Cost: 0.214814 / Training Accuracy: 0.5 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 8448/55000 / Cost: 0.216473 / Training Accuracy: 0.472656 / Validation Accuracy: 0.49\n",
      "Epoch: 3 / Batch: 8704/55000 / Cost: 0.225173 / Training Accuracy: 0.476562 / Validation Accuracy: 0.51\n",
      "Epoch: 3 / Batch: 8960/55000 / Cost: 0.203548 / Training Accuracy: 0.496094 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 9216/55000 / Cost: 0.210365 / Training Accuracy: 0.46875 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 9472/55000 / Cost: 0.199645 / Training Accuracy: 0.515625 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 9728/55000 / Cost: 0.203814 / Training Accuracy: 0.53125 / Validation Accuracy: 0.5\n",
      "Epoch: 3 / Batch: 9984/55000 / Cost: 0.203281 / Training Accuracy: 0.527344 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 10240/55000 / Cost: 0.208478 / Training Accuracy: 0.496094 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 10496/55000 / Cost: 0.207145 / Training Accuracy: 0.507812 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 10752/55000 / Cost: 0.207171 / Training Accuracy: 0.503906 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 11008/55000 / Cost: 0.20982 / Training Accuracy: 0.515625 / Validation Accuracy: 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / Batch: 11264/55000 / Cost: 0.215038 / Training Accuracy: 0.480469 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 11520/55000 / Cost: 0.214398 / Training Accuracy: 0.542969 / Validation Accuracy: 0.5\n",
      "Epoch: 3 / Batch: 11776/55000 / Cost: 0.212003 / Training Accuracy: 0.492188 / Validation Accuracy: 0.48\n",
      "Epoch: 3 / Batch: 12032/55000 / Cost: 0.201648 / Training Accuracy: 0.496094 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 12288/55000 / Cost: 0.219362 / Training Accuracy: 0.460938 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 12544/55000 / Cost: 0.211043 / Training Accuracy: 0.496094 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 12800/55000 / Cost: 0.208052 / Training Accuracy: 0.523438 / Validation Accuracy: 0.43\n",
      "Epoch: 3 / Batch: 13056/55000 / Cost: 0.211847 / Training Accuracy: 0.472656 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 13312/55000 / Cost: 0.207104 / Training Accuracy: 0.472656 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 13568/55000 / Cost: 0.194042 / Training Accuracy: 0.550781 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 13824/55000 / Cost: 0.196638 / Training Accuracy: 0.574219 / Validation Accuracy: 0.47\n",
      "Epoch: 3 / Batch: 14080/55000 / Cost: 0.195676 / Training Accuracy: 0.527344 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 14336/55000 / Cost: 0.207141 / Training Accuracy: 0.550781 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 14592/55000 / Cost: 0.202102 / Training Accuracy: 0.519531 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 14848/55000 / Cost: 0.213799 / Training Accuracy: 0.484375 / Validation Accuracy: 0.48\n",
      "Epoch: 3 / Batch: 15104/55000 / Cost: 0.202885 / Training Accuracy: 0.542969 / Validation Accuracy: 0.49\n",
      "Epoch: 3 / Batch: 15360/55000 / Cost: 0.21387 / Training Accuracy: 0.488281 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 15616/55000 / Cost: 0.209969 / Training Accuracy: 0.492188 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 15872/55000 / Cost: 0.192632 / Training Accuracy: 0.554688 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 16128/55000 / Cost: 0.191978 / Training Accuracy: 0.558594 / Validation Accuracy: 0.49\n",
      "Epoch: 3 / Batch: 16384/55000 / Cost: 0.203914 / Training Accuracy: 0.519531 / Validation Accuracy: 0.49\n",
      "Epoch: 3 / Batch: 16640/55000 / Cost: 0.191289 / Training Accuracy: 0.539062 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 16896/55000 / Cost: 0.207766 / Training Accuracy: 0.515625 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 17152/55000 / Cost: 0.206641 / Training Accuracy: 0.535156 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 17408/55000 / Cost: 0.19268 / Training Accuracy: 0.550781 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 17664/55000 / Cost: 0.196171 / Training Accuracy: 0.542969 / Validation Accuracy: 0.47\n",
      "Epoch: 3 / Batch: 17920/55000 / Cost: 0.194768 / Training Accuracy: 0.554688 / Validation Accuracy: 0.5\n",
      "Epoch: 3 / Batch: 18176/55000 / Cost: 0.194039 / Training Accuracy: 0.527344 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 18432/55000 / Cost: 0.192615 / Training Accuracy: 0.53125 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 18688/55000 / Cost: 0.187801 / Training Accuracy: 0.585938 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 18944/55000 / Cost: 0.196385 / Training Accuracy: 0.542969 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 19200/55000 / Cost: 0.195773 / Training Accuracy: 0.527344 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 19456/55000 / Cost: 0.209255 / Training Accuracy: 0.5 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 19712/55000 / Cost: 0.197266 / Training Accuracy: 0.515625 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 19968/55000 / Cost: 0.189914 / Training Accuracy: 0.542969 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 20224/55000 / Cost: 0.201607 / Training Accuracy: 0.550781 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 20480/55000 / Cost: 0.185737 / Training Accuracy: 0.578125 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 20736/55000 / Cost: 0.183873 / Training Accuracy: 0.554688 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 20992/55000 / Cost: 0.198334 / Training Accuracy: 0.546875 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 21248/55000 / Cost: 0.181408 / Training Accuracy: 0.570312 / Validation Accuracy: 0.65\n",
      "Epoch: 3 / Batch: 21504/55000 / Cost: 0.185482 / Training Accuracy: 0.585938 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 21760/55000 / Cost: 0.19263 / Training Accuracy: 0.5625 / Validation Accuracy: 0.47\n",
      "Epoch: 3 / Batch: 22016/55000 / Cost: 0.204643 / Training Accuracy: 0.527344 / Validation Accuracy: 0.48\n",
      "Epoch: 3 / Batch: 22272/55000 / Cost: 0.208338 / Training Accuracy: 0.511719 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 22528/55000 / Cost: 0.203114 / Training Accuracy: 0.542969 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 22784/55000 / Cost: 0.206727 / Training Accuracy: 0.496094 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 23040/55000 / Cost: 0.182825 / Training Accuracy: 0.585938 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 23296/55000 / Cost: 0.195443 / Training Accuracy: 0.558594 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 23552/55000 / Cost: 0.182249 / Training Accuracy: 0.582031 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 23808/55000 / Cost: 0.180461 / Training Accuracy: 0.609375 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 24064/55000 / Cost: 0.19728 / Training Accuracy: 0.515625 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 24320/55000 / Cost: 0.186512 / Training Accuracy: 0.570312 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 24576/55000 / Cost: 0.19123 / Training Accuracy: 0.574219 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 24832/55000 / Cost: 0.180492 / Training Accuracy: 0.613281 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 25088/55000 / Cost: 0.182192 / Training Accuracy: 0.59375 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 25344/55000 / Cost: 0.184427 / Training Accuracy: 0.621094 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 25600/55000 / Cost: 0.185122 / Training Accuracy: 0.597656 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 25856/55000 / Cost: 0.187855 / Training Accuracy: 0.597656 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 26112/55000 / Cost: 0.175026 / Training Accuracy: 0.613281 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 26368/55000 / Cost: 0.196574 / Training Accuracy: 0.574219 / Validation Accuracy: 0.5\n",
      "Epoch: 3 / Batch: 26624/55000 / Cost: 0.180654 / Training Accuracy: 0.5625 / Validation Accuracy: 0.52\n",
      "Epoch: 3 / Batch: 26880/55000 / Cost: 0.184258 / Training Accuracy: 0.570312 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 27136/55000 / Cost: 0.18754 / Training Accuracy: 0.570312 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 27392/55000 / Cost: 0.199046 / Training Accuracy: 0.539062 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 27648/55000 / Cost: 0.195623 / Training Accuracy: 0.558594 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 27904/55000 / Cost: 0.197002 / Training Accuracy: 0.570312 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 28160/55000 / Cost: 0.183666 / Training Accuracy: 0.582031 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 28416/55000 / Cost: 0.189758 / Training Accuracy: 0.578125 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 28672/55000 / Cost: 0.199332 / Training Accuracy: 0.550781 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 28928/55000 / Cost: 0.194479 / Training Accuracy: 0.550781 / Validation Accuracy: 0.51\n",
      "Epoch: 3 / Batch: 29184/55000 / Cost: 0.189731 / Training Accuracy: 0.582031 / Validation Accuracy: 0.54\n",
      "Epoch: 3 / Batch: 29440/55000 / Cost: 0.17282 / Training Accuracy: 0.640625 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 29696/55000 / Cost: 0.181006 / Training Accuracy: 0.582031 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 29952/55000 / Cost: 0.168744 / Training Accuracy: 0.605469 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 30208/55000 / Cost: 0.179306 / Training Accuracy: 0.582031 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 30464/55000 / Cost: 0.180011 / Training Accuracy: 0.570312 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 30720/55000 / Cost: 0.19436 / Training Accuracy: 0.570312 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 30976/55000 / Cost: 0.197002 / Training Accuracy: 0.527344 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 31232/55000 / Cost: 0.173953 / Training Accuracy: 0.597656 / Validation Accuracy: 0.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / Batch: 31488/55000 / Cost: 0.173027 / Training Accuracy: 0.636719 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 31744/55000 / Cost: 0.185853 / Training Accuracy: 0.59375 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 32000/55000 / Cost: 0.176299 / Training Accuracy: 0.632812 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 32256/55000 / Cost: 0.181362 / Training Accuracy: 0.617188 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 32512/55000 / Cost: 0.190339 / Training Accuracy: 0.539062 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 32768/55000 / Cost: 0.175237 / Training Accuracy: 0.605469 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 33024/55000 / Cost: 0.168438 / Training Accuracy: 0.644531 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 33280/55000 / Cost: 0.171958 / Training Accuracy: 0.597656 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 33536/55000 / Cost: 0.183288 / Training Accuracy: 0.597656 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 33792/55000 / Cost: 0.171541 / Training Accuracy: 0.617188 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 34048/55000 / Cost: 0.186437 / Training Accuracy: 0.566406 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 34304/55000 / Cost: 0.171275 / Training Accuracy: 0.640625 / Validation Accuracy: 0.65\n",
      "Epoch: 3 / Batch: 34560/55000 / Cost: 0.172091 / Training Accuracy: 0.597656 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 34816/55000 / Cost: 0.16812 / Training Accuracy: 0.625 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 35072/55000 / Cost: 0.182578 / Training Accuracy: 0.570312 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 35328/55000 / Cost: 0.177945 / Training Accuracy: 0.601562 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 35584/55000 / Cost: 0.186795 / Training Accuracy: 0.558594 / Validation Accuracy: 0.55\n",
      "Epoch: 3 / Batch: 35840/55000 / Cost: 0.183989 / Training Accuracy: 0.589844 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 36096/55000 / Cost: 0.188362 / Training Accuracy: 0.550781 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 36352/55000 / Cost: 0.17143 / Training Accuracy: 0.640625 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 36608/55000 / Cost: 0.174339 / Training Accuracy: 0.59375 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 36864/55000 / Cost: 0.162103 / Training Accuracy: 0.664062 / Validation Accuracy: 0.65\n",
      "Epoch: 3 / Batch: 37120/55000 / Cost: 0.174645 / Training Accuracy: 0.585938 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 37376/55000 / Cost: 0.179456 / Training Accuracy: 0.59375 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 37632/55000 / Cost: 0.157953 / Training Accuracy: 0.707031 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 37888/55000 / Cost: 0.172857 / Training Accuracy: 0.632812 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 38144/55000 / Cost: 0.165898 / Training Accuracy: 0.675781 / Validation Accuracy: 0.68\n",
      "Epoch: 3 / Batch: 38400/55000 / Cost: 0.174237 / Training Accuracy: 0.636719 / Validation Accuracy: 0.69\n",
      "Epoch: 3 / Batch: 38656/55000 / Cost: 0.167877 / Training Accuracy: 0.664062 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 38912/55000 / Cost: 0.181993 / Training Accuracy: 0.59375 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 39168/55000 / Cost: 0.166594 / Training Accuracy: 0.625 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 39424/55000 / Cost: 0.16963 / Training Accuracy: 0.613281 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 39680/55000 / Cost: 0.169532 / Training Accuracy: 0.636719 / Validation Accuracy: 0.65\n",
      "Epoch: 3 / Batch: 39936/55000 / Cost: 0.174156 / Training Accuracy: 0.625 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 40192/55000 / Cost: 0.161129 / Training Accuracy: 0.683594 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 40448/55000 / Cost: 0.160996 / Training Accuracy: 0.617188 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 40704/55000 / Cost: 0.175929 / Training Accuracy: 0.621094 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 40960/55000 / Cost: 0.186731 / Training Accuracy: 0.574219 / Validation Accuracy: 0.53\n",
      "Epoch: 3 / Batch: 41216/55000 / Cost: 0.1715 / Training Accuracy: 0.621094 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 41472/55000 / Cost: 0.167476 / Training Accuracy: 0.613281 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 41728/55000 / Cost: 0.162921 / Training Accuracy: 0.691406 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 41984/55000 / Cost: 0.15519 / Training Accuracy: 0.707031 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 42240/55000 / Cost: 0.169925 / Training Accuracy: 0.613281 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 42496/55000 / Cost: 0.159932 / Training Accuracy: 0.652344 / Validation Accuracy: 0.6\n",
      "Epoch: 3 / Batch: 42752/55000 / Cost: 0.170413 / Training Accuracy: 0.589844 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 43008/55000 / Cost: 0.171555 / Training Accuracy: 0.605469 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 43264/55000 / Cost: 0.17077 / Training Accuracy: 0.625 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 43520/55000 / Cost: 0.1663 / Training Accuracy: 0.65625 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 43776/55000 / Cost: 0.171023 / Training Accuracy: 0.613281 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 44032/55000 / Cost: 0.165178 / Training Accuracy: 0.660156 / Validation Accuracy: 0.65\n",
      "Epoch: 3 / Batch: 44288/55000 / Cost: 0.182469 / Training Accuracy: 0.601562 / Validation Accuracy: 0.65\n",
      "Epoch: 3 / Batch: 44544/55000 / Cost: 0.162865 / Training Accuracy: 0.632812 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 44800/55000 / Cost: 0.18027 / Training Accuracy: 0.613281 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 45056/55000 / Cost: 0.157739 / Training Accuracy: 0.691406 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 45312/55000 / Cost: 0.145986 / Training Accuracy: 0.660156 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 45568/55000 / Cost: 0.154709 / Training Accuracy: 0.664062 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 45824/55000 / Cost: 0.178456 / Training Accuracy: 0.585938 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 46080/55000 / Cost: 0.16987 / Training Accuracy: 0.636719 / Validation Accuracy: 0.51\n",
      "Epoch: 3 / Batch: 46336/55000 / Cost: 0.156644 / Training Accuracy: 0.640625 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 46592/55000 / Cost: 0.168288 / Training Accuracy: 0.660156 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 46848/55000 / Cost: 0.172172 / Training Accuracy: 0.613281 / Validation Accuracy: 0.66\n",
      "Epoch: 3 / Batch: 47104/55000 / Cost: 0.17653 / Training Accuracy: 0.671875 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 47360/55000 / Cost: 0.181149 / Training Accuracy: 0.574219 / Validation Accuracy: 0.65\n",
      "Epoch: 3 / Batch: 47616/55000 / Cost: 0.16955 / Training Accuracy: 0.648438 / Validation Accuracy: 0.69\n",
      "Epoch: 3 / Batch: 47872/55000 / Cost: 0.172122 / Training Accuracy: 0.609375 / Validation Accuracy: 0.68\n",
      "Epoch: 3 / Batch: 48128/55000 / Cost: 0.152711 / Training Accuracy: 0.695312 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 48384/55000 / Cost: 0.17129 / Training Accuracy: 0.613281 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 48640/55000 / Cost: 0.149296 / Training Accuracy: 0.695312 / Validation Accuracy: 0.67\n",
      "Epoch: 3 / Batch: 48896/55000 / Cost: 0.148102 / Training Accuracy: 0.71875 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 49152/55000 / Cost: 0.165519 / Training Accuracy: 0.636719 / Validation Accuracy: 0.61\n",
      "Epoch: 3 / Batch: 49408/55000 / Cost: 0.168061 / Training Accuracy: 0.632812 / Validation Accuracy: 0.56\n",
      "Epoch: 3 / Batch: 49664/55000 / Cost: 0.158035 / Training Accuracy: 0.664062 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 49920/55000 / Cost: 0.161245 / Training Accuracy: 0.652344 / Validation Accuracy: 0.66\n",
      "Epoch: 3 / Batch: 50176/55000 / Cost: 0.164622 / Training Accuracy: 0.65625 / Validation Accuracy: 0.73\n",
      "Epoch: 3 / Batch: 50432/55000 / Cost: 0.165339 / Training Accuracy: 0.667969 / Validation Accuracy: 0.71\n",
      "Epoch: 3 / Batch: 50688/55000 / Cost: 0.16524 / Training Accuracy: 0.632812 / Validation Accuracy: 0.66\n",
      "Epoch: 3 / Batch: 50944/55000 / Cost: 0.165538 / Training Accuracy: 0.671875 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 51200/55000 / Cost: 0.146234 / Training Accuracy: 0.675781 / Validation Accuracy: 0.58\n",
      "Epoch: 3 / Batch: 51456/55000 / Cost: 0.1626 / Training Accuracy: 0.65625 / Validation Accuracy: 0.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / Batch: 51712/55000 / Cost: 0.164226 / Training Accuracy: 0.625 / Validation Accuracy: 0.7\n",
      "Epoch: 3 / Batch: 51968/55000 / Cost: 0.153082 / Training Accuracy: 0.703125 / Validation Accuracy: 0.71\n",
      "Epoch: 3 / Batch: 52224/55000 / Cost: 0.151491 / Training Accuracy: 0.707031 / Validation Accuracy: 0.68\n",
      "Epoch: 3 / Batch: 52480/55000 / Cost: 0.158945 / Training Accuracy: 0.664062 / Validation Accuracy: 0.62\n",
      "Epoch: 3 / Batch: 52736/55000 / Cost: 0.152104 / Training Accuracy: 0.691406 / Validation Accuracy: 0.64\n",
      "Epoch: 3 / Batch: 52992/55000 / Cost: 0.144119 / Training Accuracy: 0.699219 / Validation Accuracy: 0.67\n",
      "Epoch: 3 / Batch: 53248/55000 / Cost: 0.151017 / Training Accuracy: 0.660156 / Validation Accuracy: 0.68\n",
      "Epoch: 3 / Batch: 53504/55000 / Cost: 0.147629 / Training Accuracy: 0.683594 / Validation Accuracy: 0.63\n",
      "Epoch: 3 / Batch: 53760/55000 / Cost: 0.15901 / Training Accuracy: 0.628906 / Validation Accuracy: 0.57\n",
      "Epoch: 3 / Batch: 54016/55000 / Cost: 0.164992 / Training Accuracy: 0.628906 / Validation Accuracy: 0.59\n",
      "Epoch: 3 / Batch: 54272/55000 / Cost: 0.143822 / Training Accuracy: 0.691406 / Validation Accuracy: 0.66\n",
      "Epoch: 3 / Batch: 54528/55000 / Cost: 0.160748 / Training Accuracy: 0.671875 / Validation Accuracy: 0.68\n",
      "Epoch: 3 / Batch: 54784/55000 / Cost: 0.155033 / Training Accuracy: 0.671296 / Validation Accuracy: 0.7\n",
      "Model is saved!!!\n",
      "Epoch: 4 / Batch: 0/55000 / Cost: 0.144492 / Training Accuracy: 0.699219 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 256/55000 / Cost: 0.160273 / Training Accuracy: 0.644531 / Validation Accuracy: 0.62\n",
      "Epoch: 4 / Batch: 512/55000 / Cost: 0.161569 / Training Accuracy: 0.660156 / Validation Accuracy: 0.63\n",
      "Epoch: 4 / Batch: 768/55000 / Cost: 0.151469 / Training Accuracy: 0.710938 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 1024/55000 / Cost: 0.150921 / Training Accuracy: 0.703125 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 1280/55000 / Cost: 0.154586 / Training Accuracy: 0.71875 / Validation Accuracy: 0.66\n",
      "Epoch: 4 / Batch: 1536/55000 / Cost: 0.161111 / Training Accuracy: 0.6875 / Validation Accuracy: 0.62\n",
      "Epoch: 4 / Batch: 1792/55000 / Cost: 0.152099 / Training Accuracy: 0.683594 / Validation Accuracy: 0.67\n",
      "Epoch: 4 / Batch: 2048/55000 / Cost: 0.143414 / Training Accuracy: 0.734375 / Validation Accuracy: 0.65\n",
      "Epoch: 4 / Batch: 2304/55000 / Cost: 0.161369 / Training Accuracy: 0.621094 / Validation Accuracy: 0.66\n",
      "Epoch: 4 / Batch: 2560/55000 / Cost: 0.15518 / Training Accuracy: 0.660156 / Validation Accuracy: 0.65\n",
      "Epoch: 4 / Batch: 2816/55000 / Cost: 0.15594 / Training Accuracy: 0.664062 / Validation Accuracy: 0.62\n",
      "Epoch: 4 / Batch: 3072/55000 / Cost: 0.16052 / Training Accuracy: 0.664062 / Validation Accuracy: 0.6\n",
      "Epoch: 4 / Batch: 3328/55000 / Cost: 0.151306 / Training Accuracy: 0.6875 / Validation Accuracy: 0.65\n",
      "Epoch: 4 / Batch: 3584/55000 / Cost: 0.142397 / Training Accuracy: 0.714844 / Validation Accuracy: 0.67\n",
      "Epoch: 4 / Batch: 3840/55000 / Cost: 0.160346 / Training Accuracy: 0.632812 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 4096/55000 / Cost: 0.153258 / Training Accuracy: 0.648438 / Validation Accuracy: 0.66\n",
      "Epoch: 4 / Batch: 4352/55000 / Cost: 0.15512 / Training Accuracy: 0.699219 / Validation Accuracy: 0.6\n",
      "Epoch: 4 / Batch: 4608/55000 / Cost: 0.148479 / Training Accuracy: 0.6875 / Validation Accuracy: 0.62\n",
      "Epoch: 4 / Batch: 4864/55000 / Cost: 0.133277 / Training Accuracy: 0.757812 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 5120/55000 / Cost: 0.133523 / Training Accuracy: 0.726562 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 5376/55000 / Cost: 0.150761 / Training Accuracy: 0.683594 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 5632/55000 / Cost: 0.156372 / Training Accuracy: 0.648438 / Validation Accuracy: 0.67\n",
      "Epoch: 4 / Batch: 5888/55000 / Cost: 0.146716 / Training Accuracy: 0.757812 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 6144/55000 / Cost: 0.140139 / Training Accuracy: 0.707031 / Validation Accuracy: 0.65\n",
      "Epoch: 4 / Batch: 6400/55000 / Cost: 0.14292 / Training Accuracy: 0.707031 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 6656/55000 / Cost: 0.146102 / Training Accuracy: 0.726562 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 6912/55000 / Cost: 0.149767 / Training Accuracy: 0.683594 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 7168/55000 / Cost: 0.144805 / Training Accuracy: 0.703125 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 7424/55000 / Cost: 0.156297 / Training Accuracy: 0.644531 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 7680/55000 / Cost: 0.136488 / Training Accuracy: 0.734375 / Validation Accuracy: 0.67\n",
      "Epoch: 4 / Batch: 7936/55000 / Cost: 0.151182 / Training Accuracy: 0.710938 / Validation Accuracy: 0.69\n",
      "Epoch: 4 / Batch: 8192/55000 / Cost: 0.154234 / Training Accuracy: 0.675781 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 8448/55000 / Cost: 0.132047 / Training Accuracy: 0.75 / Validation Accuracy: 0.66\n",
      "Epoch: 4 / Batch: 8704/55000 / Cost: 0.142821 / Training Accuracy: 0.714844 / Validation Accuracy: 0.64\n",
      "Epoch: 4 / Batch: 8960/55000 / Cost: 0.139173 / Training Accuracy: 0.742188 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 9216/55000 / Cost: 0.151147 / Training Accuracy: 0.710938 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 9472/55000 / Cost: 0.140148 / Training Accuracy: 0.707031 / Validation Accuracy: 0.69\n",
      "Epoch: 4 / Batch: 9728/55000 / Cost: 0.153361 / Training Accuracy: 0.695312 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 9984/55000 / Cost: 0.140618 / Training Accuracy: 0.707031 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 10240/55000 / Cost: 0.145537 / Training Accuracy: 0.730469 / Validation Accuracy: 0.66\n",
      "Epoch: 4 / Batch: 10496/55000 / Cost: 0.135035 / Training Accuracy: 0.734375 / Validation Accuracy: 0.67\n",
      "Epoch: 4 / Batch: 10752/55000 / Cost: 0.150072 / Training Accuracy: 0.6875 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 11008/55000 / Cost: 0.132292 / Training Accuracy: 0.761719 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 11264/55000 / Cost: 0.126521 / Training Accuracy: 0.777344 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 11520/55000 / Cost: 0.156227 / Training Accuracy: 0.695312 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 11776/55000 / Cost: 0.134423 / Training Accuracy: 0.734375 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 12032/55000 / Cost: 0.127319 / Training Accuracy: 0.757812 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 12288/55000 / Cost: 0.127519 / Training Accuracy: 0.75 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 12544/55000 / Cost: 0.130801 / Training Accuracy: 0.738281 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 12800/55000 / Cost: 0.122774 / Training Accuracy: 0.777344 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 13056/55000 / Cost: 0.146168 / Training Accuracy: 0.707031 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 13312/55000 / Cost: 0.158599 / Training Accuracy: 0.648438 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 13568/55000 / Cost: 0.148732 / Training Accuracy: 0.675781 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 13824/55000 / Cost: 0.148134 / Training Accuracy: 0.691406 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 14080/55000 / Cost: 0.13516 / Training Accuracy: 0.714844 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 14336/55000 / Cost: 0.140552 / Training Accuracy: 0.742188 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 14592/55000 / Cost: 0.136266 / Training Accuracy: 0.742188 / Validation Accuracy: 0.69\n",
      "Epoch: 4 / Batch: 14848/55000 / Cost: 0.16077 / Training Accuracy: 0.679688 / Validation Accuracy: 0.69\n",
      "Epoch: 4 / Batch: 15104/55000 / Cost: 0.130669 / Training Accuracy: 0.746094 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 15360/55000 / Cost: 0.138689 / Training Accuracy: 0.695312 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 15616/55000 / Cost: 0.152001 / Training Accuracy: 0.691406 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 15872/55000 / Cost: 0.131706 / Training Accuracy: 0.765625 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 16128/55000 / Cost: 0.140713 / Training Accuracy: 0.734375 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 16384/55000 / Cost: 0.128377 / Training Accuracy: 0.730469 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 16640/55000 / Cost: 0.120963 / Training Accuracy: 0.769531 / Validation Accuracy: 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / Batch: 16896/55000 / Cost: 0.140622 / Training Accuracy: 0.722656 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 17152/55000 / Cost: 0.147739 / Training Accuracy: 0.707031 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 17408/55000 / Cost: 0.132305 / Training Accuracy: 0.765625 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 17664/55000 / Cost: 0.1259 / Training Accuracy: 0.734375 / Validation Accuracy: 0.65\n",
      "Epoch: 4 / Batch: 17920/55000 / Cost: 0.131338 / Training Accuracy: 0.734375 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 18176/55000 / Cost: 0.131892 / Training Accuracy: 0.773438 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 18432/55000 / Cost: 0.139588 / Training Accuracy: 0.722656 / Validation Accuracy: 0.69\n",
      "Epoch: 4 / Batch: 18688/55000 / Cost: 0.13361 / Training Accuracy: 0.742188 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 18944/55000 / Cost: 0.13561 / Training Accuracy: 0.746094 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 19200/55000 / Cost: 0.131248 / Training Accuracy: 0.734375 / Validation Accuracy: 0.69\n",
      "Epoch: 4 / Batch: 19456/55000 / Cost: 0.131338 / Training Accuracy: 0.757812 / Validation Accuracy: 0.65\n",
      "Epoch: 4 / Batch: 19712/55000 / Cost: 0.12923 / Training Accuracy: 0.773438 / Validation Accuracy: 0.69\n",
      "Epoch: 4 / Batch: 19968/55000 / Cost: 0.136214 / Training Accuracy: 0.730469 / Validation Accuracy: 0.68\n",
      "Epoch: 4 / Batch: 20224/55000 / Cost: 0.128165 / Training Accuracy: 0.753906 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 20480/55000 / Cost: 0.123252 / Training Accuracy: 0.742188 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 20736/55000 / Cost: 0.133831 / Training Accuracy: 0.738281 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 20992/55000 / Cost: 0.125654 / Training Accuracy: 0.761719 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 21248/55000 / Cost: 0.121714 / Training Accuracy: 0.757812 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 21504/55000 / Cost: 0.121556 / Training Accuracy: 0.757812 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 21760/55000 / Cost: 0.142692 / Training Accuracy: 0.722656 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 22016/55000 / Cost: 0.137971 / Training Accuracy: 0.699219 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 22272/55000 / Cost: 0.120846 / Training Accuracy: 0.792969 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 22528/55000 / Cost: 0.129512 / Training Accuracy: 0.75 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 22784/55000 / Cost: 0.12524 / Training Accuracy: 0.742188 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 23040/55000 / Cost: 0.134219 / Training Accuracy: 0.730469 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 23296/55000 / Cost: 0.120461 / Training Accuracy: 0.792969 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 23552/55000 / Cost: 0.128487 / Training Accuracy: 0.75 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 23808/55000 / Cost: 0.127789 / Training Accuracy: 0.761719 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 24064/55000 / Cost: 0.121439 / Training Accuracy: 0.78125 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 24320/55000 / Cost: 0.130894 / Training Accuracy: 0.75 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 24576/55000 / Cost: 0.130282 / Training Accuracy: 0.734375 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 24832/55000 / Cost: 0.121113 / Training Accuracy: 0.777344 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 25088/55000 / Cost: 0.134119 / Training Accuracy: 0.726562 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 25344/55000 / Cost: 0.140508 / Training Accuracy: 0.714844 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 25600/55000 / Cost: 0.123093 / Training Accuracy: 0.730469 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 25856/55000 / Cost: 0.127361 / Training Accuracy: 0.785156 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 26112/55000 / Cost: 0.120613 / Training Accuracy: 0.78125 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 26368/55000 / Cost: 0.131293 / Training Accuracy: 0.738281 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 26624/55000 / Cost: 0.14176 / Training Accuracy: 0.738281 / Validation Accuracy: 0.71\n",
      "Epoch: 4 / Batch: 26880/55000 / Cost: 0.132409 / Training Accuracy: 0.765625 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 27136/55000 / Cost: 0.143902 / Training Accuracy: 0.699219 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 27392/55000 / Cost: 0.11529 / Training Accuracy: 0.800781 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 27648/55000 / Cost: 0.134432 / Training Accuracy: 0.761719 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 27904/55000 / Cost: 0.142976 / Training Accuracy: 0.710938 / Validation Accuracy: 0.66\n",
      "Epoch: 4 / Batch: 28160/55000 / Cost: 0.139882 / Training Accuracy: 0.714844 / Validation Accuracy: 0.7\n",
      "Epoch: 4 / Batch: 28416/55000 / Cost: 0.135633 / Training Accuracy: 0.742188 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 28672/55000 / Cost: 0.133201 / Training Accuracy: 0.734375 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 28928/55000 / Cost: 0.128699 / Training Accuracy: 0.777344 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 29184/55000 / Cost: 0.119488 / Training Accuracy: 0.761719 / Validation Accuracy: 0.72\n",
      "Epoch: 4 / Batch: 29440/55000 / Cost: 0.115122 / Training Accuracy: 0.785156 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 29696/55000 / Cost: 0.136282 / Training Accuracy: 0.742188 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 29952/55000 / Cost: 0.11671 / Training Accuracy: 0.785156 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 30208/55000 / Cost: 0.118296 / Training Accuracy: 0.777344 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 30464/55000 / Cost: 0.122815 / Training Accuracy: 0.761719 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 30720/55000 / Cost: 0.11338 / Training Accuracy: 0.773438 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 30976/55000 / Cost: 0.140847 / Training Accuracy: 0.738281 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 31232/55000 / Cost: 0.107503 / Training Accuracy: 0.808594 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 31488/55000 / Cost: 0.124107 / Training Accuracy: 0.761719 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 31744/55000 / Cost: 0.125907 / Training Accuracy: 0.734375 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 32000/55000 / Cost: 0.116615 / Training Accuracy: 0.773438 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 32256/55000 / Cost: 0.121188 / Training Accuracy: 0.714844 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 32512/55000 / Cost: 0.117385 / Training Accuracy: 0.753906 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 32768/55000 / Cost: 0.119041 / Training Accuracy: 0.765625 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 33024/55000 / Cost: 0.117358 / Training Accuracy: 0.757812 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 33280/55000 / Cost: 0.118715 / Training Accuracy: 0.800781 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 33536/55000 / Cost: 0.118565 / Training Accuracy: 0.804688 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 33792/55000 / Cost: 0.116384 / Training Accuracy: 0.785156 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 34048/55000 / Cost: 0.121768 / Training Accuracy: 0.757812 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 34304/55000 / Cost: 0.110735 / Training Accuracy: 0.800781 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 34560/55000 / Cost: 0.117999 / Training Accuracy: 0.78125 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 34816/55000 / Cost: 0.103555 / Training Accuracy: 0.832031 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 35072/55000 / Cost: 0.120874 / Training Accuracy: 0.765625 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 35328/55000 / Cost: 0.120823 / Training Accuracy: 0.773438 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 35584/55000 / Cost: 0.123916 / Training Accuracy: 0.761719 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 35840/55000 / Cost: 0.121328 / Training Accuracy: 0.777344 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 36096/55000 / Cost: 0.11073 / Training Accuracy: 0.800781 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 36352/55000 / Cost: 0.118705 / Training Accuracy: 0.746094 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 36608/55000 / Cost: 0.139113 / Training Accuracy: 0.714844 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 36864/55000 / Cost: 0.12293 / Training Accuracy: 0.726562 / Validation Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / Batch: 37120/55000 / Cost: 0.122841 / Training Accuracy: 0.757812 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 37376/55000 / Cost: 0.116296 / Training Accuracy: 0.78125 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 37632/55000 / Cost: 0.11813 / Training Accuracy: 0.765625 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 37888/55000 / Cost: 0.120014 / Training Accuracy: 0.785156 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 38144/55000 / Cost: 0.119293 / Training Accuracy: 0.78125 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 38400/55000 / Cost: 0.128112 / Training Accuracy: 0.742188 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 38656/55000 / Cost: 0.13468 / Training Accuracy: 0.734375 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 38912/55000 / Cost: 0.125981 / Training Accuracy: 0.777344 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 39168/55000 / Cost: 0.113128 / Training Accuracy: 0.773438 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 39424/55000 / Cost: 0.116151 / Training Accuracy: 0.769531 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 39680/55000 / Cost: 0.129926 / Training Accuracy: 0.730469 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 39936/55000 / Cost: 0.109654 / Training Accuracy: 0.804688 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 40192/55000 / Cost: 0.113917 / Training Accuracy: 0.769531 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 40448/55000 / Cost: 0.118968 / Training Accuracy: 0.746094 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 40704/55000 / Cost: 0.118274 / Training Accuracy: 0.761719 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 40960/55000 / Cost: 0.110419 / Training Accuracy: 0.804688 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 41216/55000 / Cost: 0.0944093 / Training Accuracy: 0.835938 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 41472/55000 / Cost: 0.121132 / Training Accuracy: 0.753906 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 41728/55000 / Cost: 0.118796 / Training Accuracy: 0.761719 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 41984/55000 / Cost: 0.123291 / Training Accuracy: 0.773438 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 42240/55000 / Cost: 0.111027 / Training Accuracy: 0.800781 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 42496/55000 / Cost: 0.117698 / Training Accuracy: 0.769531 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 42752/55000 / Cost: 0.107201 / Training Accuracy: 0.800781 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 43008/55000 / Cost: 0.116257 / Training Accuracy: 0.769531 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 43264/55000 / Cost: 0.126718 / Training Accuracy: 0.753906 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 43520/55000 / Cost: 0.123694 / Training Accuracy: 0.765625 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 43776/55000 / Cost: 0.109087 / Training Accuracy: 0.796875 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 44032/55000 / Cost: 0.117294 / Training Accuracy: 0.792969 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 44288/55000 / Cost: 0.113632 / Training Accuracy: 0.800781 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 44544/55000 / Cost: 0.117539 / Training Accuracy: 0.820312 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 44800/55000 / Cost: 0.10442 / Training Accuracy: 0.8125 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 45056/55000 / Cost: 0.11768 / Training Accuracy: 0.734375 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 45312/55000 / Cost: 0.103218 / Training Accuracy: 0.816406 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 45568/55000 / Cost: 0.10493 / Training Accuracy: 0.804688 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 45824/55000 / Cost: 0.115881 / Training Accuracy: 0.789062 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 46080/55000 / Cost: 0.12607 / Training Accuracy: 0.75 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 46336/55000 / Cost: 0.10656 / Training Accuracy: 0.785156 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 46592/55000 / Cost: 0.124693 / Training Accuracy: 0.730469 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 46848/55000 / Cost: 0.134579 / Training Accuracy: 0.75 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 47104/55000 / Cost: 0.0952494 / Training Accuracy: 0.835938 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 47360/55000 / Cost: 0.114025 / Training Accuracy: 0.773438 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 47616/55000 / Cost: 0.125886 / Training Accuracy: 0.746094 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 47872/55000 / Cost: 0.109944 / Training Accuracy: 0.796875 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 48128/55000 / Cost: 0.117165 / Training Accuracy: 0.765625 / Validation Accuracy: 0.81\n",
      "Epoch: 4 / Batch: 48384/55000 / Cost: 0.110426 / Training Accuracy: 0.765625 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 48640/55000 / Cost: 0.10702 / Training Accuracy: 0.816406 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 48896/55000 / Cost: 0.119148 / Training Accuracy: 0.777344 / Validation Accuracy: 0.76\n",
      "Epoch: 4 / Batch: 49152/55000 / Cost: 0.107817 / Training Accuracy: 0.808594 / Validation Accuracy: 0.77\n",
      "Epoch: 4 / Batch: 49408/55000 / Cost: 0.104097 / Training Accuracy: 0.792969 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 49664/55000 / Cost: 0.107659 / Training Accuracy: 0.777344 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 49920/55000 / Cost: 0.0975257 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 4 / Batch: 50176/55000 / Cost: 0.10637 / Training Accuracy: 0.792969 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 50432/55000 / Cost: 0.0971673 / Training Accuracy: 0.847656 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 50688/55000 / Cost: 0.109134 / Training Accuracy: 0.765625 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 50944/55000 / Cost: 0.0964345 / Training Accuracy: 0.84375 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 51200/55000 / Cost: 0.118592 / Training Accuracy: 0.753906 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 51456/55000 / Cost: 0.117359 / Training Accuracy: 0.773438 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 51712/55000 / Cost: 0.110406 / Training Accuracy: 0.777344 / Validation Accuracy: 0.73\n",
      "Epoch: 4 / Batch: 51968/55000 / Cost: 0.112369 / Training Accuracy: 0.8125 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 52224/55000 / Cost: 0.105161 / Training Accuracy: 0.816406 / Validation Accuracy: 0.79\n",
      "Epoch: 4 / Batch: 52480/55000 / Cost: 0.101262 / Training Accuracy: 0.820312 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 52736/55000 / Cost: 0.113311 / Training Accuracy: 0.777344 / Validation Accuracy: 0.83\n",
      "Epoch: 4 / Batch: 52992/55000 / Cost: 0.11627 / Training Accuracy: 0.765625 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 53248/55000 / Cost: 0.117324 / Training Accuracy: 0.789062 / Validation Accuracy: 0.75\n",
      "Epoch: 4 / Batch: 53504/55000 / Cost: 0.117303 / Training Accuracy: 0.796875 / Validation Accuracy: 0.74\n",
      "Epoch: 4 / Batch: 53760/55000 / Cost: 0.123252 / Training Accuracy: 0.761719 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 54016/55000 / Cost: 0.105702 / Training Accuracy: 0.804688 / Validation Accuracy: 0.78\n",
      "Epoch: 4 / Batch: 54272/55000 / Cost: 0.117138 / Training Accuracy: 0.777344 / Validation Accuracy: 0.8\n",
      "Epoch: 4 / Batch: 54528/55000 / Cost: 0.118064 / Training Accuracy: 0.785156 / Validation Accuracy: 0.82\n",
      "Epoch: 4 / Batch: 54784/55000 / Cost: 0.114651 / Training Accuracy: 0.782407 / Validation Accuracy: 0.76\n",
      "Model is saved!!!\n",
      "Epoch: 5 / Batch: 0/55000 / Cost: 0.116353 / Training Accuracy: 0.78125 / Validation Accuracy: 0.7\n",
      "Epoch: 5 / Batch: 256/55000 / Cost: 0.136368 / Training Accuracy: 0.730469 / Validation Accuracy: 0.77\n",
      "Epoch: 5 / Batch: 512/55000 / Cost: 0.108959 / Training Accuracy: 0.792969 / Validation Accuracy: 0.78\n",
      "Epoch: 5 / Batch: 768/55000 / Cost: 0.138175 / Training Accuracy: 0.707031 / Validation Accuracy: 0.76\n",
      "Epoch: 5 / Batch: 1024/55000 / Cost: 0.119708 / Training Accuracy: 0.746094 / Validation Accuracy: 0.77\n",
      "Epoch: 5 / Batch: 1280/55000 / Cost: 0.0928018 / Training Accuracy: 0.855469 / Validation Accuracy: 0.79\n",
      "Epoch: 5 / Batch: 1536/55000 / Cost: 0.129253 / Training Accuracy: 0.714844 / Validation Accuracy: 0.76\n",
      "Epoch: 5 / Batch: 1792/55000 / Cost: 0.134546 / Training Accuracy: 0.734375 / Validation Accuracy: 0.7\n",
      "Epoch: 5 / Batch: 2048/55000 / Cost: 0.12137 / Training Accuracy: 0.769531 / Validation Accuracy: 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / Batch: 2304/55000 / Cost: 0.10229 / Training Accuracy: 0.800781 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 2560/55000 / Cost: 0.108523 / Training Accuracy: 0.78125 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 2816/55000 / Cost: 0.126255 / Training Accuracy: 0.746094 / Validation Accuracy: 0.79\n",
      "Epoch: 5 / Batch: 3072/55000 / Cost: 0.0970266 / Training Accuracy: 0.835938 / Validation Accuracy: 0.76\n",
      "Epoch: 5 / Batch: 3328/55000 / Cost: 0.100149 / Training Accuracy: 0.8125 / Validation Accuracy: 0.76\n",
      "Epoch: 5 / Batch: 3584/55000 / Cost: 0.116076 / Training Accuracy: 0.785156 / Validation Accuracy: 0.77\n",
      "Epoch: 5 / Batch: 3840/55000 / Cost: 0.0925292 / Training Accuracy: 0.832031 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 4096/55000 / Cost: 0.115378 / Training Accuracy: 0.777344 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 4352/55000 / Cost: 0.112942 / Training Accuracy: 0.777344 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 4608/55000 / Cost: 0.104303 / Training Accuracy: 0.792969 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 4864/55000 / Cost: 0.110573 / Training Accuracy: 0.789062 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 5120/55000 / Cost: 0.119072 / Training Accuracy: 0.757812 / Validation Accuracy: 0.79\n",
      "Epoch: 5 / Batch: 5376/55000 / Cost: 0.0923514 / Training Accuracy: 0.875 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 5632/55000 / Cost: 0.0975974 / Training Accuracy: 0.839844 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 5888/55000 / Cost: 0.11437 / Training Accuracy: 0.769531 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 6144/55000 / Cost: 0.106803 / Training Accuracy: 0.835938 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 6400/55000 / Cost: 0.111061 / Training Accuracy: 0.785156 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 6656/55000 / Cost: 0.110628 / Training Accuracy: 0.792969 / Validation Accuracy: 0.77\n",
      "Epoch: 5 / Batch: 6912/55000 / Cost: 0.106774 / Training Accuracy: 0.835938 / Validation Accuracy: 0.78\n",
      "Epoch: 5 / Batch: 7168/55000 / Cost: 0.115313 / Training Accuracy: 0.820312 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 7424/55000 / Cost: 0.119158 / Training Accuracy: 0.773438 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 7680/55000 / Cost: 0.123512 / Training Accuracy: 0.777344 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 7936/55000 / Cost: 0.112743 / Training Accuracy: 0.78125 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 8192/55000 / Cost: 0.118601 / Training Accuracy: 0.785156 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 8448/55000 / Cost: 0.106625 / Training Accuracy: 0.832031 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 8704/55000 / Cost: 0.107134 / Training Accuracy: 0.765625 / Validation Accuracy: 0.74\n",
      "Epoch: 5 / Batch: 8960/55000 / Cost: 0.112565 / Training Accuracy: 0.777344 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 9216/55000 / Cost: 0.110553 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 9472/55000 / Cost: 0.0915553 / Training Accuracy: 0.820312 / Validation Accuracy: 0.79\n",
      "Epoch: 5 / Batch: 9728/55000 / Cost: 0.112255 / Training Accuracy: 0.785156 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 9984/55000 / Cost: 0.0959499 / Training Accuracy: 0.800781 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 10240/55000 / Cost: 0.106134 / Training Accuracy: 0.8125 / Validation Accuracy: 0.79\n",
      "Epoch: 5 / Batch: 10496/55000 / Cost: 0.111206 / Training Accuracy: 0.792969 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 10752/55000 / Cost: 0.102846 / Training Accuracy: 0.792969 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 11008/55000 / Cost: 0.0971799 / Training Accuracy: 0.847656 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 11264/55000 / Cost: 0.106377 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 11520/55000 / Cost: 0.0953107 / Training Accuracy: 0.839844 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 11776/55000 / Cost: 0.094887 / Training Accuracy: 0.839844 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 12032/55000 / Cost: 0.0919518 / Training Accuracy: 0.820312 / Validation Accuracy: 0.78\n",
      "Epoch: 5 / Batch: 12288/55000 / Cost: 0.0903665 / Training Accuracy: 0.84375 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 12544/55000 / Cost: 0.112194 / Training Accuracy: 0.796875 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 12800/55000 / Cost: 0.108509 / Training Accuracy: 0.824219 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 13056/55000 / Cost: 0.0998261 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 13312/55000 / Cost: 0.0990081 / Training Accuracy: 0.820312 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 13568/55000 / Cost: 0.0968155 / Training Accuracy: 0.789062 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 13824/55000 / Cost: 0.0983872 / Training Accuracy: 0.828125 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 14080/55000 / Cost: 0.102037 / Training Accuracy: 0.824219 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 14336/55000 / Cost: 0.102817 / Training Accuracy: 0.820312 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 14592/55000 / Cost: 0.0943369 / Training Accuracy: 0.835938 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 14848/55000 / Cost: 0.104425 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 15104/55000 / Cost: 0.101703 / Training Accuracy: 0.839844 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 15360/55000 / Cost: 0.105708 / Training Accuracy: 0.808594 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 15616/55000 / Cost: 0.105181 / Training Accuracy: 0.800781 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 15872/55000 / Cost: 0.104978 / Training Accuracy: 0.789062 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 16128/55000 / Cost: 0.104703 / Training Accuracy: 0.808594 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 16384/55000 / Cost: 0.111506 / Training Accuracy: 0.785156 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 16640/55000 / Cost: 0.0868237 / Training Accuracy: 0.847656 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 16896/55000 / Cost: 0.105797 / Training Accuracy: 0.796875 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 17152/55000 / Cost: 0.114499 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 17408/55000 / Cost: 0.103767 / Training Accuracy: 0.78125 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 17664/55000 / Cost: 0.0971747 / Training Accuracy: 0.828125 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 17920/55000 / Cost: 0.0944694 / Training Accuracy: 0.839844 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 18176/55000 / Cost: 0.093964 / Training Accuracy: 0.820312 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 18432/55000 / Cost: 0.0986397 / Training Accuracy: 0.84375 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 18688/55000 / Cost: 0.102034 / Training Accuracy: 0.824219 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 18944/55000 / Cost: 0.0987713 / Training Accuracy: 0.828125 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 19200/55000 / Cost: 0.0964277 / Training Accuracy: 0.820312 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 19456/55000 / Cost: 0.0916518 / Training Accuracy: 0.832031 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 19712/55000 / Cost: 0.109419 / Training Accuracy: 0.796875 / Validation Accuracy: 0.78\n",
      "Epoch: 5 / Batch: 19968/55000 / Cost: 0.113994 / Training Accuracy: 0.773438 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 20224/55000 / Cost: 0.0956518 / Training Accuracy: 0.835938 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 20480/55000 / Cost: 0.0900855 / Training Accuracy: 0.839844 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 20736/55000 / Cost: 0.102692 / Training Accuracy: 0.824219 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 20992/55000 / Cost: 0.0891029 / Training Accuracy: 0.824219 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 21248/55000 / Cost: 0.0903263 / Training Accuracy: 0.832031 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 21504/55000 / Cost: 0.091792 / Training Accuracy: 0.839844 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 21760/55000 / Cost: 0.0904914 / Training Accuracy: 0.835938 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 22016/55000 / Cost: 0.101284 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 22272/55000 / Cost: 0.0962732 / Training Accuracy: 0.828125 / Validation Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / Batch: 22528/55000 / Cost: 0.0967297 / Training Accuracy: 0.824219 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 22784/55000 / Cost: 0.092807 / Training Accuracy: 0.84375 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 23040/55000 / Cost: 0.0920553 / Training Accuracy: 0.824219 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 23296/55000 / Cost: 0.10269 / Training Accuracy: 0.84375 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 23552/55000 / Cost: 0.0997715 / Training Accuracy: 0.8125 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 23808/55000 / Cost: 0.0938786 / Training Accuracy: 0.816406 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 24064/55000 / Cost: 0.101839 / Training Accuracy: 0.804688 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 24320/55000 / Cost: 0.104255 / Training Accuracy: 0.8125 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 24576/55000 / Cost: 0.0953593 / Training Accuracy: 0.839844 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 24832/55000 / Cost: 0.0992061 / Training Accuracy: 0.820312 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 25088/55000 / Cost: 0.0970825 / Training Accuracy: 0.820312 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 25344/55000 / Cost: 0.0987121 / Training Accuracy: 0.832031 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 25600/55000 / Cost: 0.112163 / Training Accuracy: 0.796875 / Validation Accuracy: 0.8\n",
      "Epoch: 5 / Batch: 25856/55000 / Cost: 0.108397 / Training Accuracy: 0.765625 / Validation Accuracy: 0.79\n",
      "Epoch: 5 / Batch: 26112/55000 / Cost: 0.118114 / Training Accuracy: 0.785156 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 26368/55000 / Cost: 0.0834776 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 26624/55000 / Cost: 0.112209 / Training Accuracy: 0.796875 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 26880/55000 / Cost: 0.0814987 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 27136/55000 / Cost: 0.0915219 / Training Accuracy: 0.828125 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 27392/55000 / Cost: 0.0997517 / Training Accuracy: 0.808594 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 27648/55000 / Cost: 0.0931032 / Training Accuracy: 0.828125 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 27904/55000 / Cost: 0.093256 / Training Accuracy: 0.816406 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 28160/55000 / Cost: 0.0949512 / Training Accuracy: 0.828125 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 28416/55000 / Cost: 0.0961593 / Training Accuracy: 0.820312 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 28672/55000 / Cost: 0.0915228 / Training Accuracy: 0.832031 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 28928/55000 / Cost: 0.107282 / Training Accuracy: 0.796875 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 29184/55000 / Cost: 0.0820177 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 29440/55000 / Cost: 0.0872699 / Training Accuracy: 0.859375 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 29696/55000 / Cost: 0.0814988 / Training Accuracy: 0.84375 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 29952/55000 / Cost: 0.0988791 / Training Accuracy: 0.816406 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 30208/55000 / Cost: 0.0860392 / Training Accuracy: 0.863281 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 30464/55000 / Cost: 0.0840771 / Training Accuracy: 0.882812 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 30720/55000 / Cost: 0.0995192 / Training Accuracy: 0.804688 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 30976/55000 / Cost: 0.0828791 / Training Accuracy: 0.878906 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 31232/55000 / Cost: 0.0795188 / Training Accuracy: 0.847656 / Validation Accuracy: 0.9\n",
      "Epoch: 5 / Batch: 31488/55000 / Cost: 0.0807275 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 31744/55000 / Cost: 0.095973 / Training Accuracy: 0.84375 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 32000/55000 / Cost: 0.0929812 / Training Accuracy: 0.847656 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 32256/55000 / Cost: 0.103187 / Training Accuracy: 0.816406 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 32512/55000 / Cost: 0.0871704 / Training Accuracy: 0.832031 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 32768/55000 / Cost: 0.0907354 / Training Accuracy: 0.828125 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 33024/55000 / Cost: 0.080183 / Training Accuracy: 0.855469 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 33280/55000 / Cost: 0.0927253 / Training Accuracy: 0.800781 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 33536/55000 / Cost: 0.101943 / Training Accuracy: 0.828125 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 33792/55000 / Cost: 0.0886731 / Training Accuracy: 0.851562 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 34048/55000 / Cost: 0.0826344 / Training Accuracy: 0.871094 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 34304/55000 / Cost: 0.0829411 / Training Accuracy: 0.867188 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 34560/55000 / Cost: 0.102336 / Training Accuracy: 0.8125 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 34816/55000 / Cost: 0.0811246 / Training Accuracy: 0.867188 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 35072/55000 / Cost: 0.0984848 / Training Accuracy: 0.828125 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 35328/55000 / Cost: 0.092136 / Training Accuracy: 0.832031 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 35584/55000 / Cost: 0.0902281 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 35840/55000 / Cost: 0.0892578 / Training Accuracy: 0.847656 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 36096/55000 / Cost: 0.0918047 / Training Accuracy: 0.835938 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 36352/55000 / Cost: 0.0901396 / Training Accuracy: 0.84375 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 36608/55000 / Cost: 0.0928137 / Training Accuracy: 0.820312 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 36864/55000 / Cost: 0.0984232 / Training Accuracy: 0.804688 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 37120/55000 / Cost: 0.0909455 / Training Accuracy: 0.839844 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 37376/55000 / Cost: 0.0816691 / Training Accuracy: 0.839844 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 37632/55000 / Cost: 0.0990975 / Training Accuracy: 0.8125 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 37888/55000 / Cost: 0.0911245 / Training Accuracy: 0.835938 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 38144/55000 / Cost: 0.0872632 / Training Accuracy: 0.84375 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 38400/55000 / Cost: 0.0921089 / Training Accuracy: 0.820312 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 38656/55000 / Cost: 0.082492 / Training Accuracy: 0.839844 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 38912/55000 / Cost: 0.0808321 / Training Accuracy: 0.855469 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 39168/55000 / Cost: 0.0952915 / Training Accuracy: 0.835938 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 39424/55000 / Cost: 0.0851653 / Training Accuracy: 0.851562 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 39680/55000 / Cost: 0.0913025 / Training Accuracy: 0.851562 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 39936/55000 / Cost: 0.109856 / Training Accuracy: 0.800781 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 40192/55000 / Cost: 0.0782028 / Training Accuracy: 0.863281 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 40448/55000 / Cost: 0.0945983 / Training Accuracy: 0.832031 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 40704/55000 / Cost: 0.114728 / Training Accuracy: 0.765625 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 40960/55000 / Cost: 0.0861721 / Training Accuracy: 0.855469 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 41216/55000 / Cost: 0.0890373 / Training Accuracy: 0.847656 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 41472/55000 / Cost: 0.0904767 / Training Accuracy: 0.824219 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 41728/55000 / Cost: 0.0772053 / Training Accuracy: 0.867188 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 41984/55000 / Cost: 0.093983 / Training Accuracy: 0.820312 / Validation Accuracy: 0.84\n",
      "Epoch: 5 / Batch: 42240/55000 / Cost: 0.0852036 / Training Accuracy: 0.835938 / Validation Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / Batch: 42496/55000 / Cost: 0.0785472 / Training Accuracy: 0.84375 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 42752/55000 / Cost: 0.0867064 / Training Accuracy: 0.84375 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 43008/55000 / Cost: 0.0904455 / Training Accuracy: 0.820312 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 43264/55000 / Cost: 0.0901822 / Training Accuracy: 0.835938 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 43520/55000 / Cost: 0.0889455 / Training Accuracy: 0.84375 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 43776/55000 / Cost: 0.0762484 / Training Accuracy: 0.890625 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 44032/55000 / Cost: 0.0910646 / Training Accuracy: 0.832031 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 44288/55000 / Cost: 0.0956053 / Training Accuracy: 0.816406 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 44544/55000 / Cost: 0.094965 / Training Accuracy: 0.816406 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 44800/55000 / Cost: 0.0966653 / Training Accuracy: 0.84375 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 45056/55000 / Cost: 0.0867904 / Training Accuracy: 0.816406 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 45312/55000 / Cost: 0.0953241 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 45568/55000 / Cost: 0.0928387 / Training Accuracy: 0.832031 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 45824/55000 / Cost: 0.0831234 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 46080/55000 / Cost: 0.0824688 / Training Accuracy: 0.847656 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 46336/55000 / Cost: 0.0869454 / Training Accuracy: 0.839844 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 46592/55000 / Cost: 0.0914565 / Training Accuracy: 0.824219 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 46848/55000 / Cost: 0.093716 / Training Accuracy: 0.824219 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 47104/55000 / Cost: 0.0995483 / Training Accuracy: 0.800781 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 47360/55000 / Cost: 0.0918158 / Training Accuracy: 0.84375 / Validation Accuracy: 0.91\n",
      "Epoch: 5 / Batch: 47616/55000 / Cost: 0.0992386 / Training Accuracy: 0.8125 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 47872/55000 / Cost: 0.0839133 / Training Accuracy: 0.859375 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 48128/55000 / Cost: 0.098446 / Training Accuracy: 0.820312 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 48384/55000 / Cost: 0.080002 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 48640/55000 / Cost: 0.0966288 / Training Accuracy: 0.824219 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 48896/55000 / Cost: 0.0854534 / Training Accuracy: 0.835938 / Validation Accuracy: 0.82\n",
      "Epoch: 5 / Batch: 49152/55000 / Cost: 0.0913041 / Training Accuracy: 0.835938 / Validation Accuracy: 0.83\n",
      "Epoch: 5 / Batch: 49408/55000 / Cost: 0.0886794 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 49664/55000 / Cost: 0.0933017 / Training Accuracy: 0.839844 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 49920/55000 / Cost: 0.0860996 / Training Accuracy: 0.832031 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 50176/55000 / Cost: 0.0897789 / Training Accuracy: 0.824219 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 50432/55000 / Cost: 0.0727702 / Training Accuracy: 0.902344 / Validation Accuracy: 0.81\n",
      "Epoch: 5 / Batch: 50688/55000 / Cost: 0.0875522 / Training Accuracy: 0.851562 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 50944/55000 / Cost: 0.0827055 / Training Accuracy: 0.871094 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 51200/55000 / Cost: 0.0922264 / Training Accuracy: 0.820312 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 51456/55000 / Cost: 0.0887799 / Training Accuracy: 0.824219 / Validation Accuracy: 0.86\n",
      "Epoch: 5 / Batch: 51712/55000 / Cost: 0.0869989 / Training Accuracy: 0.824219 / Validation Accuracy: 0.85\n",
      "Epoch: 5 / Batch: 51968/55000 / Cost: 0.0843265 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 52224/55000 / Cost: 0.0701816 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 52480/55000 / Cost: 0.0876376 / Training Accuracy: 0.820312 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 52736/55000 / Cost: 0.0884284 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 52992/55000 / Cost: 0.086903 / Training Accuracy: 0.832031 / Validation Accuracy: 0.89\n",
      "Epoch: 5 / Batch: 53248/55000 / Cost: 0.0802531 / Training Accuracy: 0.855469 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 53504/55000 / Cost: 0.0981644 / Training Accuracy: 0.789062 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 53760/55000 / Cost: 0.0801573 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 5 / Batch: 54016/55000 / Cost: 0.0953461 / Training Accuracy: 0.820312 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 54272/55000 / Cost: 0.08649 / Training Accuracy: 0.835938 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 54528/55000 / Cost: 0.0809035 / Training Accuracy: 0.863281 / Validation Accuracy: 0.88\n",
      "Epoch: 5 / Batch: 54784/55000 / Cost: 0.0788721 / Training Accuracy: 0.87037 / Validation Accuracy: 0.91\n",
      "Model is saved!!!\n",
      "Epoch: 6 / Batch: 0/55000 / Cost: 0.105139 / Training Accuracy: 0.808594 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 256/55000 / Cost: 0.0922147 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 512/55000 / Cost: 0.0928618 / Training Accuracy: 0.835938 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 768/55000 / Cost: 0.0727436 / Training Accuracy: 0.898438 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 1024/55000 / Cost: 0.0765175 / Training Accuracy: 0.871094 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 1280/55000 / Cost: 0.0783641 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 1536/55000 / Cost: 0.0808503 / Training Accuracy: 0.894531 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 1792/55000 / Cost: 0.0848512 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 2048/55000 / Cost: 0.088099 / Training Accuracy: 0.832031 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 2304/55000 / Cost: 0.089762 / Training Accuracy: 0.84375 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 2560/55000 / Cost: 0.108064 / Training Accuracy: 0.820312 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 2816/55000 / Cost: 0.0840436 / Training Accuracy: 0.851562 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 3072/55000 / Cost: 0.0878527 / Training Accuracy: 0.839844 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 3328/55000 / Cost: 0.0841505 / Training Accuracy: 0.859375 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 3584/55000 / Cost: 0.0855208 / Training Accuracy: 0.820312 / Validation Accuracy: 0.83\n",
      "Epoch: 6 / Batch: 3840/55000 / Cost: 0.0787209 / Training Accuracy: 0.863281 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 4096/55000 / Cost: 0.0845143 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 4352/55000 / Cost: 0.0878397 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 4608/55000 / Cost: 0.0979138 / Training Accuracy: 0.820312 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 4864/55000 / Cost: 0.0775102 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 5120/55000 / Cost: 0.0720033 / Training Accuracy: 0.882812 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 5376/55000 / Cost: 0.0820596 / Training Accuracy: 0.828125 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 5632/55000 / Cost: 0.0877853 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 5888/55000 / Cost: 0.0974304 / Training Accuracy: 0.816406 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 6144/55000 / Cost: 0.0893293 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 6400/55000 / Cost: 0.0761637 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 6656/55000 / Cost: 0.086166 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 6912/55000 / Cost: 0.0904526 / Training Accuracy: 0.835938 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 7168/55000 / Cost: 0.0816112 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / Batch: 7424/55000 / Cost: 0.0700602 / Training Accuracy: 0.894531 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 7680/55000 / Cost: 0.0977535 / Training Accuracy: 0.808594 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 7936/55000 / Cost: 0.0756184 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 8192/55000 / Cost: 0.0820875 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 8448/55000 / Cost: 0.0816666 / Training Accuracy: 0.84375 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 8704/55000 / Cost: 0.0600727 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 8960/55000 / Cost: 0.0842979 / Training Accuracy: 0.835938 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 9216/55000 / Cost: 0.0646816 / Training Accuracy: 0.902344 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 9472/55000 / Cost: 0.081513 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 9728/55000 / Cost: 0.0770095 / Training Accuracy: 0.867188 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 9984/55000 / Cost: 0.0694865 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 10240/55000 / Cost: 0.0808401 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 10496/55000 / Cost: 0.0996883 / Training Accuracy: 0.832031 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 10752/55000 / Cost: 0.0781677 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 11008/55000 / Cost: 0.0911539 / Training Accuracy: 0.839844 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 11264/55000 / Cost: 0.0839061 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 11520/55000 / Cost: 0.0865458 / Training Accuracy: 0.863281 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 11776/55000 / Cost: 0.0805876 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 12032/55000 / Cost: 0.090621 / Training Accuracy: 0.8125 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 12288/55000 / Cost: 0.0805878 / Training Accuracy: 0.851562 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 12544/55000 / Cost: 0.0707777 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 12800/55000 / Cost: 0.086274 / Training Accuracy: 0.839844 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 13056/55000 / Cost: 0.0887768 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 13312/55000 / Cost: 0.0749031 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 13568/55000 / Cost: 0.0795095 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 13824/55000 / Cost: 0.0880063 / Training Accuracy: 0.835938 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 14080/55000 / Cost: 0.0727392 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 14336/55000 / Cost: 0.0826679 / Training Accuracy: 0.835938 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 14592/55000 / Cost: 0.0747528 / Training Accuracy: 0.882812 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 14848/55000 / Cost: 0.0793237 / Training Accuracy: 0.855469 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 15104/55000 / Cost: 0.0931563 / Training Accuracy: 0.820312 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 15360/55000 / Cost: 0.0871227 / Training Accuracy: 0.84375 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 15616/55000 / Cost: 0.0825473 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 15872/55000 / Cost: 0.0858264 / Training Accuracy: 0.808594 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 16128/55000 / Cost: 0.0710493 / Training Accuracy: 0.898438 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 16384/55000 / Cost: 0.0866942 / Training Accuracy: 0.839844 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 16640/55000 / Cost: 0.0890814 / Training Accuracy: 0.859375 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 16896/55000 / Cost: 0.0776402 / Training Accuracy: 0.847656 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 17152/55000 / Cost: 0.090333 / Training Accuracy: 0.847656 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 17408/55000 / Cost: 0.0847263 / Training Accuracy: 0.867188 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 17664/55000 / Cost: 0.0836807 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 17920/55000 / Cost: 0.0747432 / Training Accuracy: 0.859375 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 18176/55000 / Cost: 0.0726056 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 18432/55000 / Cost: 0.0743967 / Training Accuracy: 0.867188 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 18688/55000 / Cost: 0.0876187 / Training Accuracy: 0.851562 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 18944/55000 / Cost: 0.0746019 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 19200/55000 / Cost: 0.089057 / Training Accuracy: 0.847656 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 19456/55000 / Cost: 0.0914217 / Training Accuracy: 0.835938 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 19712/55000 / Cost: 0.0803213 / Training Accuracy: 0.851562 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 19968/55000 / Cost: 0.0865167 / Training Accuracy: 0.835938 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 20224/55000 / Cost: 0.0738267 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 20480/55000 / Cost: 0.0791798 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 20736/55000 / Cost: 0.0735448 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 20992/55000 / Cost: 0.0766455 / Training Accuracy: 0.882812 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 21248/55000 / Cost: 0.065477 / Training Accuracy: 0.871094 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 21504/55000 / Cost: 0.088181 / Training Accuracy: 0.855469 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 21760/55000 / Cost: 0.0828965 / Training Accuracy: 0.855469 / Validation Accuracy: 0.82\n",
      "Epoch: 6 / Batch: 22016/55000 / Cost: 0.0840726 / Training Accuracy: 0.832031 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 22272/55000 / Cost: 0.10347 / Training Accuracy: 0.808594 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 22528/55000 / Cost: 0.0820712 / Training Accuracy: 0.851562 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 22784/55000 / Cost: 0.0770857 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 23040/55000 / Cost: 0.0849679 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 23296/55000 / Cost: 0.080051 / Training Accuracy: 0.851562 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 23552/55000 / Cost: 0.0817903 / Training Accuracy: 0.839844 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 23808/55000 / Cost: 0.0773895 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 24064/55000 / Cost: 0.0815123 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 24320/55000 / Cost: 0.0707143 / Training Accuracy: 0.859375 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 24576/55000 / Cost: 0.0668744 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 24832/55000 / Cost: 0.0786859 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 25088/55000 / Cost: 0.0723161 / Training Accuracy: 0.875 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 25344/55000 / Cost: 0.0802899 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 25600/55000 / Cost: 0.0789381 / Training Accuracy: 0.851562 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 25856/55000 / Cost: 0.0802841 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 26112/55000 / Cost: 0.0734113 / Training Accuracy: 0.863281 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 26368/55000 / Cost: 0.0782162 / Training Accuracy: 0.855469 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 26624/55000 / Cost: 0.0757912 / Training Accuracy: 0.855469 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 26880/55000 / Cost: 0.0805361 / Training Accuracy: 0.851562 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 27136/55000 / Cost: 0.0845186 / Training Accuracy: 0.84375 / Validation Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / Batch: 27392/55000 / Cost: 0.0760343 / Training Accuracy: 0.855469 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 27648/55000 / Cost: 0.0896273 / Training Accuracy: 0.824219 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 27904/55000 / Cost: 0.0640936 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 28160/55000 / Cost: 0.0715417 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 28416/55000 / Cost: 0.0731157 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 28672/55000 / Cost: 0.0755334 / Training Accuracy: 0.871094 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 28928/55000 / Cost: 0.0715392 / Training Accuracy: 0.871094 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 29184/55000 / Cost: 0.0770885 / Training Accuracy: 0.855469 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 29440/55000 / Cost: 0.073666 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 29696/55000 / Cost: 0.0723021 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 29952/55000 / Cost: 0.0919271 / Training Accuracy: 0.828125 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 30208/55000 / Cost: 0.0846942 / Training Accuracy: 0.84375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 30464/55000 / Cost: 0.073757 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 30720/55000 / Cost: 0.0877013 / Training Accuracy: 0.835938 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 30976/55000 / Cost: 0.0705234 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 31232/55000 / Cost: 0.0725295 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 31488/55000 / Cost: 0.0779678 / Training Accuracy: 0.871094 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 31744/55000 / Cost: 0.0683224 / Training Accuracy: 0.875 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 32000/55000 / Cost: 0.0743665 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 32256/55000 / Cost: 0.0723819 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 32512/55000 / Cost: 0.0604162 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 32768/55000 / Cost: 0.0738782 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 33024/55000 / Cost: 0.0635474 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 33280/55000 / Cost: 0.0716312 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 33536/55000 / Cost: 0.0658311 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 33792/55000 / Cost: 0.0676941 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 34048/55000 / Cost: 0.0719302 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 34304/55000 / Cost: 0.0944774 / Training Accuracy: 0.835938 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 34560/55000 / Cost: 0.0774757 / Training Accuracy: 0.84375 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 34816/55000 / Cost: 0.0630053 / Training Accuracy: 0.882812 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 35072/55000 / Cost: 0.0706753 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 35328/55000 / Cost: 0.0854103 / Training Accuracy: 0.828125 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 35584/55000 / Cost: 0.0663943 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 35840/55000 / Cost: 0.0684552 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 36096/55000 / Cost: 0.0690387 / Training Accuracy: 0.882812 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 36352/55000 / Cost: 0.0792573 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 36608/55000 / Cost: 0.0741142 / Training Accuracy: 0.859375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 36864/55000 / Cost: 0.0689208 / Training Accuracy: 0.882812 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 37120/55000 / Cost: 0.0737636 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 37376/55000 / Cost: 0.0574769 / Training Accuracy: 0.910156 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 37632/55000 / Cost: 0.0755188 / Training Accuracy: 0.875 / Validation Accuracy: 0.82\n",
      "Epoch: 6 / Batch: 37888/55000 / Cost: 0.0730881 / Training Accuracy: 0.863281 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 38144/55000 / Cost: 0.0667884 / Training Accuracy: 0.882812 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 38400/55000 / Cost: 0.0799691 / Training Accuracy: 0.832031 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 38656/55000 / Cost: 0.0653685 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 38912/55000 / Cost: 0.0785732 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 39168/55000 / Cost: 0.0790394 / Training Accuracy: 0.859375 / Validation Accuracy: 0.91\n",
      "Epoch: 6 / Batch: 39424/55000 / Cost: 0.0762764 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 39680/55000 / Cost: 0.063735 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 39936/55000 / Cost: 0.0724382 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 40192/55000 / Cost: 0.0774941 / Training Accuracy: 0.894531 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 40448/55000 / Cost: 0.0792719 / Training Accuracy: 0.851562 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 40704/55000 / Cost: 0.0716129 / Training Accuracy: 0.898438 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 40960/55000 / Cost: 0.0734222 / Training Accuracy: 0.882812 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 41216/55000 / Cost: 0.0633232 / Training Accuracy: 0.882812 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 41472/55000 / Cost: 0.0719204 / Training Accuracy: 0.84375 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 41728/55000 / Cost: 0.0860304 / Training Accuracy: 0.84375 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 41984/55000 / Cost: 0.0617629 / Training Accuracy: 0.898438 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 42240/55000 / Cost: 0.0805649 / Training Accuracy: 0.863281 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 42496/55000 / Cost: 0.086872 / Training Accuracy: 0.828125 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 42752/55000 / Cost: 0.0752445 / Training Accuracy: 0.867188 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 43008/55000 / Cost: 0.0833429 / Training Accuracy: 0.863281 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 43264/55000 / Cost: 0.073724 / Training Accuracy: 0.863281 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 43520/55000 / Cost: 0.0756263 / Training Accuracy: 0.859375 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 43776/55000 / Cost: 0.0784986 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 44032/55000 / Cost: 0.0831125 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 44288/55000 / Cost: 0.0857868 / Training Accuracy: 0.851562 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 44544/55000 / Cost: 0.0744636 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 44800/55000 / Cost: 0.0654749 / Training Accuracy: 0.894531 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 45056/55000 / Cost: 0.0677304 / Training Accuracy: 0.886719 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 45312/55000 / Cost: 0.0695034 / Training Accuracy: 0.878906 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 45568/55000 / Cost: 0.0775588 / Training Accuracy: 0.855469 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 45824/55000 / Cost: 0.069029 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 46080/55000 / Cost: 0.0640759 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 6 / Batch: 46336/55000 / Cost: 0.0923268 / Training Accuracy: 0.816406 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 46592/55000 / Cost: 0.0673978 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 46848/55000 / Cost: 0.0881861 / Training Accuracy: 0.84375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 47104/55000 / Cost: 0.0665522 / Training Accuracy: 0.878906 / Validation Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / Batch: 47360/55000 / Cost: 0.0748268 / Training Accuracy: 0.867188 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 47616/55000 / Cost: 0.071333 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 47872/55000 / Cost: 0.0621595 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 48128/55000 / Cost: 0.0797884 / Training Accuracy: 0.847656 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 48384/55000 / Cost: 0.0865023 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 48640/55000 / Cost: 0.0761282 / Training Accuracy: 0.867188 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 48896/55000 / Cost: 0.0737622 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 49152/55000 / Cost: 0.0654174 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 49408/55000 / Cost: 0.0786002 / Training Accuracy: 0.867188 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 49664/55000 / Cost: 0.0705767 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 49920/55000 / Cost: 0.0670038 / Training Accuracy: 0.894531 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 50176/55000 / Cost: 0.0743617 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 50432/55000 / Cost: 0.0644064 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 50688/55000 / Cost: 0.0735723 / Training Accuracy: 0.871094 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 50944/55000 / Cost: 0.0708416 / Training Accuracy: 0.859375 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 51200/55000 / Cost: 0.0641047 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 51456/55000 / Cost: 0.0851426 / Training Accuracy: 0.851562 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 51712/55000 / Cost: 0.0624571 / Training Accuracy: 0.898438 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 51968/55000 / Cost: 0.0791761 / Training Accuracy: 0.84375 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 52224/55000 / Cost: 0.072918 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 6 / Batch: 52480/55000 / Cost: 0.0661702 / Training Accuracy: 0.890625 / Validation Accuracy: 0.86\n",
      "Epoch: 6 / Batch: 52736/55000 / Cost: 0.0663281 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 52992/55000 / Cost: 0.072743 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 53248/55000 / Cost: 0.0672479 / Training Accuracy: 0.878906 / Validation Accuracy: 0.87\n",
      "Epoch: 6 / Batch: 53504/55000 / Cost: 0.0629279 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 53760/55000 / Cost: 0.0715604 / Training Accuracy: 0.886719 / Validation Accuracy: 0.84\n",
      "Epoch: 6 / Batch: 54016/55000 / Cost: 0.085338 / Training Accuracy: 0.835938 / Validation Accuracy: 0.85\n",
      "Epoch: 6 / Batch: 54272/55000 / Cost: 0.0652589 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 6 / Batch: 54528/55000 / Cost: 0.0828698 / Training Accuracy: 0.855469 / Validation Accuracy: 0.9\n",
      "Epoch: 6 / Batch: 54784/55000 / Cost: 0.0933367 / Training Accuracy: 0.814815 / Validation Accuracy: 0.91\n",
      "Model is saved!!!\n",
      "Epoch: 7 / Batch: 0/55000 / Cost: 0.068348 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 256/55000 / Cost: 0.0703368 / Training Accuracy: 0.882812 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 512/55000 / Cost: 0.0702401 / Training Accuracy: 0.871094 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 768/55000 / Cost: 0.0705089 / Training Accuracy: 0.886719 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 1024/55000 / Cost: 0.0773003 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 1280/55000 / Cost: 0.0689675 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 1536/55000 / Cost: 0.0704323 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 1792/55000 / Cost: 0.0741524 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 2048/55000 / Cost: 0.0695554 / Training Accuracy: 0.882812 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 2304/55000 / Cost: 0.0706414 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 2560/55000 / Cost: 0.0638961 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 2816/55000 / Cost: 0.0732009 / Training Accuracy: 0.863281 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 3072/55000 / Cost: 0.0716216 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 3328/55000 / Cost: 0.0647469 / Training Accuracy: 0.882812 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 3584/55000 / Cost: 0.0715394 / Training Accuracy: 0.882812 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 3840/55000 / Cost: 0.0673557 / Training Accuracy: 0.890625 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 4096/55000 / Cost: 0.067374 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 4352/55000 / Cost: 0.0649301 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 4608/55000 / Cost: 0.0590173 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 4864/55000 / Cost: 0.0711077 / Training Accuracy: 0.867188 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 5120/55000 / Cost: 0.0891416 / Training Accuracy: 0.824219 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 5376/55000 / Cost: 0.0609722 / Training Accuracy: 0.886719 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 5632/55000 / Cost: 0.067565 / Training Accuracy: 0.890625 / Validation Accuracy: 0.84\n",
      "Epoch: 7 / Batch: 5888/55000 / Cost: 0.0636285 / Training Accuracy: 0.875 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 6144/55000 / Cost: 0.0628612 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 6400/55000 / Cost: 0.061846 / Training Accuracy: 0.882812 / Validation Accuracy: 0.85\n",
      "Epoch: 7 / Batch: 6656/55000 / Cost: 0.0658277 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 6912/55000 / Cost: 0.078072 / Training Accuracy: 0.847656 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 7168/55000 / Cost: 0.0696314 / Training Accuracy: 0.882812 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 7424/55000 / Cost: 0.0769635 / Training Accuracy: 0.863281 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 7680/55000 / Cost: 0.0536517 / Training Accuracy: 0.914062 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 7936/55000 / Cost: 0.061594 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 8192/55000 / Cost: 0.075371 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 8448/55000 / Cost: 0.0719522 / Training Accuracy: 0.882812 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 8704/55000 / Cost: 0.061262 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 8960/55000 / Cost: 0.067443 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 9216/55000 / Cost: 0.07603 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 9472/55000 / Cost: 0.0875345 / Training Accuracy: 0.832031 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 9728/55000 / Cost: 0.0603651 / Training Accuracy: 0.890625 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 9984/55000 / Cost: 0.0734209 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 10240/55000 / Cost: 0.0820865 / Training Accuracy: 0.84375 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 10496/55000 / Cost: 0.065426 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 10752/55000 / Cost: 0.0577371 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 11008/55000 / Cost: 0.0737807 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 11264/55000 / Cost: 0.0586759 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 11520/55000 / Cost: 0.0733867 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 11776/55000 / Cost: 0.0687494 / Training Accuracy: 0.871094 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 12032/55000 / Cost: 0.057126 / Training Accuracy: 0.925781 / Validation Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / Batch: 12288/55000 / Cost: 0.055732 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 12544/55000 / Cost: 0.0733175 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 12800/55000 / Cost: 0.0678334 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 13056/55000 / Cost: 0.0701558 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 13312/55000 / Cost: 0.081394 / Training Accuracy: 0.863281 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 13568/55000 / Cost: 0.0663495 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 13824/55000 / Cost: 0.0709632 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 14080/55000 / Cost: 0.0546209 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 14336/55000 / Cost: 0.0567541 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 14592/55000 / Cost: 0.0677631 / Training Accuracy: 0.882812 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 14848/55000 / Cost: 0.0661005 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 15104/55000 / Cost: 0.060589 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 15360/55000 / Cost: 0.073705 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 15616/55000 / Cost: 0.0627544 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 15872/55000 / Cost: 0.0668583 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 16128/55000 / Cost: 0.0553265 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 16384/55000 / Cost: 0.0610058 / Training Accuracy: 0.898438 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 16640/55000 / Cost: 0.0624447 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 16896/55000 / Cost: 0.0667414 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 17152/55000 / Cost: 0.0647335 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 17408/55000 / Cost: 0.0897128 / Training Accuracy: 0.835938 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 17664/55000 / Cost: 0.0592032 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 17920/55000 / Cost: 0.0531033 / Training Accuracy: 0.925781 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 18176/55000 / Cost: 0.0817308 / Training Accuracy: 0.820312 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 18432/55000 / Cost: 0.069947 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 18688/55000 / Cost: 0.0628956 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 18944/55000 / Cost: 0.0624077 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 19200/55000 / Cost: 0.0744325 / Training Accuracy: 0.847656 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 19456/55000 / Cost: 0.0739988 / Training Accuracy: 0.855469 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 19712/55000 / Cost: 0.0654643 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 19968/55000 / Cost: 0.0625383 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 20224/55000 / Cost: 0.0665736 / Training Accuracy: 0.847656 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 20480/55000 / Cost: 0.0681893 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 20736/55000 / Cost: 0.0661875 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 20992/55000 / Cost: 0.0808093 / Training Accuracy: 0.855469 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 21248/55000 / Cost: 0.0710694 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 21504/55000 / Cost: 0.0634662 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 21760/55000 / Cost: 0.0659614 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 22016/55000 / Cost: 0.0658161 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 22272/55000 / Cost: 0.0616007 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 22528/55000 / Cost: 0.0583017 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 22784/55000 / Cost: 0.0643137 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 23040/55000 / Cost: 0.0545402 / Training Accuracy: 0.917969 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 23296/55000 / Cost: 0.0625804 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 23552/55000 / Cost: 0.0681859 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 23808/55000 / Cost: 0.0533627 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 24064/55000 / Cost: 0.0807828 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 24320/55000 / Cost: 0.0705458 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 24576/55000 / Cost: 0.0557864 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 24832/55000 / Cost: 0.0569833 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 25088/55000 / Cost: 0.0764678 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 25344/55000 / Cost: 0.0738686 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 25600/55000 / Cost: 0.0637937 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 25856/55000 / Cost: 0.0572474 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 26112/55000 / Cost: 0.0773111 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 26368/55000 / Cost: 0.0618487 / Training Accuracy: 0.882812 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 26624/55000 / Cost: 0.0531252 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 26880/55000 / Cost: 0.0653936 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 27136/55000 / Cost: 0.0591873 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 27392/55000 / Cost: 0.0539362 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 27648/55000 / Cost: 0.0629071 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 27904/55000 / Cost: 0.0841694 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 28160/55000 / Cost: 0.0626748 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 28416/55000 / Cost: 0.0577629 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 28672/55000 / Cost: 0.0685601 / Training Accuracy: 0.878906 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 28928/55000 / Cost: 0.0802417 / Training Accuracy: 0.847656 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 29184/55000 / Cost: 0.0824736 / Training Accuracy: 0.828125 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 29440/55000 / Cost: 0.0638055 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 29696/55000 / Cost: 0.0650619 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 29952/55000 / Cost: 0.0701536 / Training Accuracy: 0.882812 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 30208/55000 / Cost: 0.0529886 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 30464/55000 / Cost: 0.0613979 / Training Accuracy: 0.882812 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 30720/55000 / Cost: 0.0641821 / Training Accuracy: 0.882812 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 30976/55000 / Cost: 0.0556483 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 31232/55000 / Cost: 0.0707817 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 31488/55000 / Cost: 0.0678683 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 31744/55000 / Cost: 0.068426 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 32000/55000 / Cost: 0.064841 / Training Accuracy: 0.882812 / Validation Accuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / Batch: 32256/55000 / Cost: 0.060558 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 32512/55000 / Cost: 0.064481 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 32768/55000 / Cost: 0.0700213 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 33024/55000 / Cost: 0.0637293 / Training Accuracy: 0.886719 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 33280/55000 / Cost: 0.0621741 / Training Accuracy: 0.890625 / Validation Accuracy: 0.86\n",
      "Epoch: 7 / Batch: 33536/55000 / Cost: 0.0605149 / Training Accuracy: 0.914062 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 33792/55000 / Cost: 0.0716299 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 34048/55000 / Cost: 0.0786674 / Training Accuracy: 0.859375 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 34304/55000 / Cost: 0.0752189 / Training Accuracy: 0.84375 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 34560/55000 / Cost: 0.0562249 / Training Accuracy: 0.910156 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 34816/55000 / Cost: 0.0747933 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 35072/55000 / Cost: 0.0677352 / Training Accuracy: 0.894531 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 35328/55000 / Cost: 0.0608731 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 35584/55000 / Cost: 0.0605357 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 35840/55000 / Cost: 0.065684 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 36096/55000 / Cost: 0.0563057 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 36352/55000 / Cost: 0.0556386 / Training Accuracy: 0.914062 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 36608/55000 / Cost: 0.0562401 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 36864/55000 / Cost: 0.0453041 / Training Accuracy: 0.945312 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 37120/55000 / Cost: 0.0615252 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 37376/55000 / Cost: 0.06565 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 37632/55000 / Cost: 0.0660454 / Training Accuracy: 0.882812 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 37888/55000 / Cost: 0.0656537 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 38144/55000 / Cost: 0.0574825 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 38400/55000 / Cost: 0.0712298 / Training Accuracy: 0.878906 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 38656/55000 / Cost: 0.0770703 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 38912/55000 / Cost: 0.0676434 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 39168/55000 / Cost: 0.0562604 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 39424/55000 / Cost: 0.0678293 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 39680/55000 / Cost: 0.0613795 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 39936/55000 / Cost: 0.0731694 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 40192/55000 / Cost: 0.061073 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 40448/55000 / Cost: 0.0658995 / Training Accuracy: 0.882812 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 40704/55000 / Cost: 0.0582093 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 40960/55000 / Cost: 0.0639773 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 41216/55000 / Cost: 0.0717814 / Training Accuracy: 0.855469 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 41472/55000 / Cost: 0.0526293 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 41728/55000 / Cost: 0.0651853 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 41984/55000 / Cost: 0.051901 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 42240/55000 / Cost: 0.0696546 / Training Accuracy: 0.871094 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 42496/55000 / Cost: 0.0605526 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 42752/55000 / Cost: 0.0643196 / Training Accuracy: 0.882812 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 43008/55000 / Cost: 0.0598879 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 43264/55000 / Cost: 0.0554597 / Training Accuracy: 0.894531 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 43520/55000 / Cost: 0.0484821 / Training Accuracy: 0.941406 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 43776/55000 / Cost: 0.0605502 / Training Accuracy: 0.882812 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 44032/55000 / Cost: 0.0576211 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 44288/55000 / Cost: 0.0644132 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 44544/55000 / Cost: 0.0518054 / Training Accuracy: 0.914062 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 44800/55000 / Cost: 0.0529186 / Training Accuracy: 0.914062 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 45056/55000 / Cost: 0.0679721 / Training Accuracy: 0.863281 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 45312/55000 / Cost: 0.0528785 / Training Accuracy: 0.917969 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 45568/55000 / Cost: 0.0763349 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 45824/55000 / Cost: 0.0551317 / Training Accuracy: 0.914062 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 46080/55000 / Cost: 0.058657 / Training Accuracy: 0.910156 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 46336/55000 / Cost: 0.0743881 / Training Accuracy: 0.863281 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 46592/55000 / Cost: 0.0583943 / Training Accuracy: 0.894531 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 46848/55000 / Cost: 0.067912 / Training Accuracy: 0.886719 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 47104/55000 / Cost: 0.0642691 / Training Accuracy: 0.867188 / Validation Accuracy: 0.88\n",
      "Epoch: 7 / Batch: 47360/55000 / Cost: 0.0608244 / Training Accuracy: 0.886719 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 47616/55000 / Cost: 0.0727727 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 47872/55000 / Cost: 0.0603722 / Training Accuracy: 0.902344 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 48128/55000 / Cost: 0.0655726 / Training Accuracy: 0.882812 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 48384/55000 / Cost: 0.0672794 / Training Accuracy: 0.890625 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 48640/55000 / Cost: 0.0611426 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 48896/55000 / Cost: 0.0515586 / Training Accuracy: 0.929688 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 49152/55000 / Cost: 0.0491564 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 49408/55000 / Cost: 0.066391 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 49664/55000 / Cost: 0.0656126 / Training Accuracy: 0.882812 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 49920/55000 / Cost: 0.0589635 / Training Accuracy: 0.910156 / Validation Accuracy: 0.87\n",
      "Epoch: 7 / Batch: 50176/55000 / Cost: 0.0618943 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 50432/55000 / Cost: 0.0643908 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 50688/55000 / Cost: 0.0587034 / Training Accuracy: 0.898438 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 50944/55000 / Cost: 0.0826039 / Training Accuracy: 0.816406 / Validation Accuracy: 0.94\n",
      "Epoch: 7 / Batch: 51200/55000 / Cost: 0.0549344 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 7 / Batch: 51456/55000 / Cost: 0.0618753 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 51712/55000 / Cost: 0.0668867 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 7 / Batch: 51968/55000 / Cost: 0.0707895 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / Batch: 52224/55000 / Cost: 0.0616847 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 52480/55000 / Cost: 0.0719999 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 52736/55000 / Cost: 0.0584578 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 52992/55000 / Cost: 0.0674307 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 53248/55000 / Cost: 0.0707736 / Training Accuracy: 0.863281 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 53504/55000 / Cost: 0.0535124 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 53760/55000 / Cost: 0.0573451 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 54016/55000 / Cost: 0.0579007 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 7 / Batch: 54272/55000 / Cost: 0.0534964 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 7 / Batch: 54528/55000 / Cost: 0.0597115 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 7 / Batch: 54784/55000 / Cost: 0.0602775 / Training Accuracy: 0.893519 / Validation Accuracy: 0.88\n",
      "Model is saved!!!\n",
      "Epoch: 8 / Batch: 0/55000 / Cost: 0.0716491 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 256/55000 / Cost: 0.0588415 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 512/55000 / Cost: 0.0572453 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 768/55000 / Cost: 0.0496779 / Training Accuracy: 0.9375 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 1024/55000 / Cost: 0.0812909 / Training Accuracy: 0.851562 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 1280/55000 / Cost: 0.0654763 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 1536/55000 / Cost: 0.058139 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 1792/55000 / Cost: 0.0502027 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 2048/55000 / Cost: 0.0473449 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 2304/55000 / Cost: 0.0583677 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 2560/55000 / Cost: 0.0610599 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 2816/55000 / Cost: 0.0619129 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 3072/55000 / Cost: 0.0435086 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 3328/55000 / Cost: 0.0689291 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 3584/55000 / Cost: 0.055588 / Training Accuracy: 0.898438 / Validation Accuracy: 0.95\n",
      "Epoch: 8 / Batch: 3840/55000 / Cost: 0.0585624 / Training Accuracy: 0.898438 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 4096/55000 / Cost: 0.0529866 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 4352/55000 / Cost: 0.075244 / Training Accuracy: 0.863281 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 4608/55000 / Cost: 0.0506822 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 4864/55000 / Cost: 0.054933 / Training Accuracy: 0.90625 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 5120/55000 / Cost: 0.0610864 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 5376/55000 / Cost: 0.0490105 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 5632/55000 / Cost: 0.0555896 / Training Accuracy: 0.898438 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 5888/55000 / Cost: 0.0660287 / Training Accuracy: 0.882812 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 6144/55000 / Cost: 0.0528241 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 6400/55000 / Cost: 0.0499136 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 6656/55000 / Cost: 0.0529021 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 6912/55000 / Cost: 0.0477223 / Training Accuracy: 0.929688 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 7168/55000 / Cost: 0.0604195 / Training Accuracy: 0.902344 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 7424/55000 / Cost: 0.0709884 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 7680/55000 / Cost: 0.0640562 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 7936/55000 / Cost: 0.0644981 / Training Accuracy: 0.886719 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 8192/55000 / Cost: 0.0463168 / Training Accuracy: 0.925781 / Validation Accuracy: 0.86\n",
      "Epoch: 8 / Batch: 8448/55000 / Cost: 0.0676212 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 8704/55000 / Cost: 0.0614385 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 8960/55000 / Cost: 0.0575781 / Training Accuracy: 0.878906 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 9216/55000 / Cost: 0.0644347 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 9472/55000 / Cost: 0.069234 / Training Accuracy: 0.890625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 9728/55000 / Cost: 0.0595328 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 9984/55000 / Cost: 0.0657307 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 10240/55000 / Cost: 0.0656404 / Training Accuracy: 0.875 / Validation Accuracy: 0.86\n",
      "Epoch: 8 / Batch: 10496/55000 / Cost: 0.0454181 / Training Accuracy: 0.925781 / Validation Accuracy: 0.85\n",
      "Epoch: 8 / Batch: 10752/55000 / Cost: 0.0595914 / Training Accuracy: 0.902344 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 11008/55000 / Cost: 0.0492948 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 11264/55000 / Cost: 0.0555028 / Training Accuracy: 0.914062 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 11520/55000 / Cost: 0.0642551 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 11776/55000 / Cost: 0.0585442 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 12032/55000 / Cost: 0.0680428 / Training Accuracy: 0.863281 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 12288/55000 / Cost: 0.0593715 / Training Accuracy: 0.914062 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 12544/55000 / Cost: 0.0550529 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 12800/55000 / Cost: 0.0581166 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 13056/55000 / Cost: 0.0582682 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 13312/55000 / Cost: 0.0478265 / Training Accuracy: 0.9375 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 13568/55000 / Cost: 0.0664366 / Training Accuracy: 0.871094 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 13824/55000 / Cost: 0.0586856 / Training Accuracy: 0.917969 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 14080/55000 / Cost: 0.0510076 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 14336/55000 / Cost: 0.0660454 / Training Accuracy: 0.882812 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 14592/55000 / Cost: 0.0581111 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 14848/55000 / Cost: 0.0604173 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 15104/55000 / Cost: 0.0539884 / Training Accuracy: 0.914062 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 15360/55000 / Cost: 0.0470924 / Training Accuracy: 0.914062 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 15616/55000 / Cost: 0.0630486 / Training Accuracy: 0.886719 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 15872/55000 / Cost: 0.0619485 / Training Accuracy: 0.867188 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 16128/55000 / Cost: 0.0610857 / Training Accuracy: 0.886719 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 16384/55000 / Cost: 0.0531621 / Training Accuracy: 0.929688 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 16640/55000 / Cost: 0.059119 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 16896/55000 / Cost: 0.0526171 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / Batch: 17152/55000 / Cost: 0.0520871 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 17408/55000 / Cost: 0.0631133 / Training Accuracy: 0.875 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 17664/55000 / Cost: 0.0563458 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 17920/55000 / Cost: 0.0553482 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 18176/55000 / Cost: 0.0658294 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 18432/55000 / Cost: 0.0530379 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 18688/55000 / Cost: 0.0436272 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 18944/55000 / Cost: 0.0463807 / Training Accuracy: 0.925781 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 19200/55000 / Cost: 0.0565111 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 19456/55000 / Cost: 0.0580237 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 19712/55000 / Cost: 0.0474078 / Training Accuracy: 0.925781 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 19968/55000 / Cost: 0.059414 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 20224/55000 / Cost: 0.0570471 / Training Accuracy: 0.914062 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 20480/55000 / Cost: 0.0740052 / Training Accuracy: 0.863281 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 20736/55000 / Cost: 0.0455017 / Training Accuracy: 0.925781 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 20992/55000 / Cost: 0.0560043 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 21248/55000 / Cost: 0.0635381 / Training Accuracy: 0.871094 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 21504/55000 / Cost: 0.0763571 / Training Accuracy: 0.863281 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 21760/55000 / Cost: 0.0413219 / Training Accuracy: 0.941406 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 22016/55000 / Cost: 0.0434409 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 22272/55000 / Cost: 0.0662011 / Training Accuracy: 0.890625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 22528/55000 / Cost: 0.0547582 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 22784/55000 / Cost: 0.0571425 / Training Accuracy: 0.882812 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 23040/55000 / Cost: 0.0611347 / Training Accuracy: 0.882812 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 23296/55000 / Cost: 0.046386 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 23552/55000 / Cost: 0.0517073 / Training Accuracy: 0.933594 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 23808/55000 / Cost: 0.057607 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 24064/55000 / Cost: 0.053052 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 24320/55000 / Cost: 0.054299 / Training Accuracy: 0.890625 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 24576/55000 / Cost: 0.0578271 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 24832/55000 / Cost: 0.0584006 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 25088/55000 / Cost: 0.056917 / Training Accuracy: 0.882812 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 25344/55000 / Cost: 0.0584411 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 25600/55000 / Cost: 0.0554226 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 25856/55000 / Cost: 0.0538003 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 26112/55000 / Cost: 0.0579254 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 26368/55000 / Cost: 0.04763 / Training Accuracy: 0.921875 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 26624/55000 / Cost: 0.0490683 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 26880/55000 / Cost: 0.0686778 / Training Accuracy: 0.875 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 27136/55000 / Cost: 0.0591019 / Training Accuracy: 0.882812 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 27392/55000 / Cost: 0.0534883 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 27648/55000 / Cost: 0.0556091 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 27904/55000 / Cost: 0.054767 / Training Accuracy: 0.882812 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 28160/55000 / Cost: 0.0546801 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 28416/55000 / Cost: 0.0547092 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 28672/55000 / Cost: 0.0611682 / Training Accuracy: 0.898438 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 28928/55000 / Cost: 0.0562577 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 29184/55000 / Cost: 0.0611522 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 29440/55000 / Cost: 0.052904 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 29696/55000 / Cost: 0.0578396 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 29952/55000 / Cost: 0.0459363 / Training Accuracy: 0.925781 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 30208/55000 / Cost: 0.0567503 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 30464/55000 / Cost: 0.0600649 / Training Accuracy: 0.875 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 30720/55000 / Cost: 0.0605094 / Training Accuracy: 0.890625 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 30976/55000 / Cost: 0.0713643 / Training Accuracy: 0.867188 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 31232/55000 / Cost: 0.0654896 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 31488/55000 / Cost: 0.0639257 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 31744/55000 / Cost: 0.0772171 / Training Accuracy: 0.855469 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 32000/55000 / Cost: 0.0721606 / Training Accuracy: 0.878906 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 32256/55000 / Cost: 0.0455744 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 32512/55000 / Cost: 0.0522928 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 32768/55000 / Cost: 0.0633823 / Training Accuracy: 0.878906 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 33024/55000 / Cost: 0.0537633 / Training Accuracy: 0.917969 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 33280/55000 / Cost: 0.0689538 / Training Accuracy: 0.875 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 33536/55000 / Cost: 0.0504634 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 33792/55000 / Cost: 0.0621096 / Training Accuracy: 0.890625 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 34048/55000 / Cost: 0.0469658 / Training Accuracy: 0.925781 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 34304/55000 / Cost: 0.0537155 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 34560/55000 / Cost: 0.0608946 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 34816/55000 / Cost: 0.0568601 / Training Accuracy: 0.914062 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 35072/55000 / Cost: 0.0537941 / Training Accuracy: 0.929688 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 35328/55000 / Cost: 0.0633992 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 35584/55000 / Cost: 0.0506514 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 35840/55000 / Cost: 0.0501835 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 36096/55000 / Cost: 0.0554518 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 36352/55000 / Cost: 0.0502957 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 36608/55000 / Cost: 0.0553664 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 36864/55000 / Cost: 0.0593618 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / Batch: 37120/55000 / Cost: 0.0525951 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 8 / Batch: 37376/55000 / Cost: 0.0444307 / Training Accuracy: 0.925781 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 37632/55000 / Cost: 0.0545012 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 37888/55000 / Cost: 0.0436092 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 38144/55000 / Cost: 0.0466646 / Training Accuracy: 0.929688 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 38400/55000 / Cost: 0.0534982 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 38656/55000 / Cost: 0.05121 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 38912/55000 / Cost: 0.0665468 / Training Accuracy: 0.871094 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 39168/55000 / Cost: 0.0461184 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 39424/55000 / Cost: 0.0670429 / Training Accuracy: 0.863281 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 39680/55000 / Cost: 0.0451548 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 39936/55000 / Cost: 0.0723263 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 40192/55000 / Cost: 0.065466 / Training Accuracy: 0.878906 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 40448/55000 / Cost: 0.0633017 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 40704/55000 / Cost: 0.0469441 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 40960/55000 / Cost: 0.04882 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 41216/55000 / Cost: 0.0568342 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 41472/55000 / Cost: 0.0604098 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 41728/55000 / Cost: 0.0705986 / Training Accuracy: 0.882812 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 41984/55000 / Cost: 0.0466237 / Training Accuracy: 0.914062 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 42240/55000 / Cost: 0.0403681 / Training Accuracy: 0.9375 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 42496/55000 / Cost: 0.0494846 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 42752/55000 / Cost: 0.0600081 / Training Accuracy: 0.898438 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 43008/55000 / Cost: 0.0518282 / Training Accuracy: 0.898438 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 43264/55000 / Cost: 0.0468748 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 43520/55000 / Cost: 0.0607948 / Training Accuracy: 0.894531 / Validation Accuracy: 0.89\n",
      "Epoch: 8 / Batch: 43776/55000 / Cost: 0.0522165 / Training Accuracy: 0.921875 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 44032/55000 / Cost: 0.0486455 / Training Accuracy: 0.9375 / Validation Accuracy: 0.87\n",
      "Epoch: 8 / Batch: 44288/55000 / Cost: 0.0556677 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 44544/55000 / Cost: 0.0508238 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 8 / Batch: 44800/55000 / Cost: 0.0543646 / Training Accuracy: 0.90625 / Validation Accuracy: 0.95\n",
      "Epoch: 8 / Batch: 45056/55000 / Cost: 0.0536933 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 45312/55000 / Cost: 0.0544428 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 45568/55000 / Cost: 0.0582575 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 45824/55000 / Cost: 0.0446789 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 46080/55000 / Cost: 0.0553362 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 46336/55000 / Cost: 0.0501406 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 46592/55000 / Cost: 0.0607258 / Training Accuracy: 0.898438 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 46848/55000 / Cost: 0.0489596 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 47104/55000 / Cost: 0.0515714 / Training Accuracy: 0.902344 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 47360/55000 / Cost: 0.0539248 / Training Accuracy: 0.902344 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 47616/55000 / Cost: 0.0612306 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 47872/55000 / Cost: 0.0467345 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 48128/55000 / Cost: 0.0776145 / Training Accuracy: 0.878906 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 48384/55000 / Cost: 0.0553757 / Training Accuracy: 0.886719 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 48640/55000 / Cost: 0.050549 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 48896/55000 / Cost: 0.0424237 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 49152/55000 / Cost: 0.0573236 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 49408/55000 / Cost: 0.0475529 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 49664/55000 / Cost: 0.057326 / Training Accuracy: 0.894531 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 49920/55000 / Cost: 0.0679033 / Training Accuracy: 0.867188 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 50176/55000 / Cost: 0.0447745 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 8 / Batch: 50432/55000 / Cost: 0.0568524 / Training Accuracy: 0.90625 / Validation Accuracy: 0.95\n",
      "Epoch: 8 / Batch: 50688/55000 / Cost: 0.0489435 / Training Accuracy: 0.9375 / Validation Accuracy: 0.93\n",
      "Epoch: 8 / Batch: 50944/55000 / Cost: 0.0685032 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 51200/55000 / Cost: 0.0537095 / Training Accuracy: 0.902344 / Validation Accuracy: 0.88\n",
      "Epoch: 8 / Batch: 51456/55000 / Cost: 0.0554857 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 51712/55000 / Cost: 0.0568381 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 51968/55000 / Cost: 0.0565101 / Training Accuracy: 0.882812 / Validation Accuracy: 0.9\n",
      "Epoch: 8 / Batch: 52224/55000 / Cost: 0.0500836 / Training Accuracy: 0.90625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 52480/55000 / Cost: 0.0519593 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 52736/55000 / Cost: 0.0459601 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 8 / Batch: 52992/55000 / Cost: 0.0522492 / Training Accuracy: 0.898438 / Validation Accuracy: 0.95\n",
      "Epoch: 8 / Batch: 53248/55000 / Cost: 0.0516514 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 53504/55000 / Cost: 0.0532719 / Training Accuracy: 0.902344 / Validation Accuracy: 0.96\n",
      "Epoch: 8 / Batch: 53760/55000 / Cost: 0.064686 / Training Accuracy: 0.882812 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 54016/55000 / Cost: 0.0489191 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 54272/55000 / Cost: 0.0633784 / Training Accuracy: 0.890625 / Validation Accuracy: 0.91\n",
      "Epoch: 8 / Batch: 54528/55000 / Cost: 0.0466481 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 8 / Batch: 54784/55000 / Cost: 0.0721217 / Training Accuracy: 0.861111 / Validation Accuracy: 0.94\n",
      "Model is saved!!!\n",
      "Epoch: 9 / Batch: 0/55000 / Cost: 0.0674618 / Training Accuracy: 0.875 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 256/55000 / Cost: 0.0574975 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 512/55000 / Cost: 0.0478892 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 768/55000 / Cost: 0.0525027 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 1024/55000 / Cost: 0.0582612 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 1280/55000 / Cost: 0.0639772 / Training Accuracy: 0.882812 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 1536/55000 / Cost: 0.0458508 / Training Accuracy: 0.929688 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 1792/55000 / Cost: 0.0598212 / Training Accuracy: 0.902344 / Validation Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / Batch: 2048/55000 / Cost: 0.056943 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 2304/55000 / Cost: 0.0571815 / Training Accuracy: 0.914062 / Validation Accuracy: 0.88\n",
      "Epoch: 9 / Batch: 2560/55000 / Cost: 0.0487714 / Training Accuracy: 0.90625 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 2816/55000 / Cost: 0.0412372 / Training Accuracy: 0.953125 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 3072/55000 / Cost: 0.063014 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 3328/55000 / Cost: 0.0608297 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 3584/55000 / Cost: 0.0486703 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 3840/55000 / Cost: 0.0623248 / Training Accuracy: 0.894531 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 4096/55000 / Cost: 0.0457726 / Training Accuracy: 0.949219 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 4352/55000 / Cost: 0.0563395 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 4608/55000 / Cost: 0.0707916 / Training Accuracy: 0.886719 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 4864/55000 / Cost: 0.0491576 / Training Accuracy: 0.914062 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 5120/55000 / Cost: 0.0486034 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 5376/55000 / Cost: 0.0554119 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 5632/55000 / Cost: 0.0583375 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 5888/55000 / Cost: 0.0568341 / Training Accuracy: 0.882812 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 6144/55000 / Cost: 0.0545613 / Training Accuracy: 0.90625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 6400/55000 / Cost: 0.0600021 / Training Accuracy: 0.882812 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 6656/55000 / Cost: 0.0553337 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 6912/55000 / Cost: 0.0610373 / Training Accuracy: 0.894531 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 7168/55000 / Cost: 0.0529456 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 7424/55000 / Cost: 0.0350889 / Training Accuracy: 0.953125 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 7680/55000 / Cost: 0.0475235 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 7936/55000 / Cost: 0.041507 / Training Accuracy: 0.949219 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 8192/55000 / Cost: 0.0445074 / Training Accuracy: 0.910156 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 8448/55000 / Cost: 0.0631576 / Training Accuracy: 0.890625 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 8704/55000 / Cost: 0.0502302 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 8960/55000 / Cost: 0.0506582 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 9216/55000 / Cost: 0.0610864 / Training Accuracy: 0.886719 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 9472/55000 / Cost: 0.0565841 / Training Accuracy: 0.898438 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 9728/55000 / Cost: 0.0511709 / Training Accuracy: 0.894531 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 9984/55000 / Cost: 0.0522311 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 10240/55000 / Cost: 0.0537834 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 10496/55000 / Cost: 0.0453848 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 10752/55000 / Cost: 0.0503442 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 11008/55000 / Cost: 0.0563451 / Training Accuracy: 0.875 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 11264/55000 / Cost: 0.0423376 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 11520/55000 / Cost: 0.0443318 / Training Accuracy: 0.929688 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 11776/55000 / Cost: 0.0523856 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 12032/55000 / Cost: 0.0441998 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 12288/55000 / Cost: 0.05876 / Training Accuracy: 0.914062 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 12544/55000 / Cost: 0.0560716 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 12800/55000 / Cost: 0.0525624 / Training Accuracy: 0.898438 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 13056/55000 / Cost: 0.0596617 / Training Accuracy: 0.894531 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 13312/55000 / Cost: 0.0580757 / Training Accuracy: 0.90625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 13568/55000 / Cost: 0.0540283 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 13824/55000 / Cost: 0.0504671 / Training Accuracy: 0.898438 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 14080/55000 / Cost: 0.0484102 / Training Accuracy: 0.910156 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 14336/55000 / Cost: 0.0455494 / Training Accuracy: 0.941406 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 14592/55000 / Cost: 0.0639564 / Training Accuracy: 0.878906 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 14848/55000 / Cost: 0.0604392 / Training Accuracy: 0.890625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 15104/55000 / Cost: 0.0475953 / Training Accuracy: 0.925781 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 15360/55000 / Cost: 0.0353344 / Training Accuracy: 0.945312 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 15616/55000 / Cost: 0.0373073 / Training Accuracy: 0.949219 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 15872/55000 / Cost: 0.0473317 / Training Accuracy: 0.914062 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 16128/55000 / Cost: 0.0490638 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 16384/55000 / Cost: 0.0611705 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 16640/55000 / Cost: 0.052137 / Training Accuracy: 0.910156 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 16896/55000 / Cost: 0.0579175 / Training Accuracy: 0.894531 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 17152/55000 / Cost: 0.0521051 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 17408/55000 / Cost: 0.0433052 / Training Accuracy: 0.945312 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 17664/55000 / Cost: 0.0567873 / Training Accuracy: 0.894531 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 17920/55000 / Cost: 0.0388182 / Training Accuracy: 0.9375 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 18176/55000 / Cost: 0.03608 / Training Accuracy: 0.945312 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 18432/55000 / Cost: 0.0385374 / Training Accuracy: 0.941406 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 18688/55000 / Cost: 0.0400582 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 18944/55000 / Cost: 0.0493188 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 19200/55000 / Cost: 0.0605096 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 19456/55000 / Cost: 0.0584955 / Training Accuracy: 0.890625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 19712/55000 / Cost: 0.0551496 / Training Accuracy: 0.890625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 19968/55000 / Cost: 0.0479902 / Training Accuracy: 0.910156 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 20224/55000 / Cost: 0.0497621 / Training Accuracy: 0.890625 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 20480/55000 / Cost: 0.0480506 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 20736/55000 / Cost: 0.0388886 / Training Accuracy: 0.949219 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 20992/55000 / Cost: 0.0485229 / Training Accuracy: 0.933594 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 21248/55000 / Cost: 0.0497242 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 21504/55000 / Cost: 0.0423248 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 21760/55000 / Cost: 0.0392622 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / Batch: 22016/55000 / Cost: 0.0441565 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 22272/55000 / Cost: 0.0465059 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 22528/55000 / Cost: 0.0471033 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 22784/55000 / Cost: 0.0453349 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 23040/55000 / Cost: 0.0567489 / Training Accuracy: 0.898438 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 23296/55000 / Cost: 0.0456185 / Training Accuracy: 0.9375 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 23552/55000 / Cost: 0.0439862 / Training Accuracy: 0.9375 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 23808/55000 / Cost: 0.0496447 / Training Accuracy: 0.90625 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 24064/55000 / Cost: 0.0421184 / Training Accuracy: 0.933594 / Validation Accuracy: 0.97\n",
      "Epoch: 9 / Batch: 24320/55000 / Cost: 0.0479458 / Training Accuracy: 0.933594 / Validation Accuracy: 0.97\n",
      "Epoch: 9 / Batch: 24576/55000 / Cost: 0.0612674 / Training Accuracy: 0.882812 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 24832/55000 / Cost: 0.0527859 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 25088/55000 / Cost: 0.0501989 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 25344/55000 / Cost: 0.0495987 / Training Accuracy: 0.898438 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 25600/55000 / Cost: 0.0489863 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 25856/55000 / Cost: 0.0456484 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 26112/55000 / Cost: 0.0514988 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 26368/55000 / Cost: 0.0677202 / Training Accuracy: 0.863281 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 26624/55000 / Cost: 0.0449348 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 26880/55000 / Cost: 0.0382774 / Training Accuracy: 0.945312 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 27136/55000 / Cost: 0.0385278 / Training Accuracy: 0.949219 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 27392/55000 / Cost: 0.0397202 / Training Accuracy: 0.941406 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 27648/55000 / Cost: 0.0476947 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 27904/55000 / Cost: 0.0550205 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 28160/55000 / Cost: 0.0495877 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 28416/55000 / Cost: 0.053761 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 28672/55000 / Cost: 0.050439 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 28928/55000 / Cost: 0.0479096 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 29184/55000 / Cost: 0.054778 / Training Accuracy: 0.894531 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 29440/55000 / Cost: 0.0516292 / Training Accuracy: 0.917969 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 29696/55000 / Cost: 0.0401602 / Training Accuracy: 0.941406 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 29952/55000 / Cost: 0.0571094 / Training Accuracy: 0.894531 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 30208/55000 / Cost: 0.0548678 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 30464/55000 / Cost: 0.045456 / Training Accuracy: 0.9375 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 30720/55000 / Cost: 0.0540197 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 30976/55000 / Cost: 0.0585301 / Training Accuracy: 0.910156 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 31232/55000 / Cost: 0.0399082 / Training Accuracy: 0.949219 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 31488/55000 / Cost: 0.0460824 / Training Accuracy: 0.929688 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 31744/55000 / Cost: 0.0444229 / Training Accuracy: 0.941406 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 32000/55000 / Cost: 0.0460781 / Training Accuracy: 0.929688 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 32256/55000 / Cost: 0.0408273 / Training Accuracy: 0.949219 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 32512/55000 / Cost: 0.0474874 / Training Accuracy: 0.917969 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 32768/55000 / Cost: 0.047409 / Training Accuracy: 0.914062 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 33024/55000 / Cost: 0.0496431 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 33280/55000 / Cost: 0.0468029 / Training Accuracy: 0.902344 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 33536/55000 / Cost: 0.0530692 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 33792/55000 / Cost: 0.0514989 / Training Accuracy: 0.917969 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 34048/55000 / Cost: 0.0471001 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 34304/55000 / Cost: 0.0420804 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 34560/55000 / Cost: 0.0486002 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 34816/55000 / Cost: 0.0564575 / Training Accuracy: 0.898438 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 35072/55000 / Cost: 0.0485421 / Training Accuracy: 0.910156 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 35328/55000 / Cost: 0.0479899 / Training Accuracy: 0.925781 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 35584/55000 / Cost: 0.0481464 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 35840/55000 / Cost: 0.0503523 / Training Accuracy: 0.914062 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 36096/55000 / Cost: 0.0471826 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 36352/55000 / Cost: 0.0513851 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 36608/55000 / Cost: 0.0618542 / Training Accuracy: 0.898438 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 36864/55000 / Cost: 0.0523335 / Training Accuracy: 0.90625 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 37120/55000 / Cost: 0.0359522 / Training Accuracy: 0.949219 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 37376/55000 / Cost: 0.0369086 / Training Accuracy: 0.953125 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 37632/55000 / Cost: 0.0464087 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 37888/55000 / Cost: 0.0507893 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 38144/55000 / Cost: 0.0527564 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 38400/55000 / Cost: 0.0397963 / Training Accuracy: 0.925781 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 38656/55000 / Cost: 0.050899 / Training Accuracy: 0.90625 / Validation Accuracy: 0.89\n",
      "Epoch: 9 / Batch: 38912/55000 / Cost: 0.0424875 / Training Accuracy: 0.921875 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 39168/55000 / Cost: 0.0464101 / Training Accuracy: 0.921875 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 39424/55000 / Cost: 0.0611648 / Training Accuracy: 0.898438 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 39680/55000 / Cost: 0.0652037 / Training Accuracy: 0.878906 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 39936/55000 / Cost: 0.0438921 / Training Accuracy: 0.933594 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 40192/55000 / Cost: 0.0454181 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 40448/55000 / Cost: 0.0619078 / Training Accuracy: 0.871094 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 40704/55000 / Cost: 0.0527515 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 40960/55000 / Cost: 0.0496668 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 41216/55000 / Cost: 0.0531023 / Training Accuracy: 0.90625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 41472/55000 / Cost: 0.0584876 / Training Accuracy: 0.890625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 41728/55000 / Cost: 0.0488044 / Training Accuracy: 0.910156 / Validation Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / Batch: 41984/55000 / Cost: 0.0424971 / Training Accuracy: 0.929688 / Validation Accuracy: 0.97\n",
      "Epoch: 9 / Batch: 42240/55000 / Cost: 0.0488455 / Training Accuracy: 0.914062 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 42496/55000 / Cost: 0.0536381 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 42752/55000 / Cost: 0.056305 / Training Accuracy: 0.90625 / Validation Accuracy: 0.97\n",
      "Epoch: 9 / Batch: 43008/55000 / Cost: 0.0339732 / Training Accuracy: 0.960938 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 43264/55000 / Cost: 0.0399432 / Training Accuracy: 0.929688 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 43520/55000 / Cost: 0.0569438 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 43776/55000 / Cost: 0.0486354 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 44032/55000 / Cost: 0.0544652 / Training Accuracy: 0.894531 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 44288/55000 / Cost: 0.0449234 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 44544/55000 / Cost: 0.0452161 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 44800/55000 / Cost: 0.0469245 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 45056/55000 / Cost: 0.0464875 / Training Accuracy: 0.917969 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 45312/55000 / Cost: 0.0446542 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 45568/55000 / Cost: 0.0398733 / Training Accuracy: 0.9375 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 45824/55000 / Cost: 0.0412098 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 46080/55000 / Cost: 0.0364763 / Training Accuracy: 0.949219 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 46336/55000 / Cost: 0.0435327 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 46592/55000 / Cost: 0.0539884 / Training Accuracy: 0.890625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 46848/55000 / Cost: 0.0541191 / Training Accuracy: 0.90625 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 47104/55000 / Cost: 0.048532 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 47360/55000 / Cost: 0.0507956 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 47616/55000 / Cost: 0.0477251 / Training Accuracy: 0.890625 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 47872/55000 / Cost: 0.0418862 / Training Accuracy: 0.941406 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 48128/55000 / Cost: 0.0526885 / Training Accuracy: 0.90625 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 48384/55000 / Cost: 0.0567084 / Training Accuracy: 0.890625 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 48640/55000 / Cost: 0.0515459 / Training Accuracy: 0.910156 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 48896/55000 / Cost: 0.0421352 / Training Accuracy: 0.933594 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 49152/55000 / Cost: 0.0469631 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 49408/55000 / Cost: 0.0457435 / Training Accuracy: 0.929688 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 49664/55000 / Cost: 0.0572536 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 49920/55000 / Cost: 0.0452673 / Training Accuracy: 0.914062 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 50176/55000 / Cost: 0.0465362 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 50432/55000 / Cost: 0.0549247 / Training Accuracy: 0.902344 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 50688/55000 / Cost: 0.0551085 / Training Accuracy: 0.90625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 50944/55000 / Cost: 0.0455263 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 51200/55000 / Cost: 0.0458727 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 51456/55000 / Cost: 0.0411597 / Training Accuracy: 0.941406 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 51712/55000 / Cost: 0.0446205 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 51968/55000 / Cost: 0.0377165 / Training Accuracy: 0.941406 / Validation Accuracy: 0.96\n",
      "Epoch: 9 / Batch: 52224/55000 / Cost: 0.0458346 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 9 / Batch: 52480/55000 / Cost: 0.0396308 / Training Accuracy: 0.9375 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 52736/55000 / Cost: 0.0496813 / Training Accuracy: 0.90625 / Validation Accuracy: 0.94\n",
      "Epoch: 9 / Batch: 52992/55000 / Cost: 0.0392557 / Training Accuracy: 0.9375 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 53248/55000 / Cost: 0.0396443 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 53504/55000 / Cost: 0.048071 / Training Accuracy: 0.917969 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 53760/55000 / Cost: 0.0466369 / Training Accuracy: 0.910156 / Validation Accuracy: 0.9\n",
      "Epoch: 9 / Batch: 54016/55000 / Cost: 0.0404945 / Training Accuracy: 0.945312 / Validation Accuracy: 0.91\n",
      "Epoch: 9 / Batch: 54272/55000 / Cost: 0.0324265 / Training Accuracy: 0.953125 / Validation Accuracy: 0.92\n",
      "Epoch: 9 / Batch: 54528/55000 / Cost: 0.0374257 / Training Accuracy: 0.9375 / Validation Accuracy: 0.93\n",
      "Epoch: 9 / Batch: 54784/55000 / Cost: 0.0468347 / Training Accuracy: 0.921296 / Validation Accuracy: 0.94\n",
      "Model is saved!!!\n",
      "Epoch: 10 / Batch: 0/55000 / Cost: 0.0433152 / Training Accuracy: 0.929688 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 256/55000 / Cost: 0.0505016 / Training Accuracy: 0.917969 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 512/55000 / Cost: 0.0540258 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 768/55000 / Cost: 0.0506271 / Training Accuracy: 0.910156 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 1024/55000 / Cost: 0.0520556 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 1280/55000 / Cost: 0.0426834 / Training Accuracy: 0.933594 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 1536/55000 / Cost: 0.0486274 / Training Accuracy: 0.902344 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 1792/55000 / Cost: 0.038012 / Training Accuracy: 0.933594 / Validation Accuracy: 0.9\n",
      "Epoch: 10 / Batch: 2048/55000 / Cost: 0.0490433 / Training Accuracy: 0.917969 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 2304/55000 / Cost: 0.0514212 / Training Accuracy: 0.90625 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 2560/55000 / Cost: 0.03358 / Training Accuracy: 0.972656 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 2816/55000 / Cost: 0.0413382 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 3072/55000 / Cost: 0.0438538 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 3328/55000 / Cost: 0.0390225 / Training Accuracy: 0.929688 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 3584/55000 / Cost: 0.0554947 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 3840/55000 / Cost: 0.0382483 / Training Accuracy: 0.929688 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 4096/55000 / Cost: 0.0478366 / Training Accuracy: 0.902344 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 4352/55000 / Cost: 0.0473992 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 4608/55000 / Cost: 0.0365698 / Training Accuracy: 0.957031 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 4864/55000 / Cost: 0.0415096 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 5120/55000 / Cost: 0.0480784 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 5376/55000 / Cost: 0.045473 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 5632/55000 / Cost: 0.0515172 / Training Accuracy: 0.910156 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 5888/55000 / Cost: 0.0419528 / Training Accuracy: 0.929688 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 6144/55000 / Cost: 0.046787 / Training Accuracy: 0.902344 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 6400/55000 / Cost: 0.0523165 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 6656/55000 / Cost: 0.0414362 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 / Batch: 6912/55000 / Cost: 0.0468735 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 7168/55000 / Cost: 0.067864 / Training Accuracy: 0.890625 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 7424/55000 / Cost: 0.0441763 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 7680/55000 / Cost: 0.0372609 / Training Accuracy: 0.945312 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 7936/55000 / Cost: 0.0360069 / Training Accuracy: 0.949219 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 8192/55000 / Cost: 0.046486 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 8448/55000 / Cost: 0.0537414 / Training Accuracy: 0.90625 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 8704/55000 / Cost: 0.0343448 / Training Accuracy: 0.945312 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 8960/55000 / Cost: 0.045636 / Training Accuracy: 0.917969 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 9216/55000 / Cost: 0.0293199 / Training Accuracy: 0.980469 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 9472/55000 / Cost: 0.042905 / Training Accuracy: 0.9375 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 9728/55000 / Cost: 0.0598987 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 9984/55000 / Cost: 0.0431958 / Training Accuracy: 0.929688 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 10240/55000 / Cost: 0.0398206 / Training Accuracy: 0.941406 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 10496/55000 / Cost: 0.0476746 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 10752/55000 / Cost: 0.0411753 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 11008/55000 / Cost: 0.0435393 / Training Accuracy: 0.914062 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 11264/55000 / Cost: 0.0504213 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 11520/55000 / Cost: 0.047202 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 11776/55000 / Cost: 0.033859 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 12032/55000 / Cost: 0.0366905 / Training Accuracy: 0.953125 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 12288/55000 / Cost: 0.0433181 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 12544/55000 / Cost: 0.0346741 / Training Accuracy: 0.941406 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 12800/55000 / Cost: 0.0320984 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 13056/55000 / Cost: 0.0478113 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 13312/55000 / Cost: 0.0552855 / Training Accuracy: 0.898438 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 13568/55000 / Cost: 0.0424751 / Training Accuracy: 0.941406 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 13824/55000 / Cost: 0.0374811 / Training Accuracy: 0.929688 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 14080/55000 / Cost: 0.035522 / Training Accuracy: 0.945312 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 14336/55000 / Cost: 0.0380853 / Training Accuracy: 0.914062 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 14592/55000 / Cost: 0.0473089 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 14848/55000 / Cost: 0.0493953 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 15104/55000 / Cost: 0.0372288 / Training Accuracy: 0.949219 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 15360/55000 / Cost: 0.0406193 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 15616/55000 / Cost: 0.0459889 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 15872/55000 / Cost: 0.0516227 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 16128/55000 / Cost: 0.0451372 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 16384/55000 / Cost: 0.0404284 / Training Accuracy: 0.9375 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 16640/55000 / Cost: 0.0366683 / Training Accuracy: 0.957031 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 16896/55000 / Cost: 0.0428146 / Training Accuracy: 0.933594 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 17152/55000 / Cost: 0.0380801 / Training Accuracy: 0.953125 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 17408/55000 / Cost: 0.0354048 / Training Accuracy: 0.957031 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 17664/55000 / Cost: 0.048152 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 17920/55000 / Cost: 0.0451068 / Training Accuracy: 0.917969 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 18176/55000 / Cost: 0.0579974 / Training Accuracy: 0.894531 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 18432/55000 / Cost: 0.0391067 / Training Accuracy: 0.933594 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 18688/55000 / Cost: 0.0570163 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 18944/55000 / Cost: 0.04372 / Training Accuracy: 0.914062 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 19200/55000 / Cost: 0.0381475 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 19456/55000 / Cost: 0.0459747 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 19712/55000 / Cost: 0.0455199 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 19968/55000 / Cost: 0.049036 / Training Accuracy: 0.902344 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 20224/55000 / Cost: 0.0487262 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 20480/55000 / Cost: 0.0418028 / Training Accuracy: 0.945312 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 20736/55000 / Cost: 0.0372125 / Training Accuracy: 0.933594 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 20992/55000 / Cost: 0.044293 / Training Accuracy: 0.917969 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 21248/55000 / Cost: 0.0429842 / Training Accuracy: 0.921875 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 21504/55000 / Cost: 0.0564859 / Training Accuracy: 0.882812 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 21760/55000 / Cost: 0.0438791 / Training Accuracy: 0.941406 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 22016/55000 / Cost: 0.0332186 / Training Accuracy: 0.941406 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 22272/55000 / Cost: 0.0416305 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 22528/55000 / Cost: 0.0445833 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 22784/55000 / Cost: 0.0521187 / Training Accuracy: 0.910156 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 23040/55000 / Cost: 0.0410303 / Training Accuracy: 0.945312 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 23296/55000 / Cost: 0.0436342 / Training Accuracy: 0.925781 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 23552/55000 / Cost: 0.0459358 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 23808/55000 / Cost: 0.0471975 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 24064/55000 / Cost: 0.0366811 / Training Accuracy: 0.945312 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 24320/55000 / Cost: 0.0458882 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 24576/55000 / Cost: 0.0516428 / Training Accuracy: 0.898438 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 24832/55000 / Cost: 0.0354397 / Training Accuracy: 0.960938 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 25088/55000 / Cost: 0.0424975 / Training Accuracy: 0.933594 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 25344/55000 / Cost: 0.0564221 / Training Accuracy: 0.902344 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 25600/55000 / Cost: 0.0529971 / Training Accuracy: 0.914062 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 25856/55000 / Cost: 0.0451568 / Training Accuracy: 0.917969 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 26112/55000 / Cost: 0.058071 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 26368/55000 / Cost: 0.0424436 / Training Accuracy: 0.9375 / Validation Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 / Batch: 26624/55000 / Cost: 0.0408937 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 26880/55000 / Cost: 0.0472978 / Training Accuracy: 0.925781 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 27136/55000 / Cost: 0.041952 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 27392/55000 / Cost: 0.0442819 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 27648/55000 / Cost: 0.041158 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 27904/55000 / Cost: 0.0516903 / Training Accuracy: 0.910156 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 28160/55000 / Cost: 0.0355535 / Training Accuracy: 0.945312 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 28416/55000 / Cost: 0.0446877 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 28672/55000 / Cost: 0.0449965 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 28928/55000 / Cost: 0.0351222 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 29184/55000 / Cost: 0.0434355 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 29440/55000 / Cost: 0.0440805 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 29696/55000 / Cost: 0.0430097 / Training Accuracy: 0.9375 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 29952/55000 / Cost: 0.0455721 / Training Accuracy: 0.921875 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 30208/55000 / Cost: 0.0525532 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 30464/55000 / Cost: 0.0547861 / Training Accuracy: 0.894531 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 30720/55000 / Cost: 0.0348026 / Training Accuracy: 0.9375 / Validation Accuracy: 0.99\n",
      "Epoch: 10 / Batch: 30976/55000 / Cost: 0.0518776 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 31232/55000 / Cost: 0.048362 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 31488/55000 / Cost: 0.0403925 / Training Accuracy: 0.929688 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 31744/55000 / Cost: 0.0423616 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 32000/55000 / Cost: 0.0496457 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 32256/55000 / Cost: 0.0428058 / Training Accuracy: 0.933594 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 32512/55000 / Cost: 0.0443506 / Training Accuracy: 0.9375 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 32768/55000 / Cost: 0.0435913 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 33024/55000 / Cost: 0.0459437 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 33280/55000 / Cost: 0.0451504 / Training Accuracy: 0.914062 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 33536/55000 / Cost: 0.0450607 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 33792/55000 / Cost: 0.0409367 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 34048/55000 / Cost: 0.0432731 / Training Accuracy: 0.941406 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 34304/55000 / Cost: 0.0438908 / Training Accuracy: 0.914062 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 34560/55000 / Cost: 0.0487148 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 34816/55000 / Cost: 0.0432705 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 35072/55000 / Cost: 0.0300991 / Training Accuracy: 0.960938 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 35328/55000 / Cost: 0.0375584 / Training Accuracy: 0.933594 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 35584/55000 / Cost: 0.0339713 / Training Accuracy: 0.941406 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 35840/55000 / Cost: 0.0394459 / Training Accuracy: 0.933594 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 36096/55000 / Cost: 0.0366138 / Training Accuracy: 0.929688 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 36352/55000 / Cost: 0.044649 / Training Accuracy: 0.933594 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 36608/55000 / Cost: 0.0420128 / Training Accuracy: 0.925781 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 36864/55000 / Cost: 0.0343528 / Training Accuracy: 0.949219 / Validation Accuracy: 0.92\n",
      "Epoch: 10 / Batch: 37120/55000 / Cost: 0.036461 / Training Accuracy: 0.9375 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 37376/55000 / Cost: 0.0373064 / Training Accuracy: 0.960938 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 37632/55000 / Cost: 0.0504043 / Training Accuracy: 0.910156 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 37888/55000 / Cost: 0.0319728 / Training Accuracy: 0.949219 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 38144/55000 / Cost: 0.047796 / Training Accuracy: 0.921875 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 38400/55000 / Cost: 0.0527364 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 38656/55000 / Cost: 0.0463379 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 38912/55000 / Cost: 0.045192 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 39168/55000 / Cost: 0.0519726 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 39424/55000 / Cost: 0.0501778 / Training Accuracy: 0.890625 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 39680/55000 / Cost: 0.0419375 / Training Accuracy: 0.945312 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 39936/55000 / Cost: 0.0423156 / Training Accuracy: 0.925781 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 40192/55000 / Cost: 0.0402961 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 40448/55000 / Cost: 0.0398817 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 40704/55000 / Cost: 0.0426787 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 40960/55000 / Cost: 0.0429681 / Training Accuracy: 0.925781 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 41216/55000 / Cost: 0.0403074 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 41472/55000 / Cost: 0.0461322 / Training Accuracy: 0.898438 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 41728/55000 / Cost: 0.0388799 / Training Accuracy: 0.925781 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 41984/55000 / Cost: 0.0532244 / Training Accuracy: 0.898438 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 42240/55000 / Cost: 0.0422844 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 42496/55000 / Cost: 0.0458959 / Training Accuracy: 0.921875 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 42752/55000 / Cost: 0.0444586 / Training Accuracy: 0.917969 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 43008/55000 / Cost: 0.035385 / Training Accuracy: 0.941406 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 43264/55000 / Cost: 0.0336729 / Training Accuracy: 0.953125 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 43520/55000 / Cost: 0.0376734 / Training Accuracy: 0.945312 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 43776/55000 / Cost: 0.0550832 / Training Accuracy: 0.910156 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 44032/55000 / Cost: 0.0364401 / Training Accuracy: 0.929688 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 44288/55000 / Cost: 0.0414427 / Training Accuracy: 0.933594 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 44544/55000 / Cost: 0.0362041 / Training Accuracy: 0.941406 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 44800/55000 / Cost: 0.0480589 / Training Accuracy: 0.9375 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 45056/55000 / Cost: 0.0324758 / Training Accuracy: 0.949219 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 45312/55000 / Cost: 0.0409682 / Training Accuracy: 0.9375 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 45568/55000 / Cost: 0.0502118 / Training Accuracy: 0.90625 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 45824/55000 / Cost: 0.0435697 / Training Accuracy: 0.917969 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 46080/55000 / Cost: 0.044929 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 / Batch: 46336/55000 / Cost: 0.0382755 / Training Accuracy: 0.9375 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 46592/55000 / Cost: 0.0421575 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 46848/55000 / Cost: 0.0479641 / Training Accuracy: 0.914062 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 47104/55000 / Cost: 0.037358 / Training Accuracy: 0.949219 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 47360/55000 / Cost: 0.0496591 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 47616/55000 / Cost: 0.0487224 / Training Accuracy: 0.914062 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 47872/55000 / Cost: 0.0342169 / Training Accuracy: 0.949219 / Validation Accuracy: 0.94\n",
      "Epoch: 10 / Batch: 48128/55000 / Cost: 0.0404257 / Training Accuracy: 0.933594 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 48384/55000 / Cost: 0.0345322 / Training Accuracy: 0.941406 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 48640/55000 / Cost: 0.0518964 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 48896/55000 / Cost: 0.037131 / Training Accuracy: 0.9375 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 49152/55000 / Cost: 0.0409517 / Training Accuracy: 0.929688 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 49408/55000 / Cost: 0.031248 / Training Accuracy: 0.960938 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 49664/55000 / Cost: 0.0387996 / Training Accuracy: 0.941406 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 49920/55000 / Cost: 0.0466737 / Training Accuracy: 0.910156 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 50176/55000 / Cost: 0.0454829 / Training Accuracy: 0.925781 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 50432/55000 / Cost: 0.0329768 / Training Accuracy: 0.945312 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 50688/55000 / Cost: 0.0442039 / Training Accuracy: 0.917969 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 50944/55000 / Cost: 0.028798 / Training Accuracy: 0.957031 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 51200/55000 / Cost: 0.0441719 / Training Accuracy: 0.914062 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 51456/55000 / Cost: 0.0365849 / Training Accuracy: 0.941406 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 51712/55000 / Cost: 0.0429079 / Training Accuracy: 0.9375 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 51968/55000 / Cost: 0.0512817 / Training Accuracy: 0.917969 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 52224/55000 / Cost: 0.0420255 / Training Accuracy: 0.929688 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 52480/55000 / Cost: 0.0377183 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 52736/55000 / Cost: 0.0468616 / Training Accuracy: 0.917969 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 52992/55000 / Cost: 0.0446857 / Training Accuracy: 0.917969 / Validation Accuracy: 0.97\n",
      "Epoch: 10 / Batch: 53248/55000 / Cost: 0.0498234 / Training Accuracy: 0.921875 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 53504/55000 / Cost: 0.0503229 / Training Accuracy: 0.925781 / Validation Accuracy: 0.96\n",
      "Epoch: 10 / Batch: 53760/55000 / Cost: 0.0400462 / Training Accuracy: 0.9375 / Validation Accuracy: 0.95\n",
      "Epoch: 10 / Batch: 54016/55000 / Cost: 0.0416613 / Training Accuracy: 0.945312 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 54272/55000 / Cost: 0.0453995 / Training Accuracy: 0.921875 / Validation Accuracy: 0.91\n",
      "Epoch: 10 / Batch: 54528/55000 / Cost: 0.0368348 / Training Accuracy: 0.949219 / Validation Accuracy: 0.93\n",
      "Epoch: 10 / Batch: 54784/55000 / Cost: 0.0303772 / Training Accuracy: 0.944444 / Validation Accuracy: 0.95\n",
      "Model is saved!!!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "if Is_train == True:\n",
    "    train_data_num = train_x.shape[0]\n",
    "\n",
    "    for i in range(num_epoch):\n",
    "        # Making batches\n",
    "        random_idx = np.arange(train_data_num)\n",
    "        np.random.shuffle(random_idx)\n",
    "\n",
    "        batch_count = 1\n",
    "        for j in range(0, train_data_num, batch_size):\n",
    "            if j + batch_size < train_data_num:\n",
    "                batch_index = [j, j + batch_size]\n",
    "\n",
    "                batch_x_train = train_x[random_idx[batch_index[0]:batch_index[1]],:,:]\n",
    "                batch_y_train = train_y[random_idx[batch_index[0]:batch_index[1]],:]\n",
    "            else:\n",
    "                batch_index = [j, j + train_data_num-1]\n",
    "\n",
    "                batch_x_train = train_x[random_idx[batch_index[0]:batch_index[-1]],:,:]\n",
    "                batch_y_train = train_y[random_idx[batch_index[0]:batch_index[-1]],:]\n",
    "\n",
    "\n",
    "            # Make image as fractions for attention\n",
    "            train_fraction = np.zeros([batch_x_train.shape[0], img_fraction_size, img_fraction_size, len_stack])\n",
    "            validation_fraction = np.zeros([validation_x.shape[0], img_fraction_size, img_fraction_size, len_stack])\n",
    "\n",
    "            index_fraction = 0\n",
    "            for m in range(len_vertical):\n",
    "                start_v = stride * m\n",
    "                for n in range(len_horizontal):\n",
    "                    start_h = stride * n\n",
    "\n",
    "                    train_fraction[:,:,:,index_fraction] = batch_x_train[:, \n",
    "                                                                         start_v : start_v + img_fraction_size, \n",
    "                                                                         start_h : start_h + img_fraction_size]\n",
    "\n",
    "                    validation_fraction[:,:,:,index_fraction] = validation_x[:, \n",
    "                                                                            start_v : start_v + img_fraction_size, \n",
    "                                                                            start_h : start_h + img_fraction_size]\n",
    "                    index_fraction += 1\n",
    "\n",
    "            # Training\n",
    "            optimizer.run(feed_dict = {x_image: train_fraction, y_target: batch_y_train})\n",
    "            cost = sess.run(Cost, feed_dict = {x_image: train_fraction, y_target: batch_y_train})\n",
    "            acc = sess.run(accuracy, feed_dict = {x_image: train_fraction, y_target: batch_y_train})\n",
    "            val_acc = sess.run(accuracy, feed_dict = {x_image: validation_fraction, y_target: validation_y})\n",
    "\n",
    "            # Print Progress\n",
    "            print(\"Epoch: \" + str(i+1) + ' / ' + \n",
    "                  \"Batch: \" + str(j) + '/' + str(train_data_num) + ' / ' + \n",
    "                  \"Cost: \" + str(cost) + ' / ' + \n",
    "                  \"Training Accuracy: \" + str(acc) + ' / ' + \n",
    "                  \"Validation Accuracy: \" + str(val_acc))  \n",
    "\n",
    "        saver.save(sess, 'saved_networks/' + save_name)\n",
    "        print('Model is saved!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa739247d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEbhJREFUeJzt3X2QXXV9x/H3d+9uNiyb3ewGgkJIfMgDlZgUFYOt1lZL\nW6IQOz5gRaFVqX3SjtaHmU6rM1q149jitD50WiwqrQ/QVixFoqOkUUgCFSlBEggkZAkJxCS7Idss\nScjur3+cs3CzbJIlHPbm/vJ+zdzJ3nPu+Z7fOXvu5/zO757NjZQSkqTm19LoBkiSqmGgS1ImDHRJ\nyoSBLkmZMNAlKRMGuiRlwkB/FkXE2yJieaPbIenEkF2gR8R/R0R/RLSNmX5VRHx8zLQHIuI1Fa13\nTkSMRMQT+zSl9PWU0m9VUX/Mul4dEVvGmb4iIt5ZQf3LIuLHz7SOGmPssRgR342IdxxDnTMjYk9E\nRPWtPP5ExMci4urJXrZKWQV6RMwBXgmMABdN9uqBVP47GZ7Nvwgb3RY9SyJic0QMlYH5cNnh6Khw\nFU/8/lJKS1NKRw2bsR2clNKWlFJXmoS/PoyIj0fE2oh4PCI+OsFllkfEr48z/Smdt6fhmWzrhJaN\niLaIuLbc3yMR8SvPYJ2HyCrQgUuB1cBXgN8dnRgRlwOXAB8u30DfiYivAbOB68tpHyxfe15E3BIR\nAxFxR0S8uq7OivLAu7lcZnlE9JazV5b/7i7nLRnb042IX4qI28rat0bEKyZY+5hExOvLbRgo6764\nbt5HIuL+cl0/i4g3lNPPAr4EvCIiBiOiv5x+VUR8oeztDUbEjyPitIi4orwiWhcRi49Wv5x3Wdme\nv4+I3eWylVwpNZEEvC6l1AW8BHgZ8BfjvfAE6SHfB3wI+K+JvLg8+b2UJ993zebHFJn0cKVVU0rZ\nPCgOivdQvEEOAKfWzbsK+PiY1z8A/Frd89OBncBvls9fWz6fUT5fUa7jhUB7+fxT5bw5wDAQdfUu\nA35U/twD9ANvoziRvrV83nO02uNs56uBB8eZvgJ4Z/nzOcB2iqAI4B3l9raV898InFb+/Gbg/+qe\nP9HuMfvv58AvAlOAHwKbKA7KAD4B3FT3+qPVfxx4H1AD3gLsBqY3+hiaxGP1AeA1dc8/A/xn3e/x\nr4Cbgb3AC4Au4MvANmBLub+jfH0L8FlgB3A/8Eflsdgy9rgon18OrAP2AD8rf6dfK5fZW07/YHlM\nj9TVeS7wHWAXsAF4d13NjwHfAr5aLn8X8JJj2C9XAx+dwOsuBK47zLynvNfr5n0OeBB4FPgf4JVj\ntuFa4JvlNvwEWFQ3/7nAv5Xvg43Ae8cs+7Vj2N4twK9UdVxl00OPiFdS9LivSSn9lOLAfttEFq37\n+e3ADSml7wGklH5I8UtdWveaq1JKG1NK+4FrKN4Mh6tX73XAhlSMq4+klL4J3ENxYE60dr0zyp7x\n6GMA+OW6+ZcD/5BS+kkqXA3sB84rt+3fU0rby5+vpTiZvPwI6wP4dkrpf1NKB4BvA4+llP41FUfm\nt+rbO4H621NKf5dSGk4pXQPcW+6jE05EnElxjP20bvLbgXcD0ygC6KsUv78XUJyszy/nA/x+ufxi\nihP4m46wrjcDHwXenoqrg4uAXSmlS8v1vD4VwyyfLRepH0b4Vvma51CcpD8VEb9aN/9C4OtAN3A9\n8IW69X4hIj4/gd0xUUuBG45huduARRQdrK8D10bElLr5F1FsZw/wDeC6iKiVV0nXA3dQBPtrgT+N\niPPHW0lE3BkRbz2G9j0j2QQ6xXDL91NKA+Xzb1D0BJ+OOcBbxgnJ59S95pG6n4eAzgnWPh3oGzOt\nDzjjGGtvTSn11j16gFvGbMufjdmWWWU7iIhL64ZjBoCzgVOOsg3b635+bJznT7R3AvW3jqndN9q2\nE8h15ZDWjyh60Z+um/eVlNI9KaURoBe4AHh/SmlfSmknRU9zNDDeDHwupbQtpbR7TJ2x3gV8puz0\nkFLalFKq/4B93A5JedJ5BfCRlNLjKaU7gSsp3nejbk4pfa88wV9NEZyU6/njlNKfHHl3PC1Lge8+\n3YXKDtXuslN1BcXV8IK6l9yeUvp2SmkY+Nty/nnAucApKaVPlp2QzRTbP25op5QWl522SdU62St8\nNkTEVIrL9paIGB2TmgJMj4gXp5TuYvwPLMZO20Jx2fSeY2jG0T4Q2UYxDFFvNnDjMaxrIrYAn0wp\nPeXNHRGzgX+kGG5aXU67gyffzM/oQ7AJ1IdDT2RQ7IvvPJP1NqFlKaUVh5lXH7JzgDbg4XI4PcrH\ng+X808e8fmzHod6ZFMMFT9dzgf6U0tCY9by07vnYDsnUiGgpT0qViYiFwO6U0thOwUSW/SDwTort\ngeIKqL6j8cR+TCmliNjKkx2NM0Y/U6LY/y0UJ+PjRi499N8GDgK/QHHZubj8+Wae7EFsp7hcrffI\nmGn/AlwYEb8RES0RMTWKWwQn0nPcQTHe+MLDzP8uMC8i3lpewl1ctvH6CdQ+Fv8E/EFEvBwgIk6O\niKURcTJwctnWneV2/h6wsG7Z7cCsGHPr5wSMBvbR6gPMjIj3RkRrOQxwFsfQ42pyR/qws/6kugXY\nR/FZTm9KqSelND2lNNoDfpgiqEfNOULdLRz+GD3SiXwb0FseP6Nm89QrrclwTL3zclj2Q8Cbyn3Y\nQzFWXv97OLPu9UFxVTv6ucWm+ivilFJ3Sql+yLThcgn0S4F/TiltTSn9fPQBfB64JIr7cb8MnF0O\nP/xHudxfA39ZTvtASukhYBnw5xQB3Ufx4dDofjrsAZ9Segz4JHBLWe/lY+b3A68v6+0s/31d3RBR\nFbeG1d+qdjvFOPrny17FBsohqJTSeuBvgDUUJ7WzKU5+o24C7gYeiYifP931T6A+wK3APIp98Qng\njXX7QnVSSo8A3weuiIhpUXhBPHm72zXA+yLijIjoAT5yhHJXAh+MiJcARMQLy+EUGL/TE2UbHgJW\nAZ+OiPaIWEQxfHOk2yEnfHdOeWKfSvFeayvXcbh8msj4eWtZY/TRRtEbfxzYFRFTorg9ctqY5V4a\nEW+IiBrwfooT6RqKsffBiPhw2dGrRcTZEfGyiW7jmO2dUm4vQHtEtB9Lnaeo6tNVHz4m+mCcu2hO\ntAfFHUKvOcy8m6i7K6WcNg34IkVPcQC4HXhLOa9GcQLdSTGc8occepfLIfUoPkS9h6J3uhZYXE6/\niKIT0w98gCfv3BqtczrFFeUuig+5L6+rechdHuMs+yXgi0fYH1dRXNUN1z0uHed13RQnnpaj1Boe\n8/gRxQnmyxR3uGyl6FQ98Xsot+Eais/f9pT7eHFd3edQfJD6cLkPVo1Ztn77fwb8zhHa+MA4bZz9\nTI+r0duepEkTEZcB70opVfYHFToxlMNzb0wpTfodJM0glyEXSSeGAeCKRjfieGUPXZIyYQ9dkjLR\nsPvQI6KSS4OIYM6cOXR0VPn/GqkRhoaG6Ovro6qrxpRSQ/4PlKqObelwDnds20OXpEwY6JKUCQNd\nkjJhoEtSJgx0ScqEgS5JmTDQJSkTBrokZcJAl6RMGOiSlAkDXZIyYaBLUiYMdEnKhIEuSZkw0CUp\nEwa6JGWikV9wUUmdlpYWarUatVqtknpqnFqtRktLCyMjI41uitSUGhboc+bMqaROrVZjyZIlTJ8+\nvZJ6apyBgQEAhoeHG9wSqTk1LNCr+sq4Wq1GT08PM2bMqKSeGqujo8NAl46RY+iSlAkDXZIyYaBL\nUiYMdEnKhIEuSZkw0CUpEwa6JGXCQJekTBjokpQJA12SMmGgS1ImDHRJyoSBLkmZMNAlKRMGuiRl\nwkCXpEwY6JKUiYZ9Y1FXV1cldVpbW5k+fTo9PT2klIDi+0rrfwZIKR3y8+FeNzQ0xOOPP15J21JK\nT9SXpGdbwwK9vb29kjqtra1MnTqVqVOnVlJv//79lX0Fml+lJmkyOeQiSZkw0CUpEwa6JGXCQJek\nTBjokpQJA12SMmGgS1ImDHRJyoSBLkmZMNAlKRMGuiRlwkCXpEwY6JKUCQNdkjJhoEtSJgx0ScqE\ngS5JmWjYNxZV9W0+tVqNWbNmMWvWrErqDQ4OVvYVdNu2bWNgYKCSWpJ0NA0L9JGRkUrqpJSYMWMG\np59+eiX19u7dW1mgP/roowa6pEnjkIskZcJAl6RMGOiSlAkDXZIyYaBLUiYMdEnKhIEuSZkw0CUp\nEwa6JGWiYX8pKql6ra2tzJ07l2XLlvH85z+f9evXc9NNN3H33XdX9tfZOn4Z6FJGpk2bxsKFC7nk\nkkvo7OxkeHiY1atXExGNbpomgUMuUiZaWlo488wzWbx4MfPnz2fdunXcdttt9PX12Ts/QdhDlzLQ\n0tJCb28vS5cu5cILL2TPnj1ceeWVrFy5ksHBQVJKjW6iJoGBLmWgra2NBQsWsGjRIrq7u7n11lu5\n//77/d8+TzAOuUhNLiI46aSTOOecc5g9eza7d+/mxhtvpL+/v9FN0yQz0KUmN2XKFGbMmMG5555L\nb28vGzdu5LrrrmPnzp2NbpommUMuUpObN28eF198Meeddx4HDx5k06ZN7Ny5s7IvalHzaFig12q1\nSuq0trbS09PDKaecUkm99vZ29u/fX1kt6dnU0dHBggULuOCCC+js7OQHP/gBK1as4MCBA41umhqg\nYYHe2lrNqkcDfebMmZXUa2trM9DVNM444wwWLVrEi170IjZs2MDKlSu55ZZbGt0sNYhj6FITW7Jk\nCUuWLOHgwYOsX7+ezZs3s2fPnkY3Sw3iGLrUhCKCqVOnMnfuXGbNmsXAwACrVq3iwQcfbHTT1ED2\n0KUm1N7ezrx585g/fz7t7e3cdddd3H777Wzfvr3RTVMDGehSE+rs7ORVr3oV8+fPZ9++faxZs4aN\nGzcyODjY6KapgQx0qQl1d3ezbNkynve857F37162bt3qbYoy0KVm1NraymmnnUZHRwf79+9nYGCA\n4eHhRjdLDWagS02mt7eXefPm0d3dzZ49e+jr6+OBBx6o7HZbNS/vcpGazNy5czn//PPp6upi/fr1\nrF69mjvvvLPRzdJxwB661GROPfVUzjrrLKZMmcJ9993Hfffd1+gm6ThhoEtNpK2tjd7eXnp7e9mw\nYQNr1qzh3nvvbXSzdJww0KUmMnPmTGbNmkVnZydr165l7dq1bNu2rdHN0nHCQJeayMKFC1m0aBHT\npk1j06ZN3t2iQxjoUhPp7u6ms7OTiKClxbevDuURITWRnp4eurq6APyeUD2FgS41ka6uLk4++WRq\ntRpdXV3MnDmT6dOnN7pZOk54H7rURFpbW6nVanR0dHDuuefS2trKtGnTuOGGG+yxyx661ExWrlzJ\nqlWr2LdvHwsWLKCnp4eIMMwFNLCHXtUHOi0tLezatauyW7f6+/vZt29fJbX27t1bSR1p1Lp167j+\n+usZHByks7OTO+64g82bNze6WTpONP1X0EUEDz30UCW1AHbs2MFjjz1WSa2BgYFK6kijdu/ezfLl\ny1m+fHmjm6LjkEMukpQJA12SMmGgS1ImDHRJyoSBLkmZMNAlKRMGuiRlwkCXpEwY6JKUCQNdkjJh\noEtSJgx0ScqEgS5JmTDQJSkTBrokZcJAl6RMGOiSlImGfWPR0NBQJXWmTJlCf38/7e3tldR79NFH\nOXDgQCW1Dh48WEkdSZqIhgX6rl27KqlTq9W455572LFjRyX1JKlZOeQiSZkw0CUpEwa6JGXCQJek\nTBjokpQJA12SMmGgS1ImDHRJyoSBLkmZMNAlKRMGuiRlwkCXpEwY6JKUCQNdkjJhoEtSJgx0ScqE\ngS5JmWj6r6BrbW1lYGCgklpqrN27dzM0NMTw8HCjmyI1pYYFel9fXyV1arUaACeddFIl9dQ4Q0ND\nbN68mZGRkUY3RWpKDQv0lFIldYaHhzl48KC9ugwMDw8zMjJS2bEhnWgcQ5ekTBjokpQJA12SMmGg\nS1ImDHRJyoSBLkmZMNAlKRMGuiRlwkCXpEwY6JKUCQNdkjJhoEtSJgx0ScqEgS5JmTDQJSkTBrok\nZcJAl6RMhN8OI0l5sIcuSZkw0CUpEwa6JGXCQJekTBjokpQJA12SMmGgS1ImDHRJyoSBLkmZMNAl\nKRMGuiRlwkCXpEwY6JKUCQNdkjJhoEtSJgx0ScqEgS5JmTDQJSkTBrokZcJAl6RM/D90L/Os2ZGk\nWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6af6d9e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6af90f590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKRUKCLiERCgS4iEgkFuohIJP4fQj/3K+mnRh4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6f8053d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e9049ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niHhCgS4i4gkFuoiIJ/4fVdtt0eIAO3kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e8f47e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e8e48e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEpRJREFUeJzt3X2QVfV9x/H39+7DZYWFXVhhAYGgA9UAYhO0Kk5sY2Nb\njMROYkyNkSbRptYmnaRpnOm0cSZpHhrTapqnTmtqHlqSGCUPTtDoGDEhGG0CsYoETBR2Bdzsuiyw\nK9x9uN/+cX4XD5fdZVluPHd/fl4zd7jn6Xd+59xzP+d3fucs19wdERGZ+HJZV0BERCpDgS4iEgkF\nuohIJBToIiKRUKCLiERCgS4iEgkF+m+RmV1tZvdlXQ8ReWWILtDNbIOZdZtZXdn4O8zsI2XjnjWz\n11dovQvMrGhmR/apu6919z+uRPll67rYzNqHGf+Qmb2rAuWvMbMfn2w5ko3yY9HM1pvZO8ZRzjwz\nO2BmVvlaVh8zu9nMvvZyL1tJUQW6mS0ALgKKwOqXe/WAh39fDr/NvwgrbYv8lpjZTjN7MQTm3tDg\nOKWCqzjy+bn7Knc/btiUN3Dcvd3dp/rL8NeHZnahmT0a9scvzGzlGJa5z8z+cJjxxzTeTsDJbOuY\nlzWz68zs6bC9681s9kms94ioAh24FngE+DLw56WRZnY98HbgQ2EHftfMvgrMB+4J4z4Y5j3fzH5i\nZvvMbIuZXZwq5yEz+4iZbQzL3Gdm08Pkh8O/PWHa75W3dMNB+1go+1Ezu2CMZY+Lmb0xbMO+UO6y\n1LSbzOxXYV1PmtkVYfyZwBeBC8zsoJl1h/F3mNnnw8F30Mx+bGazzOzWcEX0lJktP175YdqaUJ/P\nmllPWLYiV0oTiAOXuftU4DXACuAfhpsx9haymTUD3wP+GZgG3ELyvZw2yjKnAK/lpe/dhGFmvw98\nDLgcmA7sBL5ekcLdPZoX8DTwHpIvSD9wamraHcBHyuZ/FviD1PAcoAv4ozB8SRieEYYfCus4A8iH\n4Y+HaQuAIcBS5a0BfhTeNwPdwNUkJ9K3heHm45U9zHZeDLQNM/4h4F3h/e8CHSRBYcA7wvbWhelv\nBmaF91cCvanhI/Uu23+/Ac4B6oEHgWdITpQGfBT4YWr+45U/ALwPqAHeCvQATVkfQy/jsfos8PrU\n8KeA76U+x38CNgJ9wOnAVOBLwB6gPexvC/PngE8DncCvgL8Kx2Ku/LgIw9cDTwEHgCfDZ/rVsExf\nGP/BcEwXU+XMBr4LvADsAK5LlXkz8E3gK2H5J4DXjHFfXAY8UTZuO/DOUZa5HPjOCNOO+a6npt0G\ntAH7gf8FLirbhm8B3wjb8DPg7NT02cBd4Xvwa+C9Zct+dYzbewvw2bJyi8DCkz2uommhm9lFJC3u\nO919M8mBffVYFk29vwb4vrv/AMDdHyT5UFel5rnD3X/t7gXgTpIvw0jlpV0G7PCkX73o7t8Afkly\nYI617LS5oWVceu0D0pep1wP/7u4/88TXgAJwfti2u929I7z/FsnJ5LxR1gfwbXf/hbv3A98GDrn7\n/3hyVH4zXd8xlN/h7v/m7kPufifJF/iy46w/SmY2j+QY25wafQ1wHdBIEkBfIfn8Tic5Wb8hTAf4\ni7D8cpIT+FtGWdeVwIeBazy5OlgNvODu14b1vNGTbpZPh0XS3QjfDPO0kpykPx5amyWXA2tJWtn3\nAJ9PrffzZva50XbDMMNLR5l/FfD9UaaP5DHgbJIG1lrgW2ZWn5q+mmQ7m0lazd8xs5pwlXQPsIUk\ngC8B/sbM3jDcSszscTN72yj1SG9vKYdH294xiSbQSbpb7nf3fWH46yQtwROxAHjrMCHZmprn+dT7\nF4EpYyx7DrCrbNwuYO44y97t7tNTr2bgJ2Xb8rdl23JaqAdmdm2qO2YfsARoOc42dKTeHxpm+Eh9\nx1D+7rKyd5Xq9gryndCl9SOSVvQnUtO+7O6/dPciyWX5nwDvd/fD7t5F0tIsBcaVwG3uvsfde8rK\nKfdu4FOh0YO7P+Pu6RvswzZIwknnAuAmdx9w98eB20m+dyUb3f0H4QT/NZLgJKznRnf/6xHq9Agw\nx8yuMrNaM1tDcqU62j2FVcD6UaYPKzSoekKj6laSq+HfSc3yc3f/trsPAf8app8PnAu0uPvHQiNk\nJ8n2Dxva7r48NNqGcx9Jziw1swaSE2yR0bd3TGpPtoBqYGaTSC7bc2a2N4yuB5rMbJm7P8HwNyzK\nx7WTXDa9ZxzVON4NkT0k3RBp84F7x7GusWgHPubux3y5zWw+8B8k3U2PhHFbeOnLfFI3wcZQPhx9\nIoNkX3z3ZNY7Ab3J3R8aYVo6ZBcAdcDe0J1u4dUWps8pm7+84ZA2j6S74ETNBrrd/cWy9bw2NVze\nIJlkZrlwUhqRu3eb2ZuAfyFp1f8AeAB4brj5zWwp0OPu5Y2C4wr3yt4VtgeSK6B0Q+PIfnR3N7Pd\nvNTQmFu6p0Sy/3MkJ+MT4u4PmtnNwLqw/tuAg4ywvScilhb6nwKDwFkkl53Lw/uNvNSC6CC5XE17\nvmzcfwOXm9mlZpYzs0mWPCI4lpZjJ8lZ9owRpq8HFpnZ28Il3FWhjveMoezx+E/gL83sPAAzm2xm\nq8xsMjA51LUrbOc7OfpyrwM4zcoe/RyDUmAfr3yAmWb23tAiuxI4k3G0uCa40W52pk+q7cBhkns5\n09292d2b3L3UAt5LEtQlC0Ypt52Rj9HRTuR7gOnh+CmZz7FXWuPi7j929/PcvYXkO3sWSffIcMbV\nOg/dsn8HvCXsw2aSvvL05zAvNb+RXNWW7ls8k74idvdp7p7uMh0zd/+iuy9299kkwV5Lcj/jpMQS\n6NcC/+Xuu939N6UX8Dng7ZY8j/slYEnoflgXlvsk8I9h3Afc/TngTcDfkwT0LpKbQ6X9NOIB7+6H\nSO5c/ySUd17Z9G7gjaG8rvDvZakuoko8GpZ+VO3nJP3onwutih2ELih330bSGvopyUltCcnJr+SH\nwFbgeTP7zYmufwzlAzwKLCLZFx8F3pzaF5Li7s8D9wO3mlmjJU43s9eFWe4E3mdmc8MTIzeNUtzt\nwAfN7DUAZnZG6E6B4Rs9FurwHLAJ+ISZ5c3sbJLum9Eehxzz0zlmdk44uU8lOXba3P2BEWYfS/95\nbahn6VVH0hoeAF4ws3oz+3AYl/ZaM7vCzGqA95OcSH9KcnI5aGYfCg29GjNbYmYrxrqNqW3Nm9mS\n8L50NXubu+8/0bKOMd67qXrpNd4XwzxF80p7kTwh9PoRpv2Q1FMpYVwj8AWSluI+4OfAW8O0GpIQ\n7CLpTrmBo59yOao8kpuovyRpnf4fsDyMX03SiOkGPsBLT26VyplDckX5AslN7utTZR71lMcwy34R\n+MIo+2MtyZNO+0juf7WMMN80khNPbpSy7gjrTr9+RHKC+RLJEy67SRpVRz6HsA13hvUfCPt4earc\n1lDPvWEfbCpbNr39TwJ/Nso2PE7SzbKH5IkmG2l7TuRVeuxJ5GUTbnq9291fd9yZRVJC99yb3X20\nJ0hesWLpchGRV4Z9wK1ZV6JaqYUuIhIJtdBFRCKR2XPoZlaRSwMzo6WlhXw+X4niJEOFQoGuri4q\nddXo7pn8HyiVOrZFRjLSsa0WuohIJBToIiKRUKCLiERCgS4iEgkFuohIJBToIiKRUKCLiERCgS4i\nEgkFuohIJBToIiKRUKCLiERCgS4iEgkFuohIJBToIiKRUKCLiERCgS4iEonMfuCiUj9IkcvlaGho\noL6+viLlDQ4OUiwWK1KWnJhcLodZJr9JIRKFzAL9M5/5TEXKyeVyLFq0iMmTJ1ekvLVr17Jt27aK\nlCUnpre3F0AnVJFxyizQzz777IqUk8vlePWrX01jY2NFytuwYQO7d++uSFn6Ae4Tl8/nFegi46Q+\ndBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQikdmf/ovI\n0Wpra2lpaeGiiy5i2bJlTJ48GTPD3enu7ubRRx/l8ccfp6urK+uqSpVSoItUgVKYX3rppVx11VVc\neOGFNDY2UigUAOjq6mLRokUMDQ2xefNmDhw4kHGNpRop0EWqQGNjI0uWLOHmm29m/vz5uDsDAwPs\n3bsXgKlTp3LNNdfQ0dHB/v372bJlS8Y1lmqkQBfJWHNzM5dccgnXXXcdM2bM4ODBgzz99NM8/PDD\nPPbYY0yZMoULLriANWvW0NzczNSpU7OuslQpBbpIxmbNmsXSpUs599xzyefzbNq0iXvvvZcNGzbw\n7LPP0tDQQH9/P6tWraKlpYXW1lby+fyR7hiREgW6SMZOO+00Fi5cyCmnnEJHRwcPPPAA69at45ln\nngHAzNi+fTu7d++mtbWV5cuXs23bNrZt28bAwEDGtZdqokAXydjpp5/OggUL6O3t5e677+bBBx9k\n586dR6a7O/39/XR3d7N8+XJaW1s59dRTuemmm+ju7s6u4lJ19By6SMZmzJhBU1MTPT09rF+/nh07\ndhzzq03ujrtTU1NDfX09kyZN0u+vyjEU6CIZmzRpEvX19RQKBXbu3Mn+/fuPmp7P52lqamL69OnU\n1dVlVEuZCBToIhmqra2lrq6OmpqaYafncjnmzJnD0qVLmT9/Pg0NDQwODnL48GH9Zq0cQ4EukpG6\nujpmzZrF7NmzmTZt2rDzTJkyhdWrV3PjjTcyY8YM6urq6Ozs1A1RGZZuiopkJJfLkc/nyefz1NXV\nUVdXR3NzM/l8Hndn+vTpnH/++axcuZJXvepV1NTU0N/fz44dO9i4caMeW5RjKNBFMjI0NERfXx99\nfX0MDAwwZcoULr74YlpbWwGYN28eK1eu5JxzzqGhoQGA/v5+9uzZw1NPPaUWuhxDgS6SkcHBQTo6\nOti1axddXV0sXLiQG264gZ6eHmpra5k7dy6TJ0/G3Tl06BCTJk3i8OHDHDx4kN7e3qyrL1VIgS6S\nsU2bNjFnzhyam5uZOXMmM2fOpFgsMjg4yJ49e9iyZQu9vb1cffXVPPLIIzzxxBNZV1mqlAJdJGNb\nt26lWCzS1tbGFVdcwaFDh2hra6O9vZ3nnnuOQqHA4sWLcXf279+v1rmMSIEukrGOjg46OzvZunUr\nQ0ND9PT0sH37dnbu3ElHRwcrVqxgxYoVWVdTJgAFukgVKBaLdHZ2cssttxwzbcGCBSxbtoxcLnnK\nWM+fy0gU6CJVysxobm5m8eLFnHnmmZgZbW1tdHR0ZF01qVL6wyKRKlb6s/+mpiYA2tvbFegyIrXQ\nRaqYmWFmR7pbDh8+TH9/f8a1kmqlFrrIBLJs2TLOOOOMrKshVUqBLjKBNDU10djYmHU1pEop0EUm\nkPr6ev0XujIiBbrIBDI0NMTQ0FDW1ZAqpUAXmUC6u7s5cOBA1tWQKpXZUy633357RcqpqanhrLPO\nqli/Yvq3HEWyVigUOHDgAJ2dnQwMDPDkk0/S3t6edbWkSmUW6Pfff39FysnlcrS3t+tGkUSn9L8s\nbtmyhbvuuouBgQE2b95MV1dX1lWTKqXn0EWq2Isvvsi6detYt25d1lWRCUB96CIikVCgi4hEQoEu\nIhIJBbqISCQU6CIikVCgi4hEQoEuIhIJBbqISCQU6CIikVCgi4hEQoEuIhIJBbqISCQU6CIikVCg\ni4hEQoEuIhIJBbqISCSi+IELd8fds66GiEim1EIXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1E\nJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAX\nEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQ\nRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIK\ndBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmE\nAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQiUZvViguFQkXKqampoa+vryJlSbb6\n+vooFAoUi8WsqyIyIWUW6F1dXRUpx8wAqK+vr0h5kp1CoUBnZyfunnVVRCakzAK9kl/aoaEhteoi\nUCwWcXcFusg4qQ9dRCQSCnQRkUgo0EVEIqFAFxGJhAJdRCQSCnQRkUgo0EVEIqFAFxGJhAJdRCQS\nCnQRkUgo0EVEIqFAFxGJhAJdRCQSCnQRkUgo0EVEIqFAFxGJhAJdRCQSpl+HERGJg1roIiKRUKCL\niERCgS4iEgkFuohIJBToIiKRUKCLiERCgS4iEgkFuohIJBToIiKRUKCLiERCgS4iEgkFuohIJBTo\nIiKRUKCLiERCgS4iEgkFuohIJBToIiKRUKCLiERCgS4iEgkFuohIJP4fsdpgKMq4nIUAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e8d495d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAkDXZIyYaBLUiYMdEnKhIEuSZn4f9O2CL8QH1QUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e8d7ad10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADDCAYAAACS2+oqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNo12TgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e8c5ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Sampling test indexes\n",
    "idx = random.sample(range(test_x.shape[0]), num_test_sample)\n",
    "\n",
    "# Initialize fraction of test images and heatmap\n",
    "test_fraction = np.zeros([10, img_fraction_size, img_fraction_size, len_stack])\n",
    "heat_map = np.zeros([num_test_sample, img_size, img_size])\n",
    "\n",
    "num_correct = 0.\n",
    "\n",
    "# Test for Sampling data\n",
    "for idx_sample in range(num_test_sample):\n",
    "    \n",
    "    # Making test fractions\n",
    "    index_fraction = 0\n",
    "    for m in range(len_vertical):\n",
    "        start_v = stride * m\n",
    "        for n in range(len_horizontal):\n",
    "            start_h = stride * n\n",
    "\n",
    "            test_fraction[idx_sample,:,:,index_fraction] = test_x[idx[idx_sample], \n",
    "                                                                  start_v : start_v + img_fraction_size, \n",
    "                                                                  start_h : start_h + img_fraction_size]\n",
    "\n",
    "            index_fraction += 1\n",
    "\n",
    "    # Get alpha(weight of fractions) and output for sample test data\n",
    "    alpha_, output_ = sess.run([alpha, output],feed_dict = {x_image: [test_fraction[idx_sample,:,:,:]], y_target: [test_y[idx[idx_sample],:]]})\n",
    "    alpha_reshape = np.reshape(alpha_, (1, len_vertical, len_horizontal))\n",
    "    \n",
    "    # Make heatmap with alpha\n",
    "    for i in range(len_vertical):\n",
    "        for j in range(len_horizontal):\n",
    "            heat_map[idx_sample, stride * i : (stride * i + img_fraction_size), stride * j : (stride * j + img_fraction_size)] += alpha_reshape[:, i, j]\n",
    "\n",
    "    heat_map[idx_sample,:,:] = heat_map[idx_sample,:,:] / np.max(heat_map[idx_sample,:,:])\n",
    "\n",
    "    # Get labels for test samples\n",
    "    y_test_pred = np.argmax(output_[:])\n",
    "    y_test_true = np.argmax(test_y[idx[idx_sample], :])\n",
    "    \n",
    "    # Draw subplot for each sample \n",
    "    f1, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(heat_map[idx_sample,:,:], cmap='gray')\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title('Attention Heatmap')\n",
    "    ax[1].imshow(test_x[idx[idx_sample],:,:], cmap='gray')\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title('Prediction: ' + str(y_test_pred) + ' / ' + 'Label: ' + str(y_test_true))\n",
    "\n",
    "    # Count correct\n",
    "    if y_test_pred == y_test_true:\n",
    "        num_correct += 1.\n",
    "\n",
    "# Show results \n",
    "plt.show()\n",
    "print('Sample Accuracy: ' + str(num_correct / num_test_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
